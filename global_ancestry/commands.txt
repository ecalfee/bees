# global ancestry assessed by
# (1) PCA
# (2) NGSAdmix
# All implemented in ANGSD based off of genotype likelihoods at SNPs in low LD


# Pass 1 analysis with Harpur reference A/C/M plus some previous CA bees and new CA/AR 2018 bees:
# (0) SNPs need to be in low LD for this analysis.
# for input files in results/input/, I concatenate the GL for every 1000th SNP for ordered scaffolds:
# first make a list of gl files in order (different order will give different SNPs):
bees/global_ancestry$ for i in $(cat ../data/honeybee_genome/ordered_scaffolds.list); do echo "scaffold_$i.beagle.gz"; done > results/input/ordered_scaffolds.GL.files
# then thin to every 1000th SNP:
bees/global_ancestry$ nohup ./catBeagleGL_nth.sh 1000 ordered_scaffolds ../geno_lik_and_SNPs/results/pass1_GL_by_scaffold >& logs/prune_ordered_scaffolds_by1000.out &
[1] 22451 - COMPLETE (few minutes) # about 3k snps
# also pruning by every 250 SNPs
bees/global_ancestry$ nohup ./catBeagleGL_nth.sh 250 ordered_scaffolds ../geno_lik_and_SNPs/results/pass1_GL_by_scaffold >& logs/prune_ordered_scaffolds_by250.out &
[1] 1443 - COMPLETE

# (1) run PCAngsd (note: first need to install pcangsd.py, python2, pip2, and using pip2 all the dependencies, e.g. numpy, listed here: http://www.popgen.dk/software/index.php/PCAngsd)
bees/global_ancestry$ nohup ./runPCAngsd.sh ordered_scaffolds_prunedBy250 >& logs/runPCA_ordered_scaffolds_prunedBy250.out &
[1] 14723 - COMPLETE (seconds)

bees/global_ancestry$ nohup ./runPCAngsd.sh ordered_scaffolds_prunedBy1000 >& logs/runPCA_ordered_scaffolds_prunedBy1000.out &
[2] 15018 - COMPLETE (seconds)

# (2) run NGSAdmix
bees/global_ancestry$ nohup ./runNGSadmix.sh 3 ordered_scaffolds_prunedBy250 &> logs/runNGSadmix_ordered_scaffolds_prunedBy250.out &
[1] 13386 - COMPLETE (seconds)

bees/global_ancestry$ nohup ./runNGSadmix.sh 3 ordered_scaffolds_prunedBy1000 &> logs/runNGSadmix_ordered_scaffolds_prunedBy1000.out &
[1] 13376 - COMPLETE (seconds)

# checking for O ancestry with NGSAdmix K = 4
bees/global_ancestry$ nohup ./runNGSadmix.sh 4 ordered_scaffolds_prunedBy1000 &> logs/runNGSadmix_ordered_scaffolds_prunedBy1000_K4.out &
[2] 3597 - COMPLETED (seconds)
bees/global_ancestry$ nohup ./runNGSadmix.sh 4 ordered_scaffolds_prunedBy250 &> logs/runNGSadmix_ordered_scaffolds_prunedBy250_K4.out &
[2] 3639 - COMPLETED (seconds)


# Adding in 3 bees from Kohn's new dataset - Mexico and San Diego

# (0) pruning new GL's pass1 plus kohn, take every nth SNP:
global_ancestry$ nohup ./catBeagleGL_nth.sh 1000 ordered_scaffolds_pass1_plus_kohn ../geno_lik_and_SNPs/results/pass1_plus_kohn_GL_by_scaffold >& logs/prune_ordered_scaffolds_pass1_plus_kohn_by1000.out &
[1] 10392 - COMPLETED 2.4.19
# also pruning by every 250 SNPs
global_ancestry$ nohup ./catBeagleGL_nth.sh 251 ordered_scaffolds_pass1_plus_kohn ../geno_lik_and_SNPs/results/pass1_plus_kohn_GL_by_scaffold >& logs/prune_ordered_scaffolds_pass1_plus_kohn_by251.out &
[2] 11094 - COMPLETED 2.4.19

# (1) did not run PCA on this set of data

# (2) running NGSadmix on pass1 plus kohn dataset:
global_ancestry$ nohup parallel --no-swap --jobs 4 --joblog logs/runNGSadmix_ordered_scaffolds_pass1_plus_kohn.log './runNGSadmix.sh {1} ordered_scaffolds_pass1_plus_kohn_prunedBy{2}' ::: 2 3 4 ::: 1000 251 &> logs/runNGSadmix_ordered_scaffolds_pass1_plus_kohn.out &
[1] 1250 - COMPLETED 2.4.19


# Added Wallberg 2014 reference bees:
# (0) prune LD = take every nth SNP:
global_ancestry$ nohup parallel --noswap --joblog logs/prune_ordered_scaffolds_pass1_plus_kohn_and_wallberg_byN.log './catBeagleGL_nth.sh {1} ordered_scaffolds_pass1_plus_kohn_and_wallberg ../geno_lik_and_SNPs/results/pass1_plus_kohn_and_wallberg_GL_by_scaffold' ::: 1000 251 >& logs/prune_ordered_scaffolds_pass1_plus_kohn_and_wallberg_byN.out &
[1] 22197 - COMPLETED 2.10.19

# (1) run PCAngsd
global_ancestry$ nohup parallel --noswap --joblog logs/runPCA_ordered_scaffolds_pass1_plus_kohn_and_wallberg.log './runPCAngsd.sh ordered_scaffolds_pass1_plus_kohn_and_wallberg_prunedBy{1}' ::: 1000 251 &> logs/runPCA_ordered_scaffolds_pass1_plus_kohn_and_wallberg.out &
[1] 12839 - COMPLETED 2.10.19

# (2) run NGSadmix:
global_ancestry$ nohup parallel --noswap --jobs 4 --joblog logs/runNGSadmix_ordered_scaffolds_pass1_plus_kohn_and_wallberg.log './runNGSadmix.sh {1} ordered_scaffolds_pass1_plus_kohn_and_wallberg_prunedBy{2}' ::: 2 3 4 ::: 1000 251 &> logs/runNGSadmix_ordered_scaffolds_pass1_plus_kohn_and_wallberg.out &
[1] 13525 - COMPLETED 2.10.19


# excluding O bees from Jordan (because appear admixed):

# (0) cut those columns out of genotype likelihood files:
global_ancestry/results/input$ zcat ordered_scaffolds_pass1_plus_kohn_and_wallberg_prunedBy251.beagle.gz | cut -f1-534,553-576 | gzip > ordered_scaffolds_pass1_plus_kohn_and_wallberg_noJordanO_prunedBy251.beagle.gz
global_ancestry/results/input$ zcat ordered_scaffolds_pass1_plus_kohn_and_wallberg_prunedBy1000.beagle.gz | cut -f1-534,553-576 | gzip > ordered_scaffolds_pass1_plus_kohn_and_wallberg_noJordanO_prunedBy1000.beagle.gz

# (1) run PCAngsd
global_ancestry$ nohup parallel --noswap --joblog logs/runPCA_ordered_scaffolds_pass1_plus_kohn_and_wallberg_noJordanO.log './runPCAngsd.sh ordered_scaffolds_pass1_plus_kohn_and_wallberg_noJordanO_prunedBy{1}' ::: 1000 251 &> logs/runPCA_ordered_scaffolds_pass1_plus_kohn_and_wallberg_noJordanO.out &
[1] 16247 - COMPLETED 2.10.19

# (2) run NGSadmix:
global_ancestry$ nohup parallel --noswap --jobs 4 --joblog logs/runNGSadmix_ordered_scaffolds_pass1_plus_kohn_and_wallberg_noJordanO.log './runNGSadmix.sh {1} ordered_scaffolds_pass1_plus_kohn_and_wallberg_noJordanO_prunedBy{2}' ::: 2 3 4 ::: 1000 251 &> logs/runNGSadmix_ordered_scaffolds_pass1_plus_kohn_and_wallberg_noJordanO.out &
[1] ? - COMPLETED 2.10.19

# NGSadmix with wallberg bees, want to see K=5,6,7 results, for O group including and excluding Jordan's O bees:
global_ancestry$ nohup parallel --noswap --jobs 4 --joblog logs/runNGSadmix_ordered_scaffolds_pass1_plus_kohn_and_wallberg_K567.log './runNGSadmix.sh {1} ordered_scaffolds_pass1_plus_{3}_prunedBy{2}' ::: 5 6 7 ::: 1000 251 ::: kohn_and_wallberg kohn_and_wallberg_noJordanO &> logs/runNGSadmix_ordered_scaffolds_pass1_plus_kohn_and_wallberg_K567.out &
[1] 18920 - COMPLETED 2.10.19


# The Wallberg A group is less differentiated on the PCA than other A bees from Harpur and Sheppard.
# Can I replicate Kohn's results by only including Wallberg's A's? This would give me an explanation.

# (0) cut those columns out of genotype likelihood files:
global_ancestry/results/input$ zcat ordered_scaffolds_pass1_plus_kohn_and_wallberg_prunedBy251.beagle.gz | cut -f1-57,109-576 | gzip > ordered_scaffolds_pass1_plus_kohn_and_wallberg_onlyWallbergA_prunedBy251.beagle.gz

# (1) run PCAngsd
global_ancestry$ nohup parallel --noswap --joblog logs/runPCA_ordered_scaffolds_pass1_plus_kohn_and_wallberg_onlyWallbergA.log './runPCAngsd.sh ordered_scaffolds_pass1_plus_kohn_and_wallberg_onlyWallbergA_prunedBy{1}' ::: 251 &> logs/runPCA_ordered_scaffolds_pass1_plus_kohn_and_wallberg_onlyWallbergA.out &
[1] 30706 - COMPLETED 2.11.19

# (2) run NGSadmix:
global_ancestry$ nohup parallel --noswap --jobs 4 --joblog logs/runNGSadmix_ordered_scaffolds_pass1_plus_kohn_and_wallberg_onlyWallbergA.log './runNGSadmix.sh {1} ordered_scaffolds_pass1_plus_kohn_and_wallberg_onlyWallbergA_prunedBy{2}' ::: 2 3 4 5 ::: 251 &> logs/runNGSadmix_ordered_scaffolds_pass1_plus_kohn_and_wallberg_onlyWallbergA.out &
[2] ? - COMPLETED 2.11.19


# What if I only use the Wallberg reference bees? Exclude all Harpur and Sheppard reference bees:
global_ancestry/results/input$ zcat ordered_scaffolds_pass1_plus_kohn_and_wallberg_prunedBy251.beagle.gz | cut -f1-3,109-576 | gzip > ordered_scaffolds_pass1_plus_kohn_and_wallberg_onlyWallbergREF_prunedBy251.beagle.gz
global_ancestry$ nohup parallel --noswap --jobs 4 --joblog logs/runNGSadmix_ordered_scaffolds_pass1_plus_kohn_and_wallberg_onlyWallbergREF.log './runNGSadmix.sh {1} ordered_scaffolds_pass1_plus_kohn_and_wallberg_onlyWallbergREF_prunedBy{2}' ::: 2 3 4 5 ::: 251 &> logs/runNGSadmix_ordered_scaffolds_pass1_plus_kohn_and_wallberg_onlyWallbergREF.out &
[1] 31303 - COMPLETED 2.11.19 - Still could not replicate low A ancestry in San Diego finding.


# NOTE: pruning by every 1000th snp leaves about 3k snps, and pruning by every 251 snps leaves ~12k snps (on avg. ~80kb and ~19kb spacing, respectively)

# To see the actual spacing of SNPs, however, I need to pull that information from the beagle.gz file:
global_ancestry/results/input$ zcat ordered_scaffolds_pass1_plus_kohn_and_wallberg_prunedBy251.beagle.gz | cut -f1 | tail -n +2 > ordered_scaffolds_pass1_plus_kohn_and_wallberg_prunedBy251.var.sites
# I plot the results in plot_NGSadmix.R

# Pass 1 analysis with Harpur reference A/C/M plus some previous CA bees and new CA/AR 2018 bees:
# (0) SNPs need to be in low LD for this analysis.
# for input files in results/input/, I concatenate the GL for every 250th SNP for ordered scaffolds:
# then thin to every 250th SNP:
bees/global_ancestry$ nohup ./catBeagleGL_nth.sh 250 ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg ../geno_lik_and_SNPs/results/CA_AR_MX_harpur_sheppard_kohn_wallberg/GL_by_scaffold >& logs/CA_AR_MX_harpur_sheppard_kohn_wallberg_prune_ordered_scaffolds_by250.out &
[1] 28323 - COMPLETE (few minutes) # about 12k snps

# concatenate all SNPs (no thinning):
bees/global_ancestry$ nohup ./catBeagleGL_nth.sh 0 ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg ../geno_lik_and_SNPs/results/CA_AR_MX_harpur_sheppard_kohn_wallberg/GL_by_scaffold >& logs/CA_AR_MX_harpur_sheppard_kohn_wallberg_prune_ordered_scaffolds_by0.out &
[2] 7969

# (1) run PCAngsd
bees/global_ancestry$ nohup ./runPCAngsd.sh ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_prunedBy250 >& logs/runPCA_CA_AR_MX_harpur_sheppard_kohn_wallberg_ordered_scaffolds_prunedBy250.out &
[1] 7588 - COMPLETE (seconds)
bees/global_ancestry$ nohup ./runPCAngsd.sh ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_prunedBy0 >& logs/runPCA_CA_AR_MX_harpur_sheppard_kohn_wallberg_ordered_scaffolds_prunedBy0.out &
[1] 19988 - DID NOT RUN - 3 million SNPs is probably memory overload

# (2) run NGSAdmix
bees/global_ancestry$ nohup parallel './runNGSadmix.sh {1} ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_prunedBy250' ::: 3 4 &> logs/runNGSadmix_ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_prunedBy250.out &
[1] 7897 - COMPLETE (seconds)
bees/global_ancestry$ nohup parallel './runNGSadmix.sh {1} ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_prunedBy0' ::: 3 4 &> logs/runNGSadmix_ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_prunedBy0.out &
[2] 20012 - DID NOT RUN - 3 million SNPs is probably memory overload

# (3) # made multiple R scripts for plotting results:
plot_PCA.R
plot_NGSadmix.R
plot_admixture_by_PCA.R # shows congruence between these two global ancestry analyses


# do NGSAdmix by recombination rate:
(0) Get SNPs -- first limit to SNPs actually on chromosome (with estimated recombination rates)
# make list of ordered chromosomes
global_ancestry$ grep -v 'GroupUn' ../data/honeybee_genome/ordered_scaffolds.list > ../data/honeybee_genome/ordered_scaffolds.NoGroupUn.list
global_ancestry$ grep -v 'GroupUn' results/input/ordered_scaffolds.GL.files > results/input/ordered_scaffolds.NoGroupUn.GL.files
# take every 10th SNP on one of these chromosomes (just to make it slightly more manageable than all SNPs)
global_ancestry$ nohup ./catBeagleGL_NoGroupUn_nth.sh 10 ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn ../geno_lik_and_SNPs/results/CA_AR_MX_harpur_sheppard_kohn_wallberg/GL_by_scaffold >& logs/CA_AR_MX_harpur_sheppard_kohn_wallberg_prune_ordered_scaffolds_NoGroupUn_by10.out &
[1] 11273
# make list of SNPs
global_ancestry/results/input$ zcat ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10.beagle.gz | cut -f1 | tail -n +2 > ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10.snplist
# get updated chromosome level SNP position as a .bed file interactively using pos_snps/scaffolds_to_chr.R
wrote file: global_ancestry/results/input/ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10.bed
# get recombination rate bin at 10kb resolution of map, quintiles 1=low, 5=highly
global_ancestry/results/input$ bedtools map -a ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10.bed -b ../../../pos_snps/results/rmap_Wallberg2015_10kb.bed -c 5 -o mean > ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10.10kb.rbin5.bed
# sort back to original SNP order
global_ancestry/results/input$ cat ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10.10kb.rbin5.bed | sort -k 5 -n > ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10.10kb.rbin5.orig_order.bed
# divide GL file (with same sort order) into the 5 recombination bins:
global_ancestry/results/input$ nohup parallel --noswap --joblog ../../logs/recomb_10kb_5bins_ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedby10.log --jobs 5 \
'mkdir -p recomb_10kb_5bins_{1}; (zcat ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10.beagle.gz | head -n 1; \
zcat ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10.beagle.gz | tail -n +2 | \
paste ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10.10kb.rbin5.orig_order.bed - | \
awk -v i="{1}" '$6==i {print $0}'| cut -f7- ) | gzip > recomb_10kb_5bins_{1}/ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10.beagle.gz' \
::: {1..5} &> ../../logs/recomb_10kb_5bins_ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedby10.out &
[3] 14257 - DIDN'T WORK. USING 4 LOOP:
for i in {1..5}; do mkdir -p recomb_10kb_5bins_$i; (zcat ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10.beagle.gz | head -n 1; \
zcat ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10.beagle.gz | tail -n +2 | \
paste ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10.10kb.rbin5.orig_order.bed - | \
awk -v i=$i '$6==i {print $0}'| cut -f7- ) | gzip > recomb_10kb_5bins_$i/ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10.beagle.gz; done
# ran: looks like about 1/6 of SNPs do not have recombination rates at this resolution map "."
# and so these SNPs are excluded. But there's >50k in each of the recombination bin categories
global_ancestry/results/input$ cut -f6 ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10.10kb.rbin5.orig_order.bed | sort | uniq -c

# (2) run NGSAdmix
global_ancestry$ nohup parallel --noswap --joblog logs/runNGSadmix_ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_prunedBy10_NoGroupUn_recomb10kb_bin5.log './runNGSadmix.sh 3 recomb_10kb_5bins_{1}/ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10' ::: {1..5} &> logs/runNGSadmix_ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_prunedBy10_NoGroupUn_recomb10kb_bin5.out &
[1] 28528 - ARG. Got segmentation fault from trying to save file to directory that didn't exist. Renaming input files without a directory.
global_ancestry/results/input$ for i in {1..5}; do cp recomb_10kb_5bins_"$i"/ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10.beagle.gz recomb_10kb_5bins_"$i"_ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10.beagle.gz; done
global_ancestry$ nohup parallel --noswap --joblog logs/runNGSadmix_ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_prunedBy10_NoGroupUn_recomb10kb_bin5.log './runNGSadmix.sh 3 recomb_10kb_5bins_{1}_ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_NoGroupUn_prunedBy10' ::: {1..5} &> logs/runNGSadmix_ordered_scaffolds_CA_AR_MX_harpur_sheppard_kohn_wallberg_prunedBy10_NoGroupUn_recomb10kb_bin5.out &
[1] 29259 - RUNNING 6.16.19

# ------------------------------------------------------------------------------------------------------- #
# Combined Sept 19 analysis with Harpur reference A/C/M plus some previous CA 2014 bees and all new CA/AR 2018 bees:
# (0) SNPs need to be in low LD for this analysis.
# for input files in results/input/, I concatenate the GL for every 250th SNP for ordered scaffolds:
# then thin to every 250th SNP:
# (note I modified catBeagleGL_nth to take in a list of scaffold names
bees/global_ancestry$ nohup ./catBeagleGL_nth.sh 250 combined_sept19 chr >& logs/combined_sept19_chr_prune_by250.out &
[1] 25979 - COMPLETE (few minutes) # about 14k snps
# repeat for all scaffolds (not just chr):
bees/global_ancestry$ nohup ./catBeagleGL_nth.sh 250 combined_sept19 scaffolds >& logs/combined_sept19_scaffolds_prune_by250.out &
[2] 26003- COMPLETE (very fast). Only adds 46 SNPs..must not map as well to these shorter GroupUn scaffolds. I won't run include these any further.
GroupUN only contributes 0.3% of SNPs:
global_ancestry$ zcat ../geno_lik_and_SNPs/results/combined_sept19/GL_by_scaffold/*.mafs.gz | wc -l
3522504
global_ancestry$ zcat ../geno_lik_and_SNPs/results/combined_sept19/GL_by_scaffold/GroupUN*.mafs.gz | wc -l
11654


# (1) run PCAngsd
bees/global_ancestry$ nohup ./runPCAngsd.sh combined_sept19_chr_prunedBy250 >& logs/runPCA_combined_sept19_chr_prunedBy250.out &
[1] 26484 - COMPLETE (seconds)

# (2) run NGSAdmix
bees/global_ancestry$ nohup parallel './runNGSadmix.sh {1} combined_sept19_chr_prunedBy250' ::: 3 4 &> logs/runNGSadmix_combined_sept19_chr_prunedBy250.out &
[2] 26646 - COMPLETE (seconds)

# (3) # R scripts for plotting results:
plot_PCA.R
plot_NGSadmix.R
plot_admixture_by_PCA.R # shows congruence between these two global ancestry analyses

# Getting matching variant sites files for the thinned set of SNPs (so I can run within ancestry PCAs):
nohup ./makeVarSites_nth.sh 250 combined_sept19 chr >& logs/combined_sept19_chr_prune_by250_variant_sites.out &


# TO DO: Make NGSAdmix plots more interpretable by making anc1 always A etc. (using A group)
# because Avalon bees are driving PC3 and are likely highly drifted from their island status, maybe exclude them and rerun PCA to see if 'O' group pops out along PC3 instead
# haha make shorter file names

# This file describes the bioinformatics pipeline for the honeybee data I use.

# Bee_bam are BAM files created by Julie Cridland from the Ramirez Lab CA bee sequencing.
# Her pipeline will be published soon, but I try to reproduce it for the other files.
# I will only be using the modern (not historical) bees which have generally good coverage

# Downloaded Apis mellifera genome v4.5 from beebase.org on 10.12.17, saved in honeybee_genome

# Downloaded Harpur 2014 A, C and M bees. To get NCBI data, first downloaded SRA Toolkit.
wget https://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/2.8.2-1/sratoolkit.2.8.2-1-ubuntu64.tar.gz
tar xzvf sratoolkit.2.8.2-1-ubuntu64.tar.gz
# Downloaded sra-toolkit version 2.8.2-1 on 10.12.17


# Dowloaded alignment software - Bowtie2 v 2.3.3.1 release Oct 5 2017
# Had trouble downloading preferred threading software, Threading Building Blocks library,
# so compiled with option to use pthread instead (hence "-legacy") 
make NO_TBB=1
# Please cite: Langmead B, Salzberg S. Fast gapped-read alignment with Bowtie 2. Nature Methods. 2012, 9:357-359.
# Used Bowtie 2 to align Harpur reads to honey bee genome with very-sensitive-local alignment parameters

# To do: 1) Possibly apply filter based on heterozygosity calls in haploid males, 
# e.g. Wallberg data, to filter out regions with genome (multiple) alignment errors
# 

# Dowloaded recombination genetic map from Liu 2015 supplement and saved in recomb_map
# I will use Liu 2015's high-density map from sequenced haploid workers (used to phase queens)
# 2177 recombination events were logged in S5_rates.txt downloaded (and renamed) from Liu 2015
# (emailed authors - doesn't include recombination in bee genome gaps)

# downloading NCBI data - Harpur 2014 not sure they're actually paired reads
while read p; do fastq-dump --split-files -clip --gzip --skip-technical -O ../bees/data/Harpur_2014_NCBI/ "${p}"; done < ../bees/SRR_Acc_List_Harpur_2014.txt;

# indexed v4.5 genome from www.beebase.org
bees/data/honeybee_genome$ bowtie2-build Amel_4.5_scaffolds.fa.gz honeybee_Amel_4.5

# aligning Harpur NCBI reads using very-sensitive-local alignment with Bowtie 2
# ID uses accession number. Pipes directly into samtools to convert from SAM to binary BAM format
parallel --noswap --joblog ../../Harpur_2014_alignment.log --jobs 6 'bowtie2 --seed 2014 --very-sensitive --local -x honeybee_Amel_4.5 -U ../Harpur_2014_NCBI/fastq_files/{1}_1.fastq.gz --rg-id Harpur2014 --rg SM:{1} | samtools view -b - > ../Harpur_2014_NCBI/bam_files/Harpur_{1}.bam' :::: ../../SRR_Acc_List_Harpur_2014.txt
# Job started: Fri Nov  3 15:03:22 PDT 2017 -- Finished . Note that this was run with samtools v1.1 (downloaded by default with bwa.kit). On Dec 1 2017 I downloaded Samtools v1.6 due to incompatibility issues with bcf2 files produced and GATK

# download NCBI data - Sheppard's honeybees from Kenya (6)
while read p; do fastq-dump --split-files -clip --gzip --skip-technical -O data/Kenya_Sheppard_NCBI/ "${p}"; done < SRR_Acc_List_Kenya_Sheppard.txt;
# Job started: Fri Nov  3 17:03:30 PDT 2017 -- Finished

# aligning Sheppard's 6 samples from Kenya using very-sensitive-alignment with Bowtie 2
data/honeybee_genome$ parallel --noswap --joblog ../../Kenya_Sheppard_alignment.log --jobs 6 'bowtie2 --seed 2014 --very-sensitive --local -x honeybee_Amel_4.5 -U ../Kenya_Sheppard_NCBI/fastq_files/{1}_1.fastq.gz --rg-id Kenya --rg SM:{1} | samtools view -b - > ../Kenya_Sheppard_NCBI/bam_files/Kenya_{1}.bam' :::: ../../SRR_Acc_List_Kenya_Sheppard.txt

# sorting and indexing BAM files for both reference data sets: Harpur_2014 and Kenya_Sheppard data
parallel --noswap --joblog ../Harpur_Kenya_bam_sorting.log --jobs 6 'samtools sort {1} {1.}.sorted; samtools index {1.}.sorted.bam' ::: Harpur_2014_NCBI/bam_files/* Kenya_Sheppard_NCBI/bam_files/*

# indexing BAM files from CA (already sorted) 
parallel --noswap --jobs 6 'samtools index {1}' ::: data/CA_Bee_bam/*.bam

# Make a list of files to include in ANGST -- only more recent CA samples, no cerano individuals (CA or Harpur)
for i in data/Harpur_2014_NCBI/bam_files/Harpur_*.sorted.bam; do echo $i >> Bee_bam_include_NGSadmix.txt; done
for i in data/Kenya_Sheppard_NCBI/bam_files/Kenya_*.sorted.bam; do echo $i >> Bee_bam_include_NGSadmix.txt; done
cat List_CA_bees_include.txt | while read id rest_of_info ; do echo data/CA_Bee/bam_files/$id.*.bam >> Bee_bam_include_NGSadmix.txt; done
removed Harpur cerano = SRR957079 from list in Bee_bam_include_NGSadmix.txt

# Next I will use ANGST to create a beagle-type genotype likelihood file for input into NGSadmix which I will use for global ancestry inference
# File will include all Harpur 2014 files (except Cerana individual) (n=30)
# All Kenya files (n=6)
# and All admixed CA bees (n=51 wild samples and n=6 domestic)
# I will use two types of quality filtering minimum thresholds:
# 1) Minimum of base quality score from sequencing and base alignment quality score from noise around indels (Li 2011 "Improving SNP discovery by base alignment quality"
# 2) Mapping quality score which accounts for read mapping uniqueness (Li 2008)
# 13 and 30 (too conservative on mapQ?) may be standard thresholds or defaults, but I will first look at the distribution of quality to see if it's bimodal with a logical cuttoff.
# Pulled out a subset of reads randomly across the sequenced genomes for quality checking: (where -s .00001 specifies subset to .00001 proportion aligned reads and $5 fifth column is MAPQ
for i in *.sorted.bam; do samtools view -s .00001 $i | awk -F "\t" '{print $5}' > ../alignment_stats/${i}.mapq; done
# very slow to use angst to get a file with different quality scores for whole genome (even just 1 file):
angsd -out out_file -doCounts 1 -doQsDist 1 -bam bam.filelist
# Theoretically a mapq=20 indicates less than .01 false mapping and mapq=10 is less than .1 etc. but the scores aren't very reliable: 
# see - https://academic.oup.com/bioinformatics/article/28/18/i349/249968
# For now, since nothing pops out in the distribution of mapping quality and phred sequencing quality is more interpretable, 
# I will use >=13 for both as the cutoff (.05% theoretically)
angsd -GL 1 -baq 1 -ref data/honeybee_genome/Amel_4.5_scaffolds.fa.bgz -doGlf 2 -doMajorMinor 1 -doMaf 3 -SNP_pval 1e-1 -minInd 9 
-minMapQ 13 -minQ 13 -nThreads 14 -out Bee_bam_include_GL -bam Bee_bam_include_NGSadmix.txt
# GenotypeLikelihood=1 is for SAMtools method (2 is GATK), BAQ=1 adjusts seq quality scores using the reference genome provided, 
# -doGenotypelikelihoodfile=2 is for beagle likelihood output format
# -doMajorMinor 1 infers major/minor allele from genotype likelihoods; then after this the major allele is assumed known and it calculates MAF 2 ways: 
# doMinorAlleleFreq=3=1+2 where 1 assumes inferred major/minor are known and 2 marginalizes over possible minor alleles
# To reduce computation, I conservatively exclude sites that are very unlikely polymorphic (SNP p-value > .1) or that have data for fewer than 9 individuals (~10% of the sample)

# NOTE: I accidentally wrote over my gzipped ref genome (can just re-download) using bgzip Amel_4.5_scaffolds.fa.gz which created Amel_4.5_scaffolds.fa.gz.gz 
# then I unzipped this file twice and bgzipped
gunzip -c Amel_4.5_scaffolds.fa.gz.gz | gunzip | bgzip > Amel_4.5_scaffolds.fa.bgz

# This initial run crashed, so I am trying again with smaller segments of the genome in parallel. I only include scaffolds associated with a bee chromosome and make a list from the reference genome.
bees/data/honeybee_genome$ zgrep "^>Group[0-9]" Amel_4.5_scaffolds.fa.bgz | sed 's:>::' > list_aligned_scaffolds.txt
# In addition to splitting up the files, I've decided to run it without any minimum cutoff filters for quality and just let that be incorporated in the SNP and genotype likelihoods
cat data/honeybee_genome/list_aligned_scaffolds.txt | parallel --noswap --joblog angsd_log_aligned_scaffolds.log --jobs 12 "angsd -GL 1 -baq 1 -ref data/honeybee_genome/Amel_4.5_scaffolds.fa.bgz -r {1} -doGlf 2 -doMajorMinor 1 -doMaf 3 -SNP_pval 1e-1 -minInd 9 -minMapQ 0 -minQ 0 -nThreads 2 -out data/geno_lik/GL_{1} -bam Bee_bam_include_NGSadmix.txt"
# This crashed I think due to libreoffice. I restarted and ran with nohup and also getting rid of awkward 'cat'
/bees$ nohup parallel --noswap --joblog angsd_log_aligned_scaffolds.log --jobs 14 
"angsd -GL 1 -baq 1 -ref data/honeybee_genome/Amel_4.5_scaffolds.fa.bgz -r {1} 
-doGlf 2 -doMajorMinor 1 -doMaf 3 -SNP_pval 1e-1 -minInd 9 -minMapQ 0 -minQ 0 
-nThreads 2 -out data/geno_lik/GL_{1} -bam Bee_bam_include_NGSadmix.txt" 
< data/honeybee_genome/list_aligned_scaffolds.txt &
[1] 5111

# Completed overnight - all the files were made. Then I concatenated the output files and get rid of multiple headers (headers start with "marker ind0 " etc).
while read i; do pv "GL_${i}.beagle.gz" >> GL_all.beagle.gz; done < ../honeybee_genome/list_aligned_scaffolds.txt
(zgrep '^marker' GL_Group1.1.beagle.gz && zgrep -v '^marker' GL_all.beagle.gz) | gzip >> GL_all2.beagle.gz 
# above, take header from file with just one, add it to the file, then take everything NOT (-v) header and add to the new file, pipe to gzip
while read i; do pv "GL_${i}.mafs.gz" >> GL_all.mafs.gz; done < ../honeybee_genome/list_aligned_scaffolds.txt

# NOTE: pv is just like cat but shows a progress bar

# To infer global ancestry of each individual, I run NGSadmix with K = 3 (A, C, M ancestries). NGSadmix does not use pre-assigned labels to identify source and admixed individuals.
# other parameters: P = 14 for processors/cores, minMaf = minimum minor allele freq to filter by, outfiles= prefix of output file
nohup NGSadmix -likes geno_lik/GL_all2.beagle.gz -K 3 -P 14 -seed 100 -minMaf .01 -outfiles out_all_NGSadmix &
[1] 32363
# This process aborted because scaffold 7.1 has an incomplete line at 7.1_10306
# This did not appear in the log from parallel as an error: angsd_log_aligned_scaffolds.log
# But this section of the nohup_parallel_scaffolds_to_beagle.out does skip [ALL DONE]
less +14280 nohup_parallel_scaffolds_to_beagle.out 
# And the error in the file can be seen here:
zgrep "^Group7.1_10306" data/geno_lik/GL_Group7.1.beagle.gz
# or by using zgrep for "^Group7.1_10306" on GL_all2.beagle.gz or zgrep "Ind1" which shows this is the only messed up line
# I will save the corrupt file as a backup and re-run just scaffold Group7.1:
nohup angsd -GL 1 -baq q -ref data/honeybee_genome/Amel_4.5_scaffolds.fa.bgz -r Group7.1
-doGlf 2 -doMajorMinor 1 -doMaf 3 -SNP_pval 1e-1 -minInd 9 -minMapQ 0 -minQ 0
-nThreads 2 -out data/geno_lik/GL_Group7.1 -bam Bee_bam_include_NGSadmix.txt &
[1] 24103

# checked the file -- looks good -- repeated the merge to rerun NGSadmix
while read i; do pv "GL_${i}.beagle.gz" >> GL_all_temp.beagle.gz; done < ../honeybee_genome/list_aligned_scaffolds.txt; 
(zgrep '^marker' GL_Group1.1.beagle.gz && zgrep -v '^marker' GL_all_temp.beagle.gz) | gzip >> GL_all.beagle.gz

# run NGSadmix
nohup NGSadmix -likes geno_lik/GL_all.beagle.gz -K 3 -P 14 -seed 100 -minMaf .01 -outfiles out_all_NGSadmix &
[1] 26027
# 1pm Tuesday Nov 21 2017

# Formatting input files for Corbett-Detig HMM.
# First I need a VCF file with sites I'd like to include, 
# which I make using variants in the ref. panels only: List_AMC_bam_for_vcf.txt
# 5pm Thursday Dec 01 2017
# re-run with updated samtools v1.6, filtering non-variants, indels, and low quality sites:
nohup parallel --noswap --joblog make_AMC_vcf.log --jobs 15 "samtools mpileup 
-f data/honeybee_genome/Amel_4.5_scaffolds.fa -b List_AMC_bam_for_vcf.txt -r {1} -q 13 -Q 13 -I -u | 
bcftools call -v -Ob -m -V indels -o data/AMC_bcf/{1}.bcf" < data/honeybee_genome/list_aligned_scaffolds.txt &
[1] 13274
# make temporary uncompressed vcf files
parallel "bcftools view {} > ../AMC_vcf/{.}.vcf" ::: *

# Then I use these VCF files and GATK to get read counts for Ref/Alt alleles for
# 1) each ancestral reference population
# 2) each admixed individual
# note that GATK does some read filters by default, including removing duplicate reads (reduces PCR bias)
# Reran -- would not originally run because reference sequence needs to be type .fasta or .fa
# New format -- key is subsetting so it uses the index (fast) and giving it a VCF with only variants (not sure why bcf2 format can't be read, but oh well)
# Start with reference bees A.list M.list and C.list where counts are for the whole population
mkdir data/counts
nohup parallel --noswap --joblog AMC_counts.log --jobs 14 "java -jar ~/Software/GATK/GenomeAnalysisTK.jar -R data/honeybee_genome/Amel_4.5_scaffolds.fa
-T ASEReadCounter --minMappingQuality 13 --minBaseQuality 13 --outputFormat CSV -L {1} -sites:VCF data/AMC_vcf/{1}.vcf
-o data/counts/{2}_counts_{1}.csv -I {2}.list" :::: data/honeybee_genome/list_aligned_scaffolds.txt ::: A M C &> nohup_AMC_counts.out
# found the ones that didn't run properly and reran. unfortunately wrote over log, but nohup_AMC confirms those were only errors
cat AMC_counts.log | awk '$7==1'
(same command w/ parallel) ::: Group10.14 Group7.15 ::: M C &> nohup_MC_exit1_counts.out 
##### ERROR MESSAGE: Problem detecting index type
# didn't work, so deleted indexfile .vcf.idx from AMC_vcf then re-ran A M and C
(same command w/ parallel) ::: Group10.14 Group7.15 ::: A M C &> nohup_AMC_exit1_counts.out
# fixed!

# next priority is read counts for individual admixed bees from CA data:
# ERROR b/c needed to add read group to header, so did this first. first created list of bam file names
parallel "cd data/CA_Bee/bam_files/ && ls {1}.*.bam" >> CA_admit :::: CA_admix.list
# then used picard to add a readgroup header and saved new bams
nohup parallel --noswap --jobs 6 --joblog CA_Bees_add_RG_header.log "java -jar ~/Software/picard/picard.jar AddOrReplaceReadGroups
I=data/CA_Bee/bam_files/{1} O=data/CA_Bee/bam_files_with_RG/{1} RGID=null RGLB=CA_Bees RGPL=illumina RGPU=NA RGSM={1}" :::: CA_admix.txt &> CA_Bees_add_RG_header.out
# lastly, indexed new bam files with samtools
data/CA_Bee/bam_files_with_RG$ parallel samtools index {1} {1}.bai ::: *.bam

# now run counts for admixed individuals in CA
nohup parallel --noswap --joblog CA_admix_counts.log --jobs 6 
"java -jar ~/Software/GATK/GenomeAnalysisTK.jar -R data/honeybee_genome/Amel_4.5_scaffolds.fa -T ASEReadCounter  
--minMappingQuality 13 --minBaseQuality 13 --outputFormat CSV -L {1} -sites:VCF data/AMC_vcf/{1}.vcf 
-o data/counts/admix/{2}_counts_{1}.csv -I data/CA_Bee/bam_files_with_RG/{2}.*.bam" 
:::: data/honeybee_genome/list_aligned_scaffolds.txt :::: CA_admix.list &> nohup_CA_admix_counts.out
# CA_admix.list includes bees from Placerita_2014 Riverside_2014 Riverside_1999 SanPedro_2002 CA_Other_2014 (1 africanized bee each from Stebbins Stanislaus and Avalon based on NGSAdmix)
e.g. grep Riverside List_CA_bees_include.txt | grep 1999 | cut -f1 > Riverside_1999.list to make list of relevant bees

# To infer local ancestry along the chromosome for each individual, I will run the HMM from Corbett-Detig and Nielsen 
# But to do this, I need recombination positions for all SNPs included. The recombination map Liu 2015 sticks all scaffolds together, skipping gaps of unknown size
# Since I just have relative position to the scaffold, I need to first get the length of each scaffold to get rel. pos. to LG
# Luckily, I can use the fact that all lines in the reference genome are lists of covered gaps and genotypes (NNATTTTTAACAGNNAAAATTT) equally spaced
# So all I need to know is the number of lines and the length of the last line. Note the scaffolds are listed in a weird order 1.10 after 1.1
gunzip < Amel_4.5_scaffolds.fa.bgz | grep "^>Group[0-9]" -B1 >> last_line_prev.txt
gunzip < Amel_4.5_scaffolds.fa.bgz | grep "^>Group[0-9]" -n >> start_line_n.txt
# To get the length of the last listed scaffold, I look for the first GroupUn (scaffold not used because unmapped)

# Note that the scaffolds are not strictly listed in order in the reference, going 1, 10, 11 ... 2, 21, 22 etc.
echo -- >> last_line_prev.txt
gunzip < Amel_4.5_scaffolds.fa.bgz | grep "^>GroupUn" -B1 | head -2 >> last_line_prev.txt
gunzip < Amel_4.5_scaffolds.fa.bgz | grep "^>GroupUn" -n | head -1 >> start_line_n.txt
# Next I used recomb_map.R to put these together and get lengths and starting positions of concatenated scaffolds.
# For now I add gaps that divide equally the difference between the sequenced length (including spanned short NNNN gaps)
# and the total chromosome length reported by NCBI in ncbi_genome4.5_scaffold_stats.csv 
# data source: https://www.ncbi.nlm.nih.gov/assembly/GCF_000002195.4/#/st_Primary-Assembly


# I can see if it's sensitive to running all CA bees together in 1 population or separately by location/date (T may differ sig.)
# I will use the same quality filtering thresholds as above for this analysis.
# made new vcf files using samtools v1.6, downloaded 12/1/2017 because of filetype incompatibilty issues with bcf2 files from samtools v1.1 and GATK causing 'magic number missing' errors

# Prepare reference genome: 1) unzip genome to fasta format 2) download picard and use to create a dictionary 3) index with samtools
gunzip Amel_4.5_scaffolds.fa.gz.gz
gunzip Amel_4.5_scaffolds.fa.gz
java -jar ~/Software/picard/picard.jar CreateSequenceDictionary R= Amel_4.5_scaffolds.fa O= Amel_4.5_scaffolds.dict
samtools faidx Amel_4.5_scaffolds.fa # re-indexed dec 1 2017 with samtools v1.6
# run GATK to get read counts for reads that pass filtering

#small test example works well
java -jar ~/Software/GATK/GenomeAnalysisTK.jar -R data/honeybee_genome/Amel_4.5_scaffolds.fa -T ASEReadCounter --minMappingQuality 13 --minBaseQuality 13 
--outputFormat CSV -L Group1.11 -sites:VCF short_test.vcf -o M_counts_short_test2.csv -I data/Harpur_2014_NCBI/bam_files/Harpur_SRR957058.sorted.bam
# Above, Group1.11 will be replaced with {1} and M_counts.csv and a whole list of files -I and short_test.vcf with the path to the {1} group's vcf file

# Calling ancestry using called genotypes (with > .6 posterior probability)
# Making strictly called genotype files:
# Two different types "AC AT AA" etc. and -1, 0, 1, 2 . Posterior probability cutoff using GL method 1 and prior = allele freq
nohup parallel --noswap --joblog angsd_geno_AC.log --jobs 10 "angsd -GL 1 -baq 1 -ref data/honeybee_genome/Amel_4.5_scaffolds.fa.bgz -r {1} -doMajorMinor 1 -doMaf 3 -SNP_pval 1e-3 -minInd 9 -minMapQ 0 -minQ 0 -nThreads 2 -doGeno 4 -doPost 1 -postCutoff 0.6 -out data/geno_AC/geno_AC_{1} -bam Bee_bam_include_geno_AC_12.txt" < data/honeybee_genome/list_aligned_scaffolds.txt; parallel --noswap --joblog angsd_geno_12.log --jobs 10 "angsd -GL 1 -baq 1 -ref data/honeybee_genome/Amel_4.5_scaffolds.fa.bgz -r {1} -doMajorMinor 1 -doMaf 3 -SNP_pval 1e-3 -minInd 9 -minMapQ 0 -minQ 0 -nThreads 2 -doGeno 19 -doPost 1 -postCutoff 0.6 -out data/geno_12/geno_12_{1} -bam Bee_bam_include_geno_AC_12.txt" < data/honeybee_genome/list_aligned_scaffolds.txt &

# For the AC AT AA file types I will format them to run in ELAI using r
# First I concatenate all data within a chromosome together (note out of order is okay 1, 11, 12 etc)
data/geno_AC$ for i in {1..16}; do zcat geno_AC_Group${i}.*.geno.gz >> All/All_AC_${i}.geno; done

# I created position files that just use a chromosome average rate
# later I will get better genetic map positions, but this will do for now
# For speed I exclude snps with very low frequency because they tend to have low ancestry information (here maf<0.05 in complete sample)
# ELAI can use dense snps but for other programs I will need to thin snps further
# Now I run ELAI on all 16 chromosomes for 3 different generations since admixture (15, 30, 50), always same random seed (R=1)
nohup parallel --noswap --joblog ELAI_all_chr_avgr.log --jobs 12 
'elai-lin -g chr{1}/A.txt -p 10 -g chr{1}/C.txt -p 11 -g chr{1}/M.txt -p 12 -g chr{1}/Plac_Riv_2014.txt -p 1 -pos chr{1}/pos.txt 
-s 20 -C 3 -c 9 -mg {2} -o out_chr{1} --exclude-nopos --exclude-miss1 -exclude-maf 0.05 -R 1'
::: {1..16} ::: 15 30 55 &

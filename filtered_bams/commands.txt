# command log and scripts to take raw reads, map to reference, and filter to produce filtered bam files

# I will follow the same process from .fq raw reads to .bam mappped reads using bowtie2
# and filtering (e.g. of duplicates) using picard tools as is described in bioinfo_pipe.txt
# for the reference panel bee genomes (and earlier CA bees) downloaded as .fq files from NCBI

# First sequencing run from Novogene completed 12/12/18, dowloaded from ftp using FileZilla (interactive) 12/18/18
# and saved in data/novo_seq/C202SC18101772/. Backups saved to linux on Willowbank and Box.com on cloud.
# Check MD5 that everything downloaded properly (all good!):
# bees/data/novo_seq/C202SC18101772/raw_data$ cat */MD5.txt > ALL_MD5_expected.txt # expected md5 values
# raw_data$ for i in $(awk '{print $2}' ALL_MD5_expected.txt); do md5 */${i} | awk '{print $4}'; done > ALL_MD5_observed.txt # observed md5 values for each .fq file
# raw_data$ diff -q <(awk '{print $1}' ALL_MD5_expected.txt) <(cat ALL_md5_observed.txt) # outputs 'Files * and * differ' if they differ; outputs nothing if they're the same. Take away -q to see differences.
# checking data on barbara:
# raw_data$ for i in $(awk '{print $2}' ALL_MD5_expected.txt); do md5sum */${i}; done > ALL_MD5_observed_barbara_1.18.19.txt # observed md5 values for each .fq file
# check ALL_MD5_observed_barbara_1.18.19.txt against expected checksums:
# raw_data$ diff -q <(awk '{print $1}' ALL_MD5_expected.txt) <(awk '{print $1}' ALL_MD5_observed_barbara_1.18.19.txt) # outputs 'Files * and * differ' if they differ; outputs nothing if they're the same. Take away -q to see differences. # ALL GOOD!


# Re-downloaded honeybee genome Apis mellifera v4.5 from beebase.org on 12.19.18: data/honeybee_genome/Amel_4.5_scaffolds.fa (note: wasn't .fa.gz)

# Also downloaded Bowtie2 for macs: v2.3.3.1 to match what I used on the Linux machine previously. Downloaded 12.19.18
# re-indexed v4.5 genome from www.beebase.org (it's not gzipped the genome I downloaded)
bees/data/honeybee_genome$ bowtie2-build Amel_4.5_scaffolds.fa honeybee_Amel_4.5

# made a short script that maps reads for new bees just sequenced: map_reads.sh
# to run alignment in bulk, I first made a list of sample IDs sequenced in this batch C202SC18101772:
data/novo_seq$ awk '{print $5}' seq1_novogene_index_i7_bee_id_link.txt | tail -n +2 > C202SC18101772/samples.list
scripts$ nohup parallel --noswap --joblog ../logs/map_reads_C202SC18101772.log --jobs 4 \
./map_reads.sh {1} C202SC18101772 :::: ../data/novo_seq/C202SC18101772/samples.list &> ../logs/map_reads_C202SC18101772.out &
[1] 72328 - RUNNING 12.19.18 - DONE (some cancelled because already completed on other computer)
data/novo_seq/C202SC18101772$ tac samples.list > samples_reversed_order.list
scripts$ nohup parallel --noswap --joblog ../logs/map_reads_C202SC18101772_reversed_order.log --jobs 8 \
./map_reads.sh {1} C202SC18101772 :::: ../data/novo_seq/C202SC18101772/samples_reversed_order.list &> ../logs/map_reads_C202SC18101772_reversed_order.out &
[1] 7754 - RUNNING 12.19.18 on Barbara - cancelled due to memory. Now rerunning:
[didn't print new number/overwritten by nano, but it's running] - DONE; I cancelled last few when every bam was finished on one computer. Moved bams to Nancy's comp.
# some bams were completed by both computers and I noticed very small discrepancies in # lines per file (diff. of ~5-30 lines out of thousands)
# bowtie2 is the same version 2.3.3.1 and random seed is the same (2014) so this must be a small remaining stochasticity affected by compiling the program on mac vs. Ubuntu.
# for those bams with duplicated efforts I used the ones run on the mac going forward.
# Now filtering bams with new scripts sort_bams.sh and dedup_baq_bams.sh
scripts$ nohup parallel --noswap --joblog ../logs/filter_bams_C202SC18101772.log --jobs 4 \
'./sort_bams.sh {1} novo_seq/bam_files; ./dedup_baq_bams.sh {1} filtered_bams/results' \
:::: ../data/novo_seq/C202SC18101772/samples.list &> ../logs/filter_bams_C202SC18101772.out &
[1] 27043 -- typo, try again:
[1] 29784 -- needed to source ~/.profile to get variable $PICARD
[1] 31078 -- failed due to typo in file naming
[2] 31767 -RUNNING 12.20.18 19:15

# Now I am re-mapping all reference samples from Harpur 2014:
Harpur_2014_NCBI$ cat bam_files_old/IDs.list | cut -d'_' -f2 > samples.list
scripts$ chmod u+x map_reads_single.sh
scripts$ nohup parallel --noswap --joblog ../logs/map_reads_Harpur_2014_NCBI.log --jobs 4 \
./map_reads_single.sh {1} Harpur_2014_NCBI :::: ../data/Harpur_2014_NCBI/samples.list \
&> ../logs/map_reads_Harpur_2014_NCBI.out &
[1] 32424 - RUNNING 12.20.18 10:30. Reran ones that didn't go:
First 4 ran without issues, but then I moved the mapping script and they failed, so rerunning those:
filtered_bams$ nohup parallel --noswap --joblog ../logs/map_reads_Harpur_2014_NCBI_2.log --jobs 4 ./map_reads_single.sh {1} Harpur_2014_NCBI \
::: $(tail -n +5 ../data/Harpur_2014_NCBI/samples.list) &> ../logs/map_reads_Harpur_2014_NCBI_2.out &
[1] 14980 - RUNNING 12.21.18 # COMPLETED ALL DONE

# run sort_bams.sh and dedup_baq_bams.sh on 'original' bams from CA_Bees
# (note inconsistent in CA_Bee/bam_from_Julie naming with *.merged.bam or *.combined.bam)
# first made symlinks to bams for consistent naming on CA_Bee
CA_Bee/bam_files$ for i in $(cat ../samples.list); do ln -s ../bam_from_Julie/$i.*.bam $i.bam; done
# then run filtering steps on CA_Bee bams
bees/filtered_bams$ nohup parallel --noswap --joblog ../logs/filter_bams_CA_Bee.log --jobs 4 './sort_bams.sh {1} ../data/CA_Bee/bam_files; ./dedup_baq_bams.sh {1} filtered_bams/results' :::: ../data/CA_Bee/samples.list &> ../logs/filter_bams_CA_Bee.out &
[1] 6017 -- fixed some typos in directory, memory and PICARD variable
# make logs directory, then run:
bees/filtered_bams$ mkdir logs
bees/filtered_bams$ nohup parallel --noswap --joblog logs/filter_bams_CA_Bee.log --jobs 4 './sort_bams.sh {1} ../data/CA_Bee/bam_files; ./dedup_baq_bams.sh {1} results' :::: ../data/CA_Bee/samples.list &> logs/filter_bams_CA_Bee.out &
[1] 28013 - Low memory & wrong path to reference genome. Maxed all memory to 6G and trying again with 3 threads:
bees/filtered_bams$ nohup parallel --noswap --joblog logs/filter_bams_CA_Bee.log --jobs 3 './sort_bams.sh {1} ../data/CA_Bee/bam_files; ./dedup_baq_bams.sh {1} results' :::: ../data/CA_Bee/samples.list &> logs/filter_bams_CA_Bee.out &
[1] 31247 - RUNNING SUCCESSFULLY 12.27.18 -- ap29, ap30 and ap31 will need to be rerun (modified script while running for general case when input isn't from results/ folder)
bees/filtered_bams$ nohup bash -c "until (( $(wc -l < logs/dedup_bams_Kenya_Sheppard_NCBI.log) == 7 )); do sleep 100; done; echo "done waiting for dedup_bams_Kenya_Sheppard_NCBI to finish. Now running bam filtering for 3 CA_Bees that failed previously:"; parallel --noswap --joblog logs/filter_bams_CA_Bee_2.log --jobs 2 'echo "filtering bam for bee: " {1}; ./sort_bams.sh {1} ../data/CA_Bee/bam_files; ./dedup_baq_bams.sh {1} results' :::: ap29 ap30 ap31 &> logs/filter_bams_CA_Bee_2.out" &
[3] 862 - WAITING on other file's output - KILLED (low memory; other job didn't finish)
RERUNNING THOSE THAT CRASHED FROM LACK OF MEMORY; removing intermediate file .sort.bam as each one completes deduping:
bees/filtered_bams$ nohup parallel --noswap --joblog logs/filter_bams_CA_Bee_rerun2.log --jobs 2 './sort_bams.sh {1} ../data/CA_Bee/bam_files; ./dedup_baq_bams.sh {1} results; rm results/{1}.sort.bam' :::: logs/CA_Bee_samples_rerun2.list &> logs/filter_bams_CA_Bee_rerun2.out &
[1] 10206 - COMPLETE 1.2.19
# add readgroup IDs to CA_Bees filtered bams ..others already have this from when I mapped with bowtie2
bees/filtered_bams$ nohup parallel --noswap --delay 3 --jobs 4 --joblog logs/add_RG_CA_Bee.log \
'./add_readgroup_2_bams.sh {1} CA_Bee results' :::: ../data/CA_Bee/samples.list \
&> logs/add_RG_CA_Bee.out &
[2] 14531 - COMPLETE 1.2.19 (note: deleted I intermediate bams for space)

# run dedup_baq_bams.sh on Kenyan bees --> also put in folder filtered_bams/results
# note: these have already been mapped and sorted, just need to be deduped (I did not delete intermediate sorted file from last time)
bees/data/Kenya_Sheppard_NCBI/bam_files$ cat IDs.list | cut -d'_' -f2 > ../samples.list
bees/filtered_bams$ nohup parallel --noswap --joblog logs/dedup_bams_Kenya_Sheppard_NCBI.log --jobs 2 './dedup_baq_bams.sh {1} ../data/Kenya_Sheppard_NCBI/bam_files' :::: ../data/Kenya_Sheppard_NCBI/samples.list &> logs/dedup_bams_Kenya_Sheppard_NCBI.out &
[1] 32097 - fixed typo messing up runs where dir in is not results/:
[1] 32303 - COMPLETED 12.27.18. I had to delete intermediate sorted bams for space.

# run filtering steps on Harpur bees --> put all in one consistent folder in filtered_bams/results
bees/filtered_bams$ nohup bash -c "until (( $(wc -l < logs/filter_bams_CA_Bee.log) == 76 )); do sleep 100; done; echo "done waiting for filter_bams_CA_Bee to finish. Starting Harpur_2014_NCBI bam filtering:"; parallel --noswap --joblog logs/filter_bams_Harpur_2014_NCBI.log --jobs 5 --delay 3 'echo "now filtering bam for bee ID: " {1}; ./sort_bams.sh {1} ../data/Harpur_2014_NCBI/bam_files; ./dedup_baq_bams.sh {1} results' :::: ../data/Harpur_2014_NCBI/samples.list &> logs/filter_bams_Harpur_2014_NCBI.out" &
[2] 854 - WAITING on other file's output - KILLED (low memory; other job didn't finish) .. just running 1 job at a time:
bees/filtered_bams$ nohup parallel --noswap --joblog logs/filter_bams_Harpur_2014_NCBI.log --jobs 1 './sort_bams.sh {1} ../data/Harpur_2014_NCBI/bam_files; ./dedup_baq_bams.sh {1} results; rm results/{1}.sort.bam' :::: ../data/Harpur_2014_NCBI/samples.list &> logs/filter_bams_Harpur_2014_NCBI.out &
[2] 11441 - COMPLETE 1.2.19. Deleted intermediate bams to save space (e.g. data/Harpur_2014_NCBI/bam_files/SRR957058.bam)
# would run more in parallel except one other job w/ 2 threads is running at the same time and $ free -m says I have < 6G RAM available, which is what I've maxed picard and samtools to.


# Quick calculation of coverage for pass1 individuals: (~3minutes)
bees/filtered_bams$ angsd -bam ../bee_samples_listed/pass1.bams -doDepth 1 -out results/depth/Group1.1 \
-doCounts 1 -r Group1.1: -minMapQ 30 -minQ 20 -remove_bads 1 -maxDepth 10000
# Note: doesn't appear to count zero-depth spots
# used R to calculate mean depth for this single (large) scaffold to set .5x and 2x approximate cutoffs for angsd GL
plot_bam_metrics.R # (starting with approximation from scaffold Group1.1 only, cutoffs are 865x and 3462x)

# Getting actual depth per chromosome:
# First list scaffolds within each chromosome (and group Un for scaffolds without a chromosome assignment)
bees/data/honeybee_genome$ for i in {1..16} Un; do grep Group$i\. ordered_scaffolds.list > ordered_scaffolds.Group$i.list; done
bees/filtered_bams$ nohup parallel --noswap --joblog logs/depth_by_chr.log --jobs 2 \
'angsd -bam ../bee_samples_listed/pass1.bams -doDepth 1 -out results/depth/Group{1} \
-doCounts 1 -rf ../data/honeybee_genome/ordered_scaffolds.Group{1}.list -minMapQ 30 -minQ 20 \
-remove_bads 1 -maxDepth 20000' ::: {1..16} Un &> logs/depth_by_chr.out &
[1] 13236 - RUNNING 1.7.19

# extracting mapping metrics, including percent read duplication (e.g. PCR duplicates):
# counting # reads pre-filtering, and at de-duplication using PICARD metrics.txt output files
# (to compare effects of filtering across groups/individuals):
bees/filtered_bams/metrics$ grep 'LIBRARY' $(head -n 1 ../../bee_samples_listed/pass1.list).metrics.txt | \
awk '{print "StudyID\t"$0}' > pass1.all.metrics.raw.Nreads; \
for i in $(cat ../../bee_samples_listed/pass1.list); do grep 'Unknown Library' "$i.metrics.txt" | \
awk -v i="$i" '{print i"\t"$0}' >> pass1.all.metrics.raw.Nreads; done

# get the total number of reads, and total # mapped (any quality) AFTER removing duplicates:
# I don't actually filter for Q30 (or even unmapped); wanted to leave options open.
# first count reads using samtools flagstat:
bees/filtered_bams$ nohup parallel --noswap --joblog logs/run_flagstat.log --jobs 4 \
'samtools flagstat results/{1}.sort.dedup.baq.bam > metrics/{1}.flagstat.txt' \
:::: ../bee_samples_listed/pass1.list &> logs/run_flagstat.out &
[2] 15291 - COMPLETE 1.8.19
extract from flagstat metrics the number of reads in final filtered (no duplicates) bams:
bees/filtered_bams/metrics$ for i in $(cat ../../bee_samples_listed/pass1.list); \
do echo $i$'\t'$(cat $i.flagstat.txt | grep 'total' | cut -d' ' -f1); \
done > pass1.all.metrics.dedup.total.Nreads
bees/filtered_bams/metrics$ for i in $(cat ../../bee_samples_listed/pass1.list); \
do echo $i$'\t'$(cat $i.flagstat.txt | grep '+ 0 mapped (' | cut -d' ' -f1); \
done > pass1.all.metrics.dedup.mapped.Nreads


# TO DO:
# Use FastQ screen to assess why some samples have high % unmapped reads -- do I have contamination? FastQ screen attempts to map reads to multiple references of your choice, e.g. honeybee, human, PhiX, E. coli, adapter sequences, Vectors
# Download and map reads from Wallberg 2014 for A/C/M/O populations using pipeline for SOLiD data 
# deduplicate and run BAQ for Wallberg 2014 bees
# note: best to put more general scripts, that will be used in multiple analyses, when that comes up, in a scripts/ folder

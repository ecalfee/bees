# command log and scripts to take raw reads, map to reference, and filter to produce filtered bam files

# I will follow the same process from .fq raw reads to .bam mappped reads using bowtie2
# and filtering (e.g. of duplicates) using picard tools as is described in bioinfo_pipe.txt
# for the reference panel bee genomes (and earlier CA bees) downloaded as .fq files from NCBI

# First sequencing run from Novogene completed 12/12/18, dowloaded from ftp using FileZilla (interactive) 12/18/18
# and saved in data/novo_seq/C202SC18101772/. Backups saved to linux on Willowbank and Box.com on cloud.
# Check MD5 that everything downloaded properly (all good!):
# bees/data/novo_seq/C202SC18101772/raw_data$ cat */MD5.txt > ALL_MD5_expected.txt # expected md5 values
# raw_data$ for i in $(awk '{print $2}' ALL_MD5_expected.txt); do md5 */${i} | awk '{print $4}'; done > ALL_MD5_observed.txt # observed md5 values for each .fq file
# raw_data$ diff -q <(awk '{print $1}' ALL_MD5_expected.txt) <(cat ALL_md5_observed.txt) # outputs 'Files * and * differ' if they differ; outputs nothing if they're the same. Take away -q to see differences.
# checking data on barbara:
# raw_data$ for i in $(awk '{print $2}' ALL_MD5_expected.txt); do md5sum */${i}; done > ALL_MD5_observed_barbara_1.18.19.txt # observed md5 values for each .fq file
# check ALL_MD5_observed_barbara_1.18.19.txt against expected checksums:
# raw_data$ diff -q <(awk '{print $1}' ALL_MD5_expected.txt) <(awk '{print $1}' ALL_MD5_observed_barbara_1.18.19.txt) # outputs 'Files * and * differ' if they differ; outputs nothing if they're the same. Take away -q to see differences. # ALL GOOD!


# Re-downloaded honeybee genome Apis mellifera v4.5 from beebase.org on 12.19.18: data/honeybee_genome/Amel_4.5_scaffolds.fa (note: wasn't .fa.gz)

# Also downloaded Bowtie2 for macs: v2.3.3.1 to match what I used on the Linux machine previously. Downloaded 12.19.18
# re-indexed v4.5 genome from www.beebase.org (it's not gzipped the genome I downloaded)
bees/data/honeybee_genome$ bowtie2-build Amel_4.5_scaffolds.fa honeybee_Amel_4.5

# made a short script that maps reads for new bees just sequenced: map_reads.sh
# to run alignment in bulk, I first made a list of sample IDs sequenced in this batch C202SC18101772:
data/novo_seq$ awk '{print $5}' seq1_novogene_index_i7_bee_id_link.txt | tail -n +2 > C202SC18101772/samples.list
scripts$ nohup parallel --noswap --joblog ../logs/map_reads_C202SC18101772.log --jobs 4 \
./map_reads.sh {1} C202SC18101772 :::: ../data/novo_seq/C202SC18101772/samples.list &> ../logs/map_reads_C202SC18101772.out &
[1] 72328 - RUNNING 12.19.18 - DONE (some cancelled because already completed on other computer)
data/novo_seq/C202SC18101772$ tac samples.list > samples_reversed_order.list
scripts$ nohup parallel --noswap --joblog ../logs/map_reads_C202SC18101772_reversed_order.log --jobs 8 \
./map_reads.sh {1} C202SC18101772 :::: ../data/novo_seq/C202SC18101772/samples_reversed_order.list &> ../logs/map_reads_C202SC18101772_reversed_order.out &
[1] 7754 - RUNNING 12.19.18 on Barbara - cancelled due to memory. Now rerunning:
[didn't print new number/overwritten by nano, but it's running] - DONE; I cancelled last few when every bam was finished on one computer. Moved bams to Nancy's comp.
# some bams were completed by both computers and I noticed very small discrepancies in # lines per file (diff. of ~5-30 lines out of thousands)
# bowtie2 is the same version 2.3.3.1 and random seed is the same (2014) so this must be a small remaining stochasticity affected by compiling the program on mac vs. Ubuntu.
# for those bams with duplicated efforts I used the ones run on the mac going forward.
# Now filtering bams with new scripts sort_bams.sh and dedup_baq_bams.sh
scripts$ nohup parallel --noswap --joblog ../logs/filter_bams_C202SC18101772.log --jobs 4 \
'./sort_bams.sh {1} novo_seq/bam_files; ./dedup_baq_bams.sh {1} filtered_bams/results' \
:::: ../data/novo_seq/C202SC18101772/samples.list &> ../logs/filter_bams_C202SC18101772.out &
[1] 27043 -- typo, try again:
[1] 29784 -- needed to source ~/.profile to get variable $PICARD
[1] 31078 -- failed due to typo in file naming
[2] 31767 -RUNNING 12.20.18 19:15

# Now I am re-mapping all reference samples from Harpur 2014:
Harpur_2014_NCBI$ cat bam_files_old/IDs.list | cut -d'_' -f2 > samples.list
scripts$ chmod u+x map_reads_single.sh
scripts$ nohup parallel --noswap --joblog ../logs/map_reads_Harpur_2014_NCBI.log --jobs 4 \
./map_reads_single.sh {1} Harpur_2014_NCBI :::: ../data/Harpur_2014_NCBI/samples.list \
&> ../logs/map_reads_Harpur_2014_NCBI.out &
[1] 32424 - RUNNING 12.20.18 10:30. Reran ones that didn't go:
First 4 ran without issues, but then I moved the mapping script and they failed, so rerunning those:
filtered_bams$ nohup parallel --noswap --joblog ../logs/map_reads_Harpur_2014_NCBI_2.log --jobs 4 ./map_reads_single.sh {1} Harpur_2014_NCBI \
::: $(tail -n +5 ../data/Harpur_2014_NCBI/samples.list) &> ../logs/map_reads_Harpur_2014_NCBI_2.out &
[1] 14980 - RUNNING 12.21.18 # COMPLETED ALL DONE

# run sort_bams.sh and dedup_baq_bams.sh on 'original' bams from CA_Bees
# (note inconsistent in CA_Bee/bam_from_Julie naming with *.merged.bam or *.combined.bam)
# first made symlinks to bams for consistent naming on CA_Bee
CA_Bee/bam_files$ for i in $(cat ../samples.list); do ln -s ../bam_from_Julie/$i.*.bam $i.bam; done
# then run filtering steps on CA_Bee bams
bees/filtered_bams$ nohup parallel --noswap --joblog ../logs/filter_bams_CA_Bee.log --jobs 4 './sort_bams.sh {1} ../data/CA_Bee/bam_files; ./dedup_baq_bams.sh {1} filtered_bams/results' :::: ../data/CA_Bee/samples.list &> ../logs/filter_bams_CA_Bee.out &
[1] 6017 -- fixed some typos in directory, memory and PICARD variable
# make logs directory, then run:
bees/filtered_bams$ mkdir logs
bees/filtered_bams$ nohup parallel --noswap --joblog logs/filter_bams_CA_Bee.log --jobs 4 './sort_bams.sh {1} ../data/CA_Bee/bam_files; ./dedup_baq_bams.sh {1} results' :::: ../data/CA_Bee/samples.list &> logs/filter_bams_CA_Bee.out &
[1] 28013 - Low memory & wrong path to reference genome. Maxed all memory to 6G and trying again with 3 threads:
bees/filtered_bams$ nohup parallel --noswap --joblog logs/filter_bams_CA_Bee.log --jobs 3 './sort_bams.sh {1} ../data/CA_Bee/bam_files; ./dedup_baq_bams.sh {1} results' :::: ../data/CA_Bee/samples.list &> logs/filter_bams_CA_Bee.out &
[1] 31247 - RUNNING SUCCESSFULLY 12.27.18 -- ap29, ap30 and ap31 will need to be rerun (modified script while running for general case when input isn't from results/ folder)
bees/filtered_bams$ nohup bash -c "until (( $(wc -l < logs/dedup_bams_Kenya_Sheppard_NCBI.log) == 7 )); do sleep 100; done; echo "done waiting for dedup_bams_Kenya_Sheppard_NCBI to finish. Now running bam filtering for 3 CA_Bees that failed previously:"; parallel --noswap --joblog logs/filter_bams_CA_Bee_2.log --jobs 2 'echo "filtering bam for bee: " {1}; ./sort_bams.sh {1} ../data/CA_Bee/bam_files; ./dedup_baq_bams.sh {1} results' :::: ap29 ap30 ap31 &> logs/filter_bams_CA_Bee_2.out" &
[3] 862 - WAITING on other file's output - KILLED (low memory; other job didn't finish)
RERUNNING THOSE THAT CRASHED FROM LACK OF MEMORY; removing intermediate file .sort.bam as each one completes deduping:
bees/filtered_bams$ nohup parallel --noswap --joblog logs/filter_bams_CA_Bee_rerun2.log --jobs 2 './sort_bams.sh {1} ../data/CA_Bee/bam_files; ./dedup_baq_bams.sh {1} results; rm results/{1}.sort.bam' :::: logs/CA_Bee_samples_rerun2.list &> logs/filter_bams_CA_Bee_rerun2.out &
[1] 10206 - COMPLETE 1.2.19
# add readgroup IDs to CA_Bees filtered bams ..others already have this from when I mapped with bowtie2
bees/filtered_bams$ nohup parallel --noswap --delay 3 --jobs 4 --joblog logs/add_RG_CA_Bee.log \
'./add_readgroup_2_bams.sh {1} CA_Bee results' :::: ../data/CA_Bee/samples.list \
&> logs/add_RG_CA_Bee.out &
[2] 14531 - COMPLETE 1.2.19 (note: deleted I intermediate bams for space)

# run dedup_baq_bams.sh on Kenyan bees --> also put in folder filtered_bams/results
# note: these have already been mapped and sorted, just need to be deduped (I did not delete intermediate sorted file from last time)
bees/data/Kenya_Sheppard_NCBI/bam_files$ cat IDs.list | cut -d'_' -f2 > ../samples.list
bees/filtered_bams$ nohup parallel --noswap --joblog logs/dedup_bams_Kenya_Sheppard_NCBI.log --jobs 2 './dedup_baq_bams.sh {1} ../data/Kenya_Sheppard_NCBI/bam_files' :::: ../data/Kenya_Sheppard_NCBI/samples.list &> logs/dedup_bams_Kenya_Sheppard_NCBI.out &
[1] 32097 - fixed typo messing up runs where dir in is not results/:
[1] 32303 - COMPLETED 12.27.18. I had to delete intermediate sorted bams for space.

# run filtering steps on Harpur bees --> put all in one consistent folder in filtered_bams/results
bees/filtered_bams$ nohup bash -c "until (( $(wc -l < logs/filter_bams_CA_Bee.log) == 76 )); do sleep 100; done; echo "done waiting for filter_bams_CA_Bee to finish. Starting Harpur_2014_NCBI bam filtering:"; parallel --noswap --joblog logs/filter_bams_Harpur_2014_NCBI.log --jobs 5 --delay 3 'echo "now filtering bam for bee ID: " {1}; ./sort_bams.sh {1} ../data/Harpur_2014_NCBI/bam_files; ./dedup_baq_bams.sh {1} results' :::: ../data/Harpur_2014_NCBI/samples.list &> logs/filter_bams_Harpur_2014_NCBI.out" &
[2] 854 - WAITING on other file's output - KILLED (low memory; other job didn't finish) .. just running 1 job at a time:
bees/filtered_bams$ nohup parallel --noswap --joblog logs/filter_bams_Harpur_2014_NCBI.log --jobs 1 './sort_bams.sh {1} ../data/Harpur_2014_NCBI/bam_files; ./dedup_baq_bams.sh {1} results; rm results/{1}.sort.bam' :::: ../data/Harpur_2014_NCBI/samples.list &> logs/filter_bams_Harpur_2014_NCBI.out &
[2] 11441 - COMPLETE 1.2.19. Deleted intermediate bams to save space (e.g. data/Harpur_2014_NCBI/bam_files/SRR957058.bam)
# would run more in parallel except one other job w/ 2 threads is running at the same time and $ free -m says I have < 6G RAM available, which is what I've maxed picard and samtools to.


# Quick calculation of coverage for pass1 individuals: (~3minutes)
bees/filtered_bams$ angsd -bam ../bee_samples_listed/pass1.bams -doDepth 1 -out results/depth/Group1.1 \
-doCounts 1 -r Group1.1: -minMapQ 30 -minQ 20 -remove_bads 1 -maxDepth 10000
# Note: doesn't appear to count zero-depth spots
# used R to calculate mean depth for this single (large) scaffold to set .5x and 2x approximate cutoffs for angsd GL
plot_bam_metrics.R # (starting with approximation from scaffold Group1.1 only, cutoffs are 865x and 3462x)

# Getting actual depth per chromosome:
# First list scaffolds within each chromosome (and group Un for scaffolds without a chromosome assignment)
bees/data/honeybee_genome$ for i in {1..16} Un; do grep Group$i\. ordered_scaffolds.list > ordered_scaffolds.Group$i.list; done
bees/filtered_bams$ nohup parallel --noswap --joblog logs/depth_by_chr.log --jobs 2 \
'angsd -bam ../bee_samples_listed/pass1.bams -doDepth 1 -out results/depth/Group{1} \
-doCounts 1 -rf ../data/honeybee_genome/ordered_scaffolds.Group{1}.list -minMapQ 30 -minQ 20 \
-remove_bads 1 -maxDepth 20000' ::: {1..16} Un &> logs/depth_by_chr.out &
[1] 13236 - RUNNING 1.7.19

# extracting mapping metrics, including percent read duplication (e.g. PCR duplicates):
# counting # reads pre-filtering, and at de-duplication using PICARD metrics.txt output files
# (to compare effects of filtering across groups/individuals):
bees/filtered_bams/metrics$ grep 'LIBRARY' $(head -n 1 ../../bee_samples_listed/pass1.list).metrics.txt | \
awk '{print "StudyID\t"$0}' > pass1.all.metrics.raw.Nreads; \
for i in $(cat ../../bee_samples_listed/pass1.list); do grep 'Unknown Library' "$i.metrics.txt" | \
awk -v i="$i" '{print i"\t"$0}' >> pass1.all.metrics.raw.Nreads; done

# get the total number of reads, and total # mapped (any quality) AFTER removing duplicates:
# I don't actually filter for Q30 (or even unmapped); wanted to leave options open.
# first count reads using samtools flagstat:
bees/filtered_bams$ nohup parallel --noswap --joblog logs/run_flagstat.log --jobs 4 \
'samtools flagstat results/{1}.sort.dedup.baq.bam > metrics/{1}.flagstat.txt' \
:::: ../bee_samples_listed/pass1.list &> logs/run_flagstat.out &
[2] 15291 - COMPLETE 1.8.19
extract from flagstat metrics the number of reads in final filtered (no duplicates) bams:
bees/filtered_bams/metrics$ for i in $(cat ../../bee_samples_listed/pass1.list); \
do echo $i$'\t'$(cat $i.flagstat.txt | grep 'total' | cut -d' ' -f1); \
done > pass1.all.metrics.dedup.total.Nreads
bees/filtered_bams/metrics$ for i in $(cat ../../bee_samples_listed/pass1.list); \
do echo $i$'\t'$(cat $i.flagstat.txt | grep '+ 0 mapped (' | cut -d' ' -f1); \
done > pass1.all.metrics.dedup.mapped.Nreads

# another way to quickly visualize results from samtools flagstat output and picard's markduplicates is multiQC:
pip3 install multiqc # install
bees/filtered_bams/metrics$ multiqc . # created summary output file: gitErin/bees/filtered_bams/metrics/multiqc_report.html
# from this I see that a few of Ramirez bees, e.g. ap41, and some of my newer bees have very low mapping rates. In general my duplication rate is fine.

# Use FastQ screen to assess why some samples have high % unmapped reads -- do I have contamination? FastQ screen attempts to map reads to multiple references of your choice, to check for contamination
# I downloaded fastq_screen program and multiple reference genomes to ~/Software/fastQ_screen
# made a configuration file including the following genomes for mapping as possible sources of contamination: honeybee, honeybee mtdna, human, PhiX, E. coli (bacteria proxy), Adapter sequences, Arabidopsis (angiosperm proxy for possible pollen contamination), Vectors, plus some additional commonly sequenced things that could contribute to sequencer contamination, lambda, worm, yeast, drosophila, rat, mouse, (human?) mitochondria: fastq_screen_honeybee.conf
# made symlink to fastq_Screen_v0.13.0 folder because needs to have .conf file in that folder:
bees/filtered_bams/fastQ_screen$ ln -s fastq_screen_honeybee.conf ~/Software/fastQ_screen/fastq_screen_v0.13.0/fastq_screen.conf
# ran test (mouse data -- looks good! deleted output after checking)
bees/filtered_bams/fastQ_screen$ ~/Software/fastQ_screen/fastq_screen_v0.13.0/fastq_screen --aligner BOWTIE2 --conf fastq_screen_honeybee.conf ~/Software/fastQ_screen/fastq_screen_test_dataset/fqs_test_dataset.fastq.gz
# just one of my files to test:
bees/filtered_bams/fastQ_screen$ ~/Software/fastQ_screen/fastq_screen_v0.13.0/fastq_screen --aligner BOWTIE2 --conf fastq_screen_honeybee.conf ../../data/novo_seq/C202SC18101772/raw_data/CA0102/CA0102_USPD16090569-AK1956-AK389_HTMNTCCXY_L6_1.fq.gz
# Running fastQ_screen on all my fastq's sequenced thus far:
bees/filtered_bams/fastQ_screen$ nohup parallel --noswap --delay 2 --jobs 4 --joblog ../logs/run_fastQ_screen_C202SC18101772.log '~/Software/fastQ_screen/fastq_screen_v0.13.0/fastq_screen --aligner BOWTIE2 --conf fastq_screen_honeybee.conf --outdir output $(ls ../../data/novo_seq/C202SC18101772/raw_data/{1}/{1}_*_{2}.fq.gz)' :::: ../../data/novo_seq/C202SC18101772/samples.list ::: 1 2 &> ../logs/run_fastQ_screen_C202SC18101772.out &
[1] 28891 - RUNNING 1.19.19
# I summarize these multi-genome mapping results using multiQC:
bees/filtered_bams/fastQ_screen/output$ multiqc .
# this searched for parsable output files (here from fastq_screen) and summarized results in one file: bees/filtered_bams/fastQ_screen/output/multiqc_report.html
# From this I conclude that a small number of samples have a majority or reads that don't map to anything, e.g. AR1115, AR2202 and AR2913.
# These samples could have contamination for which I have no close reference -- they do, e.g., have a little more E. coli mapping than others,
# but I think maybe adapter contamination is worth investigating.
# See TO DO below for next steps to solving this mystery.

# take a subset of reads from problem files and one ok file (CA1410) to see which reads do and don't match
filtered_bams/fastQ_screen$ nohup parallel --noswap --jobs 4 --joblog ../logs/subset_no_hits_fastQ_screen_low_mapping.log '~/Software/fastQ_screen/fastq_screen_v0.13.0/fastq_screen --subset 100000 --aligner BOWTIE2 --conf fastq_screen_honeybee.conf --nohits --outdir nohits ../../data/novo_seq/C202SC18101772/raw_data/{1}/*_1.fq.gz' ::: AR1115 AR2202 AR2913 CA1410 &> subset_no_hits_fastQ_screen_low_mapping.log &
fastQ_screen$ mv subset_no_hits_fastQ_screen_low_mapping.log ../logs/.
[1] 9332 - COMPLETED. oops overwritten .log file but ran ok.

# and take a subset of reads that map to honeybee (for comparison). okay if they don't map uniquely
filtered_bams/fastQ_screen$ nohup parallel --noswap --jobs 4 --joblog ../logs/subset_do_map_fastQ_screen_low_mapping.log '~/Software/fastQ_screen/fastq_screen_v0.13.0/fastq_screen --subset 100000 --aligner BOWTIE2 --conf fastq_screen_honeybee.conf --tag --filter --------------3- --outdir domap ../../data/novo_seq/C202SC18101772/raw_data/{1}/*_1.fq.gz' ::: AR1115 AR2202 AR2913 CA1410 &> ../logs/subset_do_map_fastQ_screen_low_mapping.out &
COMPLETED 2.4.19.
# also running fastQC to look at read quality on a subset of samples:
filtered_bams$ nohup parallel --noswap --jobs 5 --joblog logs/run_fastQC_low_mapping.log '~/Software/FastQC/fastqc ../data/novo_seq/C202SC18101772/raw_data/{1}/*.fq.gz --outdir=fastQC' ::: AR1115 AR2202 AR2913 CA1410 AR0302 &> logs/run_fastQC_low_mapping.out &
[1] 13648 - COMPLETED 2.4.19
# NOTE: I don't see any obvious quality issues for the libraries with low mapping %
# In all libraries, there's bias in base content for the first ~10 bases,
# which is likely a result of tagmentation in the Nextera kit because the enzyme cuts at certain sequence patterns.
# Some libraries have .1-.2% repeated sequences, many of which are simple repeats, e.g. AACCTAACCTAACCTAACCTAACCTAACCTAACCTAACCTAACCTAACCT
# resulting .tagged.fastq.gz have a subset of 100000 random reads while .tagged_filter.fastq.gz files have just reads meeting filter criteria from that subset
# Also I have minor adapter contamination -- about 1-3% of my reads have adapter sequences, e.g.
# to find my search sequence I used the reverse complement of the adapter sequence Anne gave me:
https://www.bioinformatics.org/sms/rev_comp.html of CAAGCAGAAGACGGCATACGAGATGTCGGTAAAGTCTCGTGGGCTCGG for index TTTACCGAC
filtered_bams/fastQ_screen/nohits$ zgrep --color 'CCGAGCCCACGAGACT' AR1115*_1.tagged.fastq.gz
# this can be filtered out but is true of low mapping and high mapping files
filtered_bams/fastQ_screen/nohits$ zgrep --color 'CCGAGCCCACGAGACT' CA1410*_1.tagged.fastq.gz | wc -l
# I also tested for adapter contamination in reads that do map, and it's about the same 1.5%:
filtered_bams/fastQ_screen/domap$ zgrep --color 'CCGAGCCCACGAGACT' CA1410*_1.tagged_filter.fastq.gz | wc -l

# I also did a blastN search in NCBI for some of the reads that were not hits
fastQ_screen/nohits$ bioawk -c fastx '{print $name}' AR1115_USPD16090569-AK4210-AK389_HTMNTCCXY_L6_1.tagged_filter.fastq
# From the results I conclude that I have some contamination from the gut for the low mapping samples
# because I get hits to a common honeybee gut symbiont Gilliamella apicola https://blast.ncbi.nlm.nih.gov


# Downloading additional A/C/M/ and new O reference bees in addition to one male haploid drone and several Africanized bees from Brazil from Wallberg 2014
# These require their own bioinformatics pipeline because they were sequenced on an older platform, ABI SOLiD technology, at ~4-6x coverage each
# First get SSR ID's for NCBI download from all bees in Wallberg 2014
data/Wallberg_2014$ (awk -F"\t" '$10 != "USA" && $10 != "Japan" && $10 != "geo_loc_name" {print $7}' SraRunTable.txt; awk -F"\t" '$12 == "male" {print $7}' SraRunTable.txt) > SRR_Acc_to_get.list
data/Wallberg_2014$ (awk -F"\t" '$10 != "USA" && $10 != "Japan" && $10 != "geo_loc_name" {print $8}' SraRunTable.txt; awk -F"\t" '$12 == "male" {print $8}' SraRunTable.txt) > sample_IDs_to_get.list
# Note: many of the bees have multiple files representing different sequencing runs, which creates repeats in sample_IDs_to_get.list
# Download files from NCBI onto Nancy's computer:
data/Wallberg_2014$ nohup parallel --joblog ../../logs/download_Wallberg_2014_NCBI.log --delay 2.5 --noswap 'fastq-dump --split-files -clip \
--gzip --skip-technical -O fastq_files/ "{1}"' :::: SRR_Acc_to_get.list &> ../../logs/download_Wallberg_2014_NCBI.out &
[1] 19643 - oops fastq-dump not installed...I'm installing sratoolkit with homebrew
[2] 40694 - RUNNING 1.19.19

# the next step is to align this SOLiD data using SHRiMP (Rumble et al. 2009). Then I can remove duplicates and adjust by BAQ. And ultimately merge files/runs for the same sample before incorporating these samples into ANGSD variant calling and genotype likelihoods.
# testing my script for downloading aligning and sorting SOLiD data from Wallberg study:
filtered_bams$ chmod u+x download_map_sort_SOLiD_reads.sh
filtered_bams$ nohup parallel --joblog logs/test_download_filter_Wallberg_2014_NCBI.log --noswap './download_map_sort_SOLiD_reads.sh {1} {2}' ::: SRR1151485 ::: SRS549155 &> logs/test_download_filter_Wallberg_2014_NCBI.out &
[1] 72364 - killed, fixed typo in tmp directory, restarting:
[2] 72570 - finished running & all looked good (except see below!). Now modified to delete intermediate files & running whole set:
# ACTUALLY, there was an issue with truncated bam file. I think next step in script is proceeding without finishing first step...need to resolve.
filtered_bams$ nohup parallel --joblog logs/test2_download_filter_Wallberg_2014_NCBI.log --noswap './download_map_sort_SOLiD_reads.sh {1} {2}' ::: SRR1151485 SRR1151486 ::: SRS549155 &> logs/test2_download_filter_Wallberg_2014_NCBI.out &
[1] 91045 - COMPLETED 1.22.19 - ran without errors. I will add to code commands to delete intermediate files. Unclear what issue may have been. Moved test files to filtered_bams/test/SOLiD
# moved results of test to Barbara comp.: filtered_bams/test/SOLiD/SRS549155

# index honeybee genome and save for all calls to SHRiMP 1.22.19:
honeybee_genome$ /Users/ecalfee/Software/SHRiMP_2_2_2/bin/gmapper-cs --save Amel_4.5_scaffolds.fa Amel_4.5_scaffolds.fa
Saving genome map to Amel_4.5_scaffolds.fa # saves .genome and .seed.0 .seed.1 .seed.2 files.
#BUT this doesn't load when I use this genome for SHRiMP, so I deleted these files.

# Run mapping script on all Wallberg 2014 samples 1.22.19:
# note: parallel --link option means each SRR and sample_ID are run together only once (not every possible combination!)
filtered_bams$ nohup parallel --joblog logs/download_filter_Wallberg_2014_NCBI.log --noswap --delay 5s --link './download_map_sort_SOLiD_reads.sh {1} {2}' :::: ../data/Wallberg_2014/SRR_Acc_to_get.list :::: ../data/Wallberg_2014/sample_IDs_to_get.list &> logs/download_filter_Wallberg_2014_NCBI.out &
[1] 22588 - RUNNING 1.23.19 - DID NOT WORK (STALLED OUT) -- trying again (see below) with just ACMO bees

# making list of just the M/C/O/A reference bees from Wallberg (no admixed Brazil and no high-coverage drone -- can add these in later)
data/Wallberg_2014$ (awk -F"\t" '$10 != "USA" && $10 != "Japan" && $10 != "geo_loc_name" && $10 != "Brazil" {print $7}' SraRunTable.txt) > SRR_Acc_to_get_ACMO.list
data/Wallberg_2014$ (awk -F"\t" '$10 != "USA" && $10 != "Japan" && $10 != "geo_loc_name" && $10 != "Brazil" {print $8}' SraRunTable.txt) > sample_IDs_to_get_ACMO.list

# mapping Wallberg 2014 ACMO reference bees:
filtered_bams$ nohup parallel --joblog logs/download_filter_Wallberg_2014_NCBI_ACMO.log --noswap --jobs 6 --delay 2s --link './download_map_sort_SOLiD_reads.sh {1} {2} /Users/ecalfee/Software/SHRiMP_2_2_2/bin' :::: ../data/Wallberg_2014/SRR_Acc_to_get_ACMO.list :::: ../data/Wallberg_2014/sample_IDs_to_get_ACMO.list &> logs/download_filter_Wallberg_2014_NCBI_ACMO.out &
[1] 73180 - RUNNING 2.4.19
72488(0) swapins, 152460(0) swapouts at 11:44 am 2.5.19
79832(0) swapins, 152460(0) swapouts at 14:38 pm 2.5.19 (not growing)

# I don't actually need to run all of these samples, so I cancelled this job:

# instead, I'll make a list in this order of O (anatoliaca), A (scutellata), C (ligustica -- already done), and M (iberiensis) to run (I may want to exclude the 3 super high coverage individuals too.. tbd):
# first 27 files ran, which is 12 bees. What if I get 5 O (anatoliaca), 5 A (scutellata), 5 O (syrica), 2 M (ibiriensis), 2 M (mellifera sweden), 2 M (carnica):
Wallberg_2014$ (awk -F"\t" '$10 != "USA" && $10 != "Japan" && $10 != "geo_loc_name" && $10 != "Brazil" && $13 != "EU domestic" {print $7"\t"$8"\t"$13"\t"$10"\t"$26}' SraRunTable.txt) > all_ACMO.txt
# finish scutellata SRS549639 and run 3 more (total = 5)
head -n 27 all_ACMO.txt > C_ling_and_A_done.txt
grep 'scutellata' all_ACMO.txt | tail -n +8 | head -n 23 > A_scut_complete_5.txt
grep 'Turkey' all_ACMO.txt | tail -n +11 | head -n 36 > O_turkey_5.txt
grep 'Jordan' all_ACMO.txt | head -n 35 > O_jordan_5.txt
for i in Spain Sweden Norway; do grep $i all_ACMO.txt | head -n 12; done > M_spain_sweden_norway_6.txt
grep 'Austria' all_ACMO.txt | head -n 12 > C_austria_2.txt
cat O_turkey_5.txt A_scut_complete_5.txt O_jordan_5.txt M_spain_sweden_norway_6.txt C_austria_2.txt > ACMO_subset_todo.txt
Wallberg_2014$ cut -f1 ACMO_subset_todo.txt > SRR_Acc_ACMO_subset_todo.list
Wallberg_2014$ cut -f2 ACMO_subset_todo.txt > sample_IDs_ACMO_subset_todo.list
# running this subset with 8 threads:
filtered_bams$ nohup parallel --joblog logs/download_filter_Wallberg_2014_NCBI_ACMO_subset.log --noswap --jobs 8 --delay 60s --link './download_map_sort_SOLiD_reads.sh {1} {2} /Users/ecalfee/Software/SHRiMP_2_2_2/bin' :::: ../data/Wallberg_2014/SRR_Acc_ACMO_subset_todo.list :::: ../data/Wallberg_2014/sample_IDs_ACMO_subset_todo.list &> logs/download_filter_Wallberg_2014_NCBI_ACMO_subset.out &
[1] 4881 - COMPLETE 2.5.19 BUT I forgot one:
filtered_bams$ nohup parallel --joblog logs/download_filter_Wallberg_2014_NCBI_ACMO_SRS549663.log --noswap --jobs 1 './download_map_sort_SOLiD_reads.sh {1} {2} \
/Users/ecalfee/Software/SHRiMP_2_2_2/bin' ::: SRR1152376 ::: SRS549663 &> logs/download_filter_Wallberg_2014_NCBI_ACMO_SRS549663.out &
[1] 85166 - COMPLETED 2.7.19

# merge and deduplicate other files:
filtered_bams$ mkdir SOLiD/merged
filtered_bams$ nohup parallel --delay 3 --noswap --joblog logs/merge_dedup_Wallberg_ACMO_subset.log --jobs 5 \
'ls SOLiD/{1}/*.sort.bam > merged/{1}.list;
samtools merge -b merged/{1}.list merged/{1}.sort.bam;
./dedup_baq_bams.sh {1} merged;
samtools flagstat results/{1}.sort.dedup.baq.bam > metrics/{1}.flagstat.txt' \
::: $(ls SOLiD/) &> logs/merge_dedup_Wallberg_ACMO_subset.out &
[2] 85441 - COMPLETED 2.7.19. will need to do dedup on other computer. rerunning merge on one missing file:
filtered_bams$ nohup parallel --joblog logs/merge_Wallberg_ACMO_subset_SRS549663.log \
'ls SOLiD/{1}/*.sort.bam > merged/{1}.list;
samtools merge -b merged/{1}.list merged/{1}.sort.bam' \
::: SRS549663 &> logs/merge_Wallberg_ACMO_subset_SRS549663.out &
[1] 90429 - COMPLETED 2.8.19

# made list of files that includes n=28 total Wallberg 2014 reference bees:
# 6 O turkey, 6 O jordan, 6 M (spain, sweden, norway), 2 C carnica (austria), 4 C ling (italy), 5 A scuttelatta (S. Africa).
# I'm ignoring additional C I aligned from Italy for now, to not give that group undue weight:
data/Wallberg_2014$ cut -f2 C_ling_and_A_done.txt | uniq | tail -n 5 | head -n 4 > Wallberg_12O_6M_6C_5A.list; cut -f2 ACMO_subset_todo.txt | uniq >> Wallberg_12O_6M_6C_5A.list; mv Wallberg_12O_6M_6C_5A.list ../../bee_samples_listed/.

# saved all meta data from Wallber 2014 together:
Wallberg_2014$ cut -f8,10,12,13,26,27 SraRunTable.txt > ../../bee_samples_listed/Wallberg_2014_all.meta

# now deduplicating & adding BAQ:
filtered_bams$ nohup parallel --delay 3 --noswap --joblog logs/dedup_baq_Wallberg_ACMO_subset.log --jobs 3 \
'./dedup_baq_bams.sh {1} merged;
samtools flagstat results/{1}.sort.dedup.baq.bam > metrics/{1}.flagstat.txt' \
:::: ../bee_samples_listed/Wallberg_12O_6M_6C_5A.list &> logs/dedup_baq_Wallberg_ACMO_subset.out &
[1] 9080 - RUNNING 2.8.19

# Kohn data - 2 San Diego bees and 1 Mexico bee sample
# map data (multiple lanes of illumina reads per bee):
filtered_bams$ nohup parallel --noswap --joblog logs/map_reads_and_sort_kohn_San_Diego.log --jobs 3 \
'./map_reads_kohn.sh SanDiego{1} {2} San_Diego_Honeybee_{1}; \
./sort_reads.sh SanDiego{1} {2}' ::: 001 002 ::: L006 L007 L008 \
&> logs/map_reads_and_sort_kohn_San_Diego.out &
[1] 19236 - Map completed. Sort script was misspelled -- sort_BAMS.sh. Will sort below. 2.1.19

filtered_bams$ nohup parallel --noswap --joblog logs/map_reads_and_sort_kohn_Mexico.log --jobs 1 \
'./map_reads_kohn.sh Mexico{1} {2} Mexico_Honeybee_{1}; \
./sort_reads.sh Mexico{1} {2}' ::: 001 ::: L006 L007 \
&> logs/map_reads_and_sort_kohn_Mexico.out &
[2] 19347 - COMPLETED (but not sorted, see below)

# After sorting, I merge bams:
# e.g. L006/SanDiego001.sort.bam L007/SanDiego001.sort.bam L008/SanDiego001.sort.bam into merged/SanDiego001.sort.bam
# then run dedup_baq_bams.sh on the resulting merged bam file
nohup parallel --delay 3 --noswap --joblog logs/sort_merge_dedup_kohn.log --jobs 3 \
'./sort_merge_bams_kohn.sh {1}; ./dedup_baq_bams.sh {1} merged' \
::: SanDiego001 SanDiego002 Mexico001 &> logs/sort_merge_dedup_kohn.out &
[2] 29013 - couldn't allocate memory .. so reduced memory. also possibly had lingering jobs running .. oops:
[1] 30349 - RAN but error in merge 2.1.19. Rerunning merge and dedup:
nohup parallel --delay 3 --noswap --joblog logs/merge_dedup_kohn2.log --jobs 3 \
'ls L*/{1}.sort.bam > merged/{1}.list;
samtools merge -b merged/{1}.list merged/{1}.sort.bam;
./dedup_baq_bams.sh {1} merged' ::: SanDiego001 SanDiego002 Mexico001 &> logs/merge_dedup_kohn2.out &
[1] 3391 - COMPLETED 2.2.19 and also fixed sort_merge_bams_kohn.sh to reflect these fixes to samtools merge.


# note that Mexico honeybee I'm only using 2/3 (no L008 file) of the data but that's ok coverage for a quick ngsADMIX analysis
# basic metrics for kohn bees:
nohup parallel --noswap --joblog logs/run_flagstat_kohn.log --jobs 3 \
'samtools flagstat results/{1}.sort.dedup.baq.bam > metrics/{1}.flagstat.txt' \
::: SanDiego001 SanDiego002 Mexico001 &> logs/run_flagstat_kohn.out &
[1] 4548 - COMPLETED 2.2.19

# results/SRCD12B.sort.dedup.baq.bam is now an empty file -- I'm not sure why it was written over.
# Re-doing filtering of SRCD12B from original bam in CA_bee/bam_files/ :
nohup parallel --noswap --joblog logs/filter_bams_CA_Bee_rerun_SRCD12B.log --jobs 1 \
'./sort_bams.sh {1} ../data/CA_Bee/bam_files; ./dedup_baq_bams.sh {1} results; \
cp results/{1}.sort.dedup.baq.bam results/SRCD12B.backup.sort.dedup.baq.bam; \
./add_readgroup_2_bams.sh {1} CA_Bee results;
cp results/RG_added/{1}.sort.dedup.baq.bam results/{1}.sort.dedup.baq.bam' \
::: SRCD12B &> logs/filter_bams_CA_Bee_rerun_SRCD12B.out &
[1] 7740 - RUNNING 2.2.19 - COMPLETED. Forgot to cp over .bai file too, so copied to results/ by hand. deleted RG_added/ and all intermediate files

# Use fastQ screen to understand why the four lanes returned from Novogene in May 2019 have a high % reads that are 'undetermined', i.e. could not be de-multiplexed. Analysis 5.24.19:
# are 'undetermined' reads honey bee reads? Do they look different than the reads that could be demultiplexed?
bees/filtered_bams/fastQ_screen$ nohup parallel --noswap --delay 2 --jobs 2 --joblog ../logs/run_fastQ_screen_undetermined_reads.log '~/Software/fastQ_screen/fastq_screen_v0.13.0/fastq_screen --aligner BOWTIE2 --conf fastq_screen_honeybee.conf --outdir output $(ls ../../data/novo_seq/lanes2_5/Undetermined/Undetermined_H2F5YCCX2_L{1}_{2}.fq.gz)' ::: 1 2 3 4 ::: 1 2 &> ../logs/run_fastQ_screen_undetermined_reads.out &
[1] 17114 - RUNNING 5.24.19 (L1 isn't finished downloading so it produces and error but the others are running)
# running just L1 now that it's downloaded:
filtered_bams/fastQ_screen$ nohup parallel --noswap --delay 2 --jobs 2 --joblog ../logs/run_fastQ_screen_undetermined_reads_L1.log '~/Software/fastQ_screen/fastq_screen_v0.13.0/fastq_screen --aligner BOWTIE2 --conf fastq_screen_honeybee.conf --outdir output $(ls ../../data/novo_seq/lanes2_5/Undetermined/Undetermined_H2F5YCCX2_L{1}_{2}.fq.gz)' ::: 1 ::: 1 2 &> ../logs/run_fastQ_screen_undetermined_reads_L1.out &
[1] 25234 - RUNNING 5.24.19


# what do a few regular demultiplexed sets of reads look like from the newest round of sequencing?
bees/filtered_bams/fastQ_screen$ nohup parallel --noswap --delay 2 --jobs 1 --joblog ../logs/run_fastQ_screen_AR0101_AR0103.log '~/Software/fastQ_screen/fastq_screen_v0.13.0/fastq_screen --aligner BOWTIE2 --conf fastq_screen_honeybee.conf --outdir output $(ls ../../data/novo_seq/lanes2_5/{1}/{1}_*L*_{2}.fq.gz)' ::: AR0101 AR0103 ::: 1 2 &> ../logs/run_fastQ_screen_AR0101_AR0103.out &
[2] 18052 - RUNNING 5.24.19 (fast). A few more:
bees/filtered_bams/fastQ_screen$ nohup parallel --noswap --delay 2 --jobs 1 --joblog ../logs/run_fastQ_screen_AR0105-0115.log '~/Software/fastQ_screen/fastq_screen_v0.13.0/fastq_screen --aligner BOWTIE2 --conf fastq_screen_honeybee.conf --outdir output $(ls ../../data/novo_seq/lanes2_5/{1}/{1}_*L*_{2}.fq.gz)' ::: AR0105 AR0108 AR0109 AR0110 AR0111 AR0115 ::: 1 2 &> ../logs/run_fastQ_screen_AR0105-AR0115.out &
[2] 21118 - RUNNING 5.24.19
# now all of the new fastqs that were demultiplexed:
bees/filtered_bams/fastQ_screen$ nohup parallel --noswap --delay 2 --jobs 1 --joblog ../logs/run_fastQ_screen_lanes2_5.log '~/Software/fastQ_screen/fastq_screen_v0.13.0/fastq_screen --aligner BOWTIE2 --conf fastq_screen_honeybee.conf --outdir output $(ls ../../data/novo_seq/lanes2_5/{1}/{1}_*L*_{2}.fq.gz)' :::: ../../bee_samples_listed/lanes2_5_IDs.list ::: 1 2 &> ../logs/run_fastQ_screen_lanes2_5.out &
[2] 24215 - RUNNING 5.30.19. Note: skips files that already have QC reports, so doesn't repeat e.g. AR0101 completed from job above

# I summarize these multi-genome mapping results using multiQC:
bees/filtered_bams/fastQ_screen/output$ multiqc .

# mostly 'undetermined' reads map to honeybee, with 5-15% mapping to phiX (presumably from spike in).
# I also looked at the barcodes and reads that were 'undetermined':
Undetermined$ zgrep '1:N:0:' ../Undetermined/*_L4_1.fq.gz | cut -f10 -d":" | head -n 100000 | sort | uniq -c | sort -nr | head -n 100
   1420 GGAGAGTA+GCGATCTA
# this is the most common undetermined index in all 4 lanes, and represents < 1% of 'undetermined' reads
# so basically they are not concentrated on a few types.
# many match the i5 end or are a single base pair off and match the i7 end (I could try to demultiplex these but I'm not sure how common they are really if it's worth it to get 500 extra reads
# e.g. Undetermined$ zgrep '1:N:0:' ../Undetermined/*_L4_1.fq.gz | cut -f10 -d":" | head -n 1000000 | grep '^T' | sort | uniq -c | sort -nr | head -n 10
   2430 TAAGACCG+ACGATCTA # .002 % of 55G undetermined reads is approx 0.1G and possibly lower quality reads in general
# I initially thought it was a lot but actually it's a small percent that have a single bp N at the beginning of each index and their read:
Undetermined$ zgrep '1:N:0:' ../Undetermined/*_L4_1.fq.gz | cut -f10 -d":" | head -n 1000000 | grep '^N' | wc -l
7647
# presumably these should be my 56 barcodes: (but last one doesn't match .. because AR1212 didn't amplify)
Undetermined$ zgrep '1:N:0:' ../Undetermined/*_L4_1.fq.gz | cut -f10 -d":" | cut -f1 
-d"+" | head -n 1000000 | grep '^T' | sort | uniq -c | sort -nr | head -n 56
# so about how many of these sequences are there?
bees/data/novo_seq/lanes2_5/Undetermined$ zgrep '1:N:0:' ../Undetermined/*_L4_1.fq.gz | cut -f10 -d":" | cut -f1 
-d"+" | head -n 1000000 | grep '^T' | sort | uniq -c | sort -nr | head -n 55 | awk '{print $1}' | paste -sd+ | bc
369389 # about 37% (up to 49% w/ L1) of 'undetermined' reads may be assignable based on i7 barcode alone if I trust that the i5 barcode doesn't need to match..

# Aligning first set of 140 from the new sequences (all of AR bees; buying more space before I can do the rest):
# make list of alphabetically first
bees/bee_samples_listed$ tail -n +2 ../labwork/Novogene_libraries2-5_barcodes.txt | sort -u -k2 | cut -f1 -d" " | cut -f3 -d"_" > lanes2_5_libraries.list
bees/bee_samples_listed$ tail -n +2 ../labwork/Novogene_libraries2-5_barcodes.txt | sort -u -k2 | cut -f2 -d" " > lanes2_5_IDs.list
bee_samples_listed$ head -n 140 lanes2_5_IDs.list > may2019AR_IDs.list
bee_samples_listed$ head -n 140 lanes2_5_libraries.list > may2019AR_libraries.list
# for first 140 map to reference genome:
filtered_bams$ nohup parallel --noswap --delay 5 --joblog logs/map_reads_may2019_AR.log --jobs 3 './map_reads.sh {1} {2} novo_seq/lanes2_5/{1}/{1}_; ./sort_bams.sh {1} novo_seq/bam_files; rm ../data/novo_seq/bam_files/{1}.bam; ./dedup_baq_bams.sh {1} filtered_bams/results; rm results/{1}.sort.bam' :::: ../bee_samples_listed/may2019AR_IDs.list :::: ../bee_samples_listed/may2019AR_libraries.list &> logs/map_reads_may2019_AR.out &
[1] 31958 - FAILED 5.24.19 - trying small test case with first 100 reads for AR0101:
filtered_bams$ nohup parallel --noswap --delay 1 --joblog logs/map_reads_TEST_may2019_AR.log --jobs 3 './map_reads.sh {1} {2} novo_seq/lanes2_5/{1}/{1}_; ./sort_bams.sh {1} ../data/novo_seq/bam_files; rm ../data/novo_seq/bam_files/{1}.bam; ./dedup_baq_bams.sh {1} results; rm results/{1}.sort.bam' ::: TEST_AR0101 ::: TEST_LANE &> logs/map_reads_TEST_may2019_AR.out &
[1] 21684 - COMPLETED SUCCESSFULLY 5.28.19
# fixed directory naming issues and parallel config (oops trying to run all combinations!!) & re-running for all the bees from lanes 2-5:
filtered_bams$ nohup parallel --noswap --delay 2 --joblog logs/map_reads_lanes2_5.log --jobs 4 './map_reads.sh {1} {2} novo_seq/lanes2_5/{1}/{1}_; ./sort_bams.sh {1} ../data/novo_seq/bam_files; rm ../data/novo_seq/bam_files/{1}.bam; ./dedup_baq_bams.sh {1} results; rm results/{1}.sort.bam' :::: ../bee_samples_listed/lanes2_5_IDs.list ::::+ ../bee_samples_listed/lanes2_5_libraries.list &> logs/map_reads_lanes2_5.out &
[1] 24579 - RUNNING 5.28.19. This will take maybe a week, even with 4 threads. I killed with -9 at 2:15pm on 5.29.19 to transfer data over to larger 8TB drive.
filtered_bams$ cp logs/map_reads_lanes2_5.log logs/map_reads_lanes2_5_try1.log
filtered_bams$ cp logs/map_reads_lanes2_5.out logs/map_reads_lanes2_5_try1.out
filtered_bams$ nohup parallel --noswap --delay 2 --resume-failed --joblog logs/map_reads_lanes2_5.log --jobs 4 './map_reads.sh {1} {2} novo_seq/lanes2_5/{1}/{1}_; ./sort_bams.sh {1} ../data/novo_seq/bam_files; rm ../data/novo_seq/bam_files/{1}.bam; ./dedup_baq_bams.sh {1} results; rm results/{1}.sort.bam' :::: ../bee_samples_listed/lanes2_5_IDs.list ::::+ ../bee_samples_listed/lanes2_5_libraries.list &> logs/map_reads_lanes2_5_try2.out &
[1] 22365 - RUNNING 5.30.19. COMPLETED 6.5.19.

# run flagstat on all new novogene aligned bams
bees/filtered_bams$ nohup parallel --noswap --joblog logs/run_flagstat_lanes2_5.log --jobs 4 \
'samtools flagstat ../filtered_bams/results/{1}.sort.dedup.baq.bam > metrics/{1}.flagstat.txt' \
:::: ../bee_samples_listed/lanes2_5_IDs.list &> logs/run_flagstat_lanes2_5.out &
[1] 16886 - RUNNING 6.5.19. COMPLETED.

# run flagstat on all bams with a mapping quality filter mapQ>30 (to estimate coverage). Remember some bees have diff. length reads:
bees/filtered_bams$ mkdir -p metrics/Q30
bees/filtered_bams$ nohup parallel --noswap --joblog logs/run_flagstat_Q30.log --jobs 4 \
'samtools view -h -q 30 ../filtered_bams/results/{1}.sort.dedup.baq.bam | samtools flagstat - > metrics/Q30/{1}.flagstat.txt' \
:::: ../bee_samples_listed/CA_AR_MX_harpur_sheppard_kohn_wallberg.list &> logs/run_flagstat_Q30.out &
[1] 21303 - RUNNING 6.5.19

# summarise output of flagstat
filtered_bams/metrics/Q30$ for i in $(cat  ../../../bee_samples_listed/CA_AR_MX_harpur_sheppard_kohn_wallberg.list); do cat "$i".flagstat.txt | grep 'QC-passed' | cut -d" " -f1; done > CA_AR_MX_harpur_sheppard_kohn_wallberg.nreads

# checking MD5 sums for all data from newest round of sequencing:
bees/data/novo_seq/lanes3_5$ cat */MD5.txt > ALL_MD5_expected.txt
bees/data/novo_seq/lanes2_5$ for i in $(awk '{print $2}' ALL_MD5_expected.txt); do md5sum */${i}; done > ALL_MD5_observed.txt # observed MD5 sums
bees/data/novo_seq/lanes2_5$ diff -q <(awk '{print $1}' ALL_MD5_expected.txt) <(awk '{print $1}' ALL_MD5_observed.txt) # outputs 'Files * and * differ' if they differ; outputs nothing if they're the same. Take away -q to see differences. (all ok; no differences!)
# I'm still re-downloading the 'Undetermined' reads to the 8TB drive so I'll have to check their MD5 sums later.
# checking undetermined reads:
data/novo_seq/lanes2_5/Undetermined$ cat MD5.txt > ALL_MD5_expected.txt
bees/data/novo_seq/lanes2_5/Undetermined$ diff <(awk '{print $1}' ALL_MD5_expected.txt) <(awk '{print $1}' ALL_MD5_observed.txt) # lanes 2 and 3 have switched order -- otherwise no differences

---------------------------------------------------------------------------------
# Switching to new genome HAv3.1:
# made symbolic link to NCBI downloaded file:
# unzipping genome file:
data/honeybee_genome$ gunzip GCF_003254395.2_Amel_HAv3.1_genomic.fna.gz
# making symbolic link for shorter file name
honeybee_genome$ ln -s GCF_003254395.2_Amel_HAv3.1_genomic.fna Amel_HAv3.1.fasta
# indexing genome with bowtie:
data/honeybee_genome$ bowtie2-build Amel_HAv3.1.fasta Amel_HAv3.1
# indexing genome with samtools:
data/honeybee_genome$ samtools faidx Amel_HAv3.1.fasta

# moved old results to new directories marked Amel4.5:
bees/filtered_bams$ mv results results_Amel4.5
filtered_bams$ mv metrics/ metrics_Amel4.5/
filtered_bams$ mv merged/ merged_Amel4.5/
filtered_bams$ mv fastQ_screen fastQ_screen_Amel4.5
filtered_bams$ mv fastQC fastQC_Amel4.5

# Mapping reads (modified script from previous genome)
filtered_bams$ nohup parallel --noswap --delay 1 --joblog logs/map_reads_HAv3.1_C202SC18101772.log --jobs 4 './map_reads.sh {1} {2} ../data/novo_seq/lanes2_5/{1}/{1}_; ./sort_bams.sh {1} results/intermediate_bams; rm results/intermediate_bams/{1}.bam; ./dedup_baq_bams.sh {1} results/intermediate_bams; rm results/intermediate_bams/{1}.sort.bam' :::: ../bee_samples_listed/lanes2_5_IDs.list ::::+ ../bee_samples_listed/lanes2_5_libraries.list &> logs/map_reads_lanes2_5_HAv3.1.out &
[1] 17936 - RUNNING. KILLED 8.2.19. I will continue where this left off on Nancy's mac (a lot faster), or at least with fewer threads here so I can run other things too.
filtered_bams$ cp logs/map_reads_HAv3.1_C202SC18101772.log logs/map_reads_lanes2_5_HAv3.1.log

# note: bams are about double fastq in terms of storage space
# TO DO: on Nancy's mac: BUT I'M WAITING DUE TO LACK OF STORAGE SPACE
I NEED TO SPLIT THIS TASK UP INTO SMALLER PIECES SO I HAVE ENOUGH SPACE
filtered_bams$ cp logs/map_reads_lanes2_5_HAv3.1_2.log logs/map_reads_lanes2_5_HAv3.1_2resume.log
# start jop after a ~4 hour delay to download all the files:
filtered_bams$ sleep 20000; nohup parallel --resume --noswap --delay 1 --joblog logs/map_reads_lanes2_5_HAv3.1_2resume.log --jobs 8 './map_reads.sh {1} {2} ../data/novo_seq/lanes2_5/{1}/{1}_; ./sort_bams.sh {1} results/intermediate_bams; rm results/intermediate_bams/{1}.bam; ./dedup_baq_bams.sh {1} results/intermediate_bams; rm results/intermediate_bams/{1}.sort.bam' :::: ../bee_samples_listed/lanes2_5_IDs.list ::::+ ../bee_samples_listed/lanes2_5_libraries.list &> logs/map_reads_lanes2_5_HAv3.1_2resume.out &
# (!) NOTE: I may need to redo or check the output for the last one run
[5] 1846. Oops! I accidentally rant this on Barbara over the weekend and it started from the beginning and wrote over many of the finished files. I killed all the bowtie-align and looked at timestamps to figure out what partial files need to be re-done: AR1301, AR1302, AR1306, AR1311, AR1314 may be messed up. Also re-do AR1214
AR1214, AR1401 were still working (I'll let let picard dedup finish)
In addition, AR0813 and AR0506 had issues, zero file size, and I will rerun.
AT 09:55:33 I killed 5 bowtie2 threads, so with the exception of AR1214 and AR1401
(which I saw .sort. files ahead of time, so alignment was done), all .dedup.baq.bams created after 9:55am are suspect.
RE-DO ALL OF THESE:
AR1214, AR1301, AR1302, AR1306, AR1311, AR1314, AR1401 (AR1305 ended 9:53, .bai made 9:54 right as I was cancelling 8-threads, so it is A-okay).
In addition, redo AR0813 and AR0506 (no logged error, but zero file size)

# ok so I broke this task up into 4 batches (batch0 already completed with barbara):
# I will run these batches separately and transfer the completed bams back
# running batch1:
filtered_bams$ nohup parallel --resume --noswap --delay 1 --joblog logs/map_reads_lanes2_5_HAv3.1.batch1.log --jobs 8 './map_reads.sh {1} {2} ../data/novo_seq/lanes2_5/{1}/{1}_; ./sort_bams.sh {1} results/intermediate_bams; rm results/intermediate_bams/{1}.bam; ./dedup_baq_bams_mac.sh {1} results/intermediate_bams; rm results/intermediate_bams/{1}.sort.bam' :::: ../bee_samples_listed/lanes2_5_IDs.batch1.list ::::+ ../bee_samples_listed/lanes2_5_libraries.batch1.list &> logs/map_reads_lanes2_5_HAv3.1.batch1.out &
[1] 73467 - RUNNING 8.5.19 on Nancy's Mac. OOPS NOT SAVING ANYTHING BECAUSE OF UNBOUND $PICARD VARIABLE. CANCELLED, COMMENTED OUT $PICARD, AND RERUNNING:
[1] 81949 - RUNNING 8.6.19 5:30pm

# TO DO:
# Download Julie's bees from NCBI:
# First get SSR ID's for NCBI download from all bees in Study. year >1994 & not Humboldt. Actually I should just get Humboldt too maybe if I have space/time.
Done
# Download files from NCBI (not done yet!)
data/Cridland_2018$ nohup parallel --joblog ../../logs/download_Cridland_2018_NCBI.log --delay 2.5 --noswap --jobs 8 'fastq-dump --split-files -clip \
--gzip --skip-technical -O fastq_files/ "{1}"' :::: SRR_to_download.list &> ../../logs/download_Cridland_2018_NCBI.out &
[1] 6077 - BLOCKED BY FIREWALL
[1] 14939 - RUNNING 6.10.19. SEVERAL ERRORS. I THINK IT RAN OUT OF DISK SPACE. I NEED TO RESTART/RETRY AND POSSIBLY CHECK ALL FILES FOR CHECKSUMS MD5
filtered_bams$ cp ../logs/download_Cridland_2018_NCBI.log ../logs/download_Cridland_2018_NCBI_retry2.log
filtered_bams$ cp ../logs/download_Cridland_2018_NCBI.out ../logs/download_Cridland_2018_NCBI_retry2.out
data/Cridland_2018$ nohup parallel --resume-failed --joblog ../../logs/download_Cridland_2018_NCBI_retry2.log --delay 2.5 --noswap --jobs 8 'fastq-dump --split-files -clip --gzip --skip-technical -O fastq_files/ "{1}"' :::: SRR_to_download.list &> ../../logs/download_Cridland_2018_NCBI_retry2.out &
[2] 5553 - RUNNING 8.27.19. MANY STILL HAVE NON-ZERO EXIT STATUS.
Fastq-dump is super frustrating. I downloaded Aspera to get fastq files directly from the European Nucleotide Archive (ENA)
These instructions worked:
https://www.biostars.org/p/325010/
Put copy of ascp executable in path on Nancy's Mac:
(in .bash_profile):
# Add path for Aspera downloads 9.1.19:
export PATH="/Users/ecalfee/Applications/Aspera Connect.app/Contents/Resources:$PATH"

Test ascp:
Cridland_2018 ecalfee$ ascp -QT -l 300m -P33001 -i ~/Applications/Aspera\ Connect.app/Contents/Resources/asperaweb_id_dsa.openssh era-fasp@fasp.sra.ebi.ac.uk:/vol1/fastq/SRR558/001/SRR5580841/SRR5580841.fastq.gz .
# WORKS. I put this in a script to autogenerate urls to download from ENA:
filtered_bams$ ./download_fastq_ena.sh SRR5580833 ../data/Cridland_2018/fastq_files



# map these samples:
NOT RUN YET. I SHOULD MAKE SYMLINKS FIRST TO ID NOT SRR FOR FILE NAMING.
ALSO NEED TO TEST WITH SMALL FILE UPDATES TO MAP_READS_SINGLE.sh
# TEST:
data/Cridland_2018$ head fastq_files/SRR5580778_1.fastq.gz > fastq_files/TEST_SRR_1.fastq.gz
filtered_bams$ parallel 'ln -s ~/Documents/gitErin/bees/data/{3}/fastq_files/{1}_1.fastq.gz ../data/{3}/fastq_files/{2}_1.fastq.gz; ./map_reads_single.sh {2} {3}; ./sort_bams.sh {2} results/intermediate_bams; rm results/intermediate_bams/{2}.bam; ./dedup_baq_bams_mac.sh {2} results/intermediate_bams; rm results/intermediate_bams/{2}.sort.bam' ::: TEST_SRR ::: TEST_ID ::: Cridland_2018
# note: needed full absolute path for symbolic link to work (!)
# RUN ALL. 
# Note: this is modified from the test to download the fastq first, then map.
To save space, it deletes the fastq after mapping (BUT saves an md5 sum first! to verify data integrity against expected md5sum):
filtered_bams$ parallel --noswap --joblog logs/download_and_map_reads_Cridland_2018_HAv3.1.log --delay 3 --jobs 8 './download_fastq_ena.sh {1} ../data/{3}/fastq_files; md5 ../data/{3}/fastq_files/{1}.fastq.gz > ../data/{3}/fastq_files/{1}.observed.md5; ln -s ~/Documents/gitErin/bees/data/{3}/fastq_files/{1}.fastq.gz ../data/{3}/fastq_files/{2}_1.fastq.gz; ./map_reads_single.sh {2} {3}; rm ../data/{3}/fastq_files/{1}.fastq.gz; ./sort_bams.sh {2} results/intermediate_bams; rm results/intermediate_bams/{2}.bam; ./dedup_baq_bams_mac.sh {2} results/intermediate_bams; rm results/intermediate_bams/{2}.sort.bam' :::: ../data/Cridland_2018/SRR_to_download.list ::::+ ../data/Cridland_2018/IDs_to_download.list ::: Cridland_2018 &> logs/download_and_map_reads_Cridland_2018_HAv3.1.out &
[1] 15946 - RUNNING 9.1.19. OOPS many download errors probably because 8 is too many files at once. I'll download on two threads and then once it's 8 files in, I will start mapping.
# I delete all partial files for now.
# DOWNLOAD ONLY:
filtered_bams$ parallel --noswap --joblog logs/download_Cridland_2018_HAv3.1_1thread.log --jobs 1 './download_fastq_ena.sh {1} ../data/{3}/fastq_files' :::: ../data/Cridland_2018/SRR_to_download.list ::::+ ../data/Cridland_2018/IDs_to_download.list ::: Cridland_2018 &> logs/download_Cridland_2018_HAv3.1_1thread.out &
[1] 18907 - RUNNING 9.1.19 5:35pm. KILL. DELETE & RERUN FROM BEGINNING BECAUSE I LOST SOME
[1] 21812 - RUNNINg 9.1.19 7:30pm
# ALL FILES WERE DOWNLOADED COMPLETELY - successful check:
# first I extract the md5 column from each type, then I compare:
Cridland_2018/fastq_files$ for i in $(cat ../SRR_to_download.list); do cut -f4 -d" " $i.observed.md5 > $i.observed2.md5; done
Cridland_2018/fastq_files$ for i in $(cat ../SRR_to_download.list); do cut -f1 -d" " $i.true.md5 > $i.true2.md5; done
Cridland_2018/fastq_files$ for i in $(cat ../SRR_to_download.list); do diff $i.true2.md5 $i.observed2.md5; done
# no output to diff means no differences -- great!

# MAP AND DELETE FASTQ:
filtered_bams$ nohup parallel --noswap --joblog logs/map_reads_Cridland_2018_HAv3.1_fromENA.log --delay 3 --jobs 6 'md5 ../data/{3}/fastq_files/{1}.fastq.gz > ../data/{3}/fastq_files/{1}.observed.md5; ln -s ~/Documents/gitErin/bees/data/{3}/fastq_files/{1}.fastq.gz ../data/{3}/fastq_files/{2}_1.fastq.gz; ./map_reads_single.sh {2} {3}; rm ../data/{3}/fastq_files/{1}.fastq.gz; ./sort_bams.sh {2} results/intermediate_bams; rm results/intermediate_bams/{2}.bam; ./dedup_baq_bams_mac.sh {2} results/intermediate_bams; rm results/intermediate_bams/{2}.sort.bam' :::: ../data/Cridland_2018/SRR_to_download.list ::::+ ../data/Cridland_2018/IDs_to_download.list ::: Cridland_2018 &> logs/map_reads_Cridland_2018_HAv3.1_fromENA.out &
[2] 20994 - RUNNING 9.1.19 7pm. NO CANCELLED. AND IT DELETED 6 FILES (grr). Restart w/ sleep 3600;
WAITING FOR PROCESS ID AFTER 'SLEEP'. COMPLETED by 9.4.19
# all bams look fine! 
bams_Cridland_2018_HAv3.1$ for i in $(ls *.sort.dedup.baq.bam); do samtools view $i | head -n 1; done

# moving over completed Cridland 2018 bams 9.4.19 to iplant:
mv results_Cridland_2018_bams_HAv3.1/ bams_Cridland_2018_HAv3.1
iput -K -P -b -r -T -X logs/checkpoint-file_iput_bams_Cridland_2018_HAv3.1.txt bams_Cridland_2018_HAv3.1/
RUNNING interactively 9.4.19
# checking with checksums file is complete:
filtered_bams$ nohup irsync -r -v -K bams_Cridland_2018_HAv3.1 i:bams_Cridland_2018_HAv3.1 &> logs/confirm_irsync_bams_Cridland_2018_HAv3.1_withKoption.txt &
[1] 24992 - RUNNING 9.5.19


# Mapping lane 1
filtered_bams$ nohup parallel --noswap --delay 1 --joblog logs/map_reads_lane_1_HAv3.1.log --jobs 6 './map_reads.sh {1} {2} ../data/novo_seq/C202SC18101772/raw_data/{1}/{1}_; ./sort_bams.sh {1} results/intermediate_bams; rm results/intermediate_bams/{1}.bam; ./dedup_baq_bams.sh {1} results/intermediate_bams; rm results/intermediate_bams/{1}.sort.bam' :::: ../data/novo_seq/C202SC18101772/samples.list ::: L1 &> logs/map_reads_lane_1_HAv3.1.out &
[1] 7694 - CANCELLED TO RUN WITH 6 THREADS:
[1] 8376 - RUNNING. OOPS needed to fix Picard variable for running on Nancy's Mac:
# (same version 2.18.2, but running on Mac it's called differently):
filtered_bams$ nohup parallel --noswap --delay 1 --joblog logs/map_reads_lane_1_HAv3.1.log --jobs 8  &> logs/map_reads_lane_1_HAv3.1.out &
[1] 18333 - COMPLETED 8.1.19. NOPE. ALL ERRORS (!)
TRY AGAIN:
TEST:
filtered_bams$ parallel './map_reads.sh {1} {2} ../data/novo_seq/C202SC18101772/raw_data/{1}/{1}_; ./sort_bams.sh {1} results/intermediate_bams; rm results/intermediate_bams/{1}.bam; ./dedup_baq_bams_mac.sh {1} results/intermediate_bams; rm results/intermediate_bams/{1}.sort.bam' ::: TEST_AR0302 ::: lane_blah
RUN ALL:
filtered_bams$ nohup parallel --noswap --delay 1 --joblog logs/map_reads_lane_1_HAv3.1_take2_8.26.19.log --jobs 8 './map_reads.sh {1} {2} ../data/novo_seq/C202SC18101772/raw_data/{1}/{1}_; ./sort_bams.sh {1} results/intermediate_bams; rm results/intermediate_bams/{1}.bam; ./dedup_baq_bams_mac.sh {1} results/intermediate_bams; rm results/intermediate_bams/{1}.sort.bam' :::: ../data/novo_seq/C202SC18101772/samples.list ::: L1 &> logs/map_reads_lane_1_HAv3.1_take2_8.26.19.out &
[1] 84522 - COMPLETED 8.26.19 - 8.27.19

# putting on iplant (first login with iinit):
filtered_bams$ mv results bams_lane_1_HAv3.1
filtered_bams$ iput -K -P -b -r -T -X logs/checkpoint-file_iput_bams_lane_1_HAv3.1.txt bams_lane1_HAv3.1/
COMPLETED 8.27.19. CONFIRM ALL SET BEFORE DELETING:
filtered_bams$ nohup irsync -r -v bams_lane1_HAv3.1 i:bams_lane1_HAv3.1 &> logs/confirm_irsync_bams_lane_1_HAv3.1.txt &
[1] 31017 - DONE 8.28.19. Double check with explicit checksums option:
filtered_bams ecalfee$ nohup irsync -r -v -K bams_lane1_HAv3.1 i:bams_lane1_HAv3.1 &> logs/confirm_irsync_bams_lane_1_HAv3.1_withKoption.txt &
[1] 31290 - COMPLETED 8.28.19. Then I deleted the local copy of these files off of Nancy's Mac.


# REMAPPING REF A/C/M bees to HAv3.1 genome:
# first download Kenya bees and Harpur to Nancy's mac:
filtered_bams$ parallel --noswap --joblog logs/download_harpur_w_Cerana_kenya_for_HAv3.1.log --jobs 1 './download_fastq_ena.sh {1} ../data/{3}/fastq_files' :::: ../bee_samples_listed/harpur_with_Cerana_kenya_IDs.list ::::+ ../bee_samples_listed/harpur_with_Cerana_kenya_IDs.list ::::+ ../bee_samples_listed/harpur_with_Cerana_kenya_libraries.list &> logs/download_harpur_w_Cerana_kenya_for_HAv3.1.out &
[1] 2595 - RUNNING 9.4.19. SOME POTENTIAL ERRORS. I'LL CONFIRM WHICH NEED NEW DOWNLOAD WITH md5:

# get md5 sums of downloaded files
filtered_bams$ nohup parallel --noswap --joblog logs/calc_md5_Harpur_Kenya_HAv3.1_fromENA.log --delay 3 --jobs 8 'md5 ../data/{3}/fastq_files/{1}.fastq.gz > ../data/{3}/fastq_files/{1}.observed.md5; cut -f4 -d" " ../data/{3}/fastq_files/{1}.observed.md5 > ../data/{3}/fastq_files/{1}.observed2.md5; cut -f1 -d" " ../data/{3}/fastq_files/{1}.true.md5 > ../data/{3}/fastq_files/{1}.true2.md5' :::: ../bee_samples_listed/harpur_with_Cerana_kenya_IDs.list ::::+ ../bee_samples_listed/harpur_with_Cerana_kenya_IDs.list ::::+ ../bee_samples_listed/harpur_with_Cerana_kenya_libraries.list &> logs/calc_md5_Harpur_Kenya_HAv3.1_fromENA.out &
[1] 25694 - RUNNING 9.5.19

# restart 4 jobs that failed:
cp logs/download_harpur_w_Cerana_kenya_for_HAv3.1.log logs/download_harpur_w_Cerana_kenya_for_HAv3.1_retry.log 
filtered_bams$ parallel --noswap --resume-failed --joblog logs/download_harpur_w_Cerana_kenya_for_HAv3.1_retry.log --jobs 1 './download_fastq_ena.sh {1} ../data/{3}/fastq_files' :::: ../bee_samples_listed/harpur_with_Cerana_kenya_IDs.list ::::+ ../bee_samples_listed/harpur_with_Cerana_kenya_IDs.list ::::+ ../bee_samples_listed/harpur_with_Cerana_kenya_libraries.list &> logs/download_harpur_w_Cerana_kenya_for_HAv3.1_retry.out &
[1] 62250 - RAN 9.6.19. Still failed for last 3. Try again:
filtered_bams$ parallel --noswap --resume-failed --joblog logs/download_harpur_w_Cerana_kenya_for_HAv3.1_retry2.log --jobs 1 './download_fastq_ena.sh {1} ../data/{3}/fastq_files' ::: SRR957077 SRR957078 SRR957091 :::+ SRR957077 SRR957078 SRR957091 ::: Harpur_2014 &> logs/download_harpur_w_Cerana_kenya_for_HAv3.1_retry2.out &
[3] 66768 - RUNNING 9.6.19, 5:50pm. Did not work. Try again:
filtered_bams$ parallel --noswap --joblog logs/download_harpur_w_Cerana_kenya_for_HAv3.1_retry3.log --jobs 1 './download_fastq_ena.sh {1} ../data/{3}/fastq_files' ::: SRR957077 SRR957078 SRR957091 :::+ SRR957077 SRR957078 SRR957091 ::: Harpur_2014 &> logs/download_harpur_w_Cerana_kenya_for_HAv3.1_retry3.out &
[1] 46614 - RUNNING 9.9.19. COMPLETED.

# mapping reads to HAv3.1
filtered_bams$ nohup parallel --noswap --joblog logs/map_reads_Harpur_Kenya_HAv3.1_fromENA.log --delay 3 --jobs 6 'md5 ../data/{3}/fastq_files/{1}.fastq.gz > ../data/{3}/fastq_files/{1}.observed.md5; cut -f4 -d" " ../data/{3}/fastq_files/{1}.observed.md5 > ../data/{3}/fastq_files/{1}.observed2.md5; cut -f1 -d" " ../data/{3}/fastq_files/{1}.true.md5 > ../data/{3}/fastq_files/{1}.true2.md5; ln -s ~/Documents/gitErin/bees/data/{3}/fastq_files/{1}.fastq.gz ../data/{3}/fastq_files/{2}_1.fastq.gz; ./map_reads_single.sh {2} {3}; rm ../data/{3}/fastq_files/{1}.fastq.gz; ./sort_bams.sh {2} results/intermediate_bams; rm results/intermediate_bams/{2}.bam; ./dedup_baq_bams_mac.sh {2} results/intermediate_bams; rm results/intermediate_bams/{2}.sort.bam' :::: ../bee_samples_listed/harpur_with_Cerana_kenya_IDs.list ::::+ ../bee_samples_listed/harpur_with_Cerana_kenya_IDs.list ::::+ ../bee_samples_listed/harpur_with_Cerana_kenya_libraries.list &> logs/map_reads_Harpur_Kenya_HAv3.1_fromENA.out &
[2] 62321 - RUNNINg 6.9.19 (started at the same time as the retry for downloading above because only 4 files in the middle hadn't finished downloading.) Looks like it finished but I need to run the 3 files that didn't download properly -- and check all other md5 sums that they look ok.
# successfully downloaded the 3 remaining files from ENA ('retry3') and now mapping:
filtered_bams$ nohup parallel --noswap --joblog logs/map_reads_Harpur_Kenya_HAv3.1_fromENA_retry3.log --delay 3 --jobs 3 'md5 ../data/{3}/fastq_files/{1}.fastq.gz > ../data/{3}/fastq_files/{1}.observed.md5; cut -f4 -d" " ../data/{3}/fastq_files/{1}.observed.md5 > ../data/{3}/fastq_files/{1}.observed2.md5; cut -f1 -d" " ../data/{3}/fastq_files/{1}.true.md5 > ../data/{3}/fastq_files/{1}.true2.md5; ln -s ~/Documents/gitErin/bees/data/{3}/fastq_files/{1}.fastq.gz ../data/{3}/fastq_files/{2}_1.fastq.gz; ./map_reads_single.sh {2} {3}; rm ../data/{3}/fastq_files/{1}.fastq.gz; ./sort_bams.sh {2} results/intermediate_bams; rm results/intermediate_bams/{2}.bam; ./dedup_baq_bams_mac.sh {2} results/intermediate_bams; rm results/intermediate_bams/{2}.sort.bam' ::: SRR957077 SRR957078 SRR957091 :::+ SRR957077 SRR957078 SRR957091 :::+ Harpur_2014 &> logs/map_reads_Harpur_Kenya_HAv3.1_fromENA_retry3.out &
[1] 61862 - RUNNING 9.10.19 -- oops it's only running the first file. I'll start the other two separately (shouldn't have had the + on the :::+ Harpur_2014.

filtered_bams$ nohup parallel --noswap --joblog logs/map_reads_Harpur_Kenya_HAv3.1_fromENA_retry2.log --delay 3 --jobs 2 'md5 ../data/{3}/fastq_files/{1}.fastq.gz > ../data/{3}/fastq_files/{1}.observed.md5; cut -f4 -d" " ../data/{3}/fastq_files/{1}.observed.md5 > ../data/{3}/fastq_files/{1}.observed2.md5; cut -f1 -d" " ../data/{3}/fastq_files/{1}.true.md5 > ../data/{3}/fastq_files/{1}.true2.md5; ln -s ~/Documents/gitErin/bees/data/{3}/fastq_files/{1}.fastq.gz ../data/{3}/fastq_files/{2}_1.fastq.gz; ./map_reads_single.sh {2} {3}; rm ../data/{3}/fastq_files/{1}.fastq.gz; ./sort_bams.sh {2} results/intermediate_bams; rm results/intermediate_bams/{2}.bam; ./dedup_baq_bams_mac.sh {2} results/intermediate_bams; rm results/intermediate_bams/{2}.sort.bam' ::: SRR957078 SRR957091 :::+ SRR957078 SRR957091 ::: Harpur_2014 &> logs/map_reads_Harpur_Kenya_HAv3.1_fromENA_retry2.out &
[2] 64224 - RUNNING 9.10.19. COMPLETED.

# move completed bams to plant:
filtered_bams$ mv results bams_harpur_kenya_HAv3.1
filtered_bams$ iput -K -P -b -r -T -X logs/checkpoint-file_iput_bams_harpur_kenya_HAv3.1.txt bams_harpur_kenya_HAv3.1/
RUNNING 9.11.19. COMPLETED.
filtered_bams$ nohup irsync -r -v -K bams_harpur_kenya_HAv3.1 i:bams_harpur_kenya_HAv3.1 &> logs/confirm_irsync_bams_harpur_kenya_HAv3.1_withKoption.txt &
[1] 88051 - RUNNING 9.11.19 COMPLETED. I deleted local copy


# checked all downloads look good for Harpur and Kenya reference bees:
filtered_bams$ parallel 'diff ../data/{2}/fastq_files/{1}.true2.md5 ../data/{2}/fastq_files/{1}.observed2.md5' :::: ../bee_samples_listed/harpur_with_Cerana_kenya_IDs.list ::::+ ../bee_samples_listed/harpur_with_Cerana_kenya_libraries.list
All good! 9.10.19


# transferring files over to Nancy's Mac for much faster alignment:
bees/data/novo_seq$ irsync -r --retries 3 -v -N 8 i:/iplant/home/ecalfee/lanes2_5 . 
I DELETED THESE FILES TO MAKE MORE DISK SPACE. I WILL MAP THESE ON BARBARA INSTEAD.

# decide if I'm going to try to demultiplex 'Undetermined' reads
# Use fastq_screen to see what the reads look like that don't have any hits -- are they contaminants from something I haven't considered? Yes - likely gut symbionts
# Adapter contamination at a low (~1-3%) is also there. I don't think this is having a large effect on my intial analysis, but I could filter out adapters e.g. with cutadapt, and check if my bams have adapter sequences that made it past filtering (?)
# If adapter contamination seems likely, I can use something like SeqPurge to trim off adapter sequences. (Sturm et al. 2016, https://doi.org/10.1186/s12859-016-1069-7)
# I can also check that sequences for the reference bees don't have adapter contamination.
# download and align pooled-seq reads for Brazilian Africanized honey bees (vcf is downloading ~/Downloads/AFZ.vcf.gz but I can alternatively get bams for each of 30 hives (pooled w/in hives) - https://www.nature.com/articles/sdata201697#cite2

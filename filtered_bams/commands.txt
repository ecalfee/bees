# command log and scripts to take raw reads, map to reference, and filter to produce filtered bam files

# I will follow the same process from .fq raw reads to .bam mappped reads using bowtie2
# and filtering (e.g. of duplicates) using picard tools as is described in bioinfo_pipe.txt
# for the reference panel bee genomes (and earlier CA bees) downloaded as .fq files from NCBI

# First sequencing run from Novogene completed 12/12/18, dowloaded from ftp using FileZilla (interactive) 12/18/18
# and saved in data/novo_seq/C202SC18101772/. Backups saved to linux on Willowbank and Box.com on cloud.
# Check MD5 that everything downloaded properly (all good!):
# bees/data/novo_seq/C202SC18101772/raw_data$ cat */MD5.txt > ALL_MD5_expected.txt # expected md5 values
# raw_data$ for i in $(awk '{print $2}' ALL_MD5_expected.txt); do md5 */${i} | awk '{print $4}'; done > ALL_MD5_observed.txt # observed md5 values for each .fq file
# raw_data$ diff -q <(awk '{print $1}' ALL_MD5_expected.txt) <(cat ALL_md5_observed.txt) # outputs 'Files * and * differ' if they differ; outputs nothing if they're the same. Take away -q to see differences.

# Re-downloaded honeybee genome Apis mellifera v4.5 from beebase.org on 12.19.18: data/honeybee_genome/Amel_4.5_scaffolds.fa (note: wasn't .fa.gz)

# Also downloaded Bowtie2 for macs: v2.3.3.1 to match what I used on the Linux machine previously. Downloaded 12.19.18
# re-indexed v4.5 genome from www.beebase.org (it's not gzipped the genome I downloaded)
bees/data/honeybee_genome$ bowtie2-build Amel_4.5_scaffolds.fa honeybee_Amel_4.5

# made a short script that maps reads for new bees just sequenced: map_reads.sh
# to run alignment in bulk, I first made a list of sample IDs sequenced in this batch C202SC18101772:
data/novo_seq$ awk '{print $5}' seq1_novogene_index_i7_bee_id_link.txt | tail -n +2 > C202SC18101772/samples.list
scripts$ nohup parallel --noswap --joblog ../logs/map_reads_C202SC18101772.log --jobs 4 \
./map_reads.sh {1} C202SC18101772 :::: ../data/novo_seq/C202SC18101772/samples.list &> ../logs/map_reads_C202SC18101772.out &
[1] 72328 - RUNNING 12.19.18 - DONE (some cancelled because already completed on other computer)
data/novo_seq/C202SC18101772$ tac samples.list > samples_reversed_order.list
scripts$ nohup parallel --noswap --joblog ../logs/map_reads_C202SC18101772_reversed_order.log --jobs 8 \
./map_reads.sh {1} C202SC18101772 :::: ../data/novo_seq/C202SC18101772/samples_reversed_order.list &> ../logs/map_reads_C202SC18101772_reversed_order.out &
[1] 7754 - RUNNING 12.19.18 on Barbara - cancelled due to memory. Now rerunning:
[didn't print new number/overwritten by nano, but it's running] - DONE; I cancelled last few when every bam was finished on one computer. Moved bams to Nancy's comp.
# some bams were completed by both computers and I noticed very small discrepancies in # lines per file (diff. of ~5-30 lines out of thousands)
# bowtie2 is the same version 2.3.3.1 and random seed is the same (2014) so this must be a small remaining stochasticity affected by compiling the program on mac vs. Ubuntu.
# for those bams with duplicated efforts I used the ones run on the mac going forward.
# Now filtering bams with new scripts sort_bams.sh and dedup_baq_bams.sh
scripts$ nohup parallel --noswap --joblog ../logs/filter_bams_C202SC18101772.log --jobs 4 \
'./sort_bams.sh {1} novo_seq/bam_files; ./dedup_baq_bams.sh {1} filtered_bams/results' \
:::: ../data/novo_seq/C202SC18101772/samples.list &> ../logs/filter_bams_C202SC18101772.out &
[1] 27043 -- typo, try again:
[1] 29784 -- needed to source ~/.profile to get variable $PICARD
[1] 31078 -- failed due to typo in file naming
[2] 31767 -RUNNING 12.20.18 19:15

# Now I am re-mapping all reference samples from Harpur 2014:
Harpur_2014_NCBI$ cat bam_files_old/IDs.list | cut -d'_' -f2 > samples.list
scripts$ chmod u+x map_reads_single.sh
scripts$ nohup parallel --noswap --joblog ../logs/map_reads_Harpur_2014_NCBI.log --jobs 4 \
./map_reads_single.sh {1} Harpur_2014_NCBI :::: ../data/Harpur_2014_NCBI/samples.list \
&> ../logs/map_reads_Harpur_2014_NCBI.out &
[1] 32424 - RUNNING 12.20.18 10:30. Reran ones that didn't go:
First 4 ran without issues, but then I moved the mapping script and they failed, so rerunning those:
filtered_bams$ nohup parallel --noswap --joblog ../logs/map_reads_Harpur_2014_NCBI_2.log --jobs 4 ./map_reads_single.sh {1} Harpur_2014_NCBI \
::: $(tail -n +5 ../data/Harpur_2014_NCBI/samples.list) &> ../logs/map_reads_Harpur_2014_NCBI_2.out &
[1] 14980 - RUNNING 12.21.18 # COMPLETED ALL DONE

# TO DO:
# and on now running Harpur bees --> put all in one consistent folder in filtered_bams/results
# run dedup_baq_bams.sh on Kenyan bees --> also put in folder filtered_bams/results
# delete intermediate bams if you need the space (likely).
# note: best to put more general scripts, that will be used in multiple analyses, when that comes up, in a scripts/ folder
# also need a script to calculate coverage distribution and mean coverage (to get 2x and .5x thresholds)


# run sort_bams.sh and dedup_baq_bams.sh on 'original' bams from CA_Bees
# (note inconsistent in CA_Bee/bam_from_Julie naming with *.merged.bam or *.combined.bam)
# first made symlinks to bams for consistent naming on CA_Bee
CA_Bee/bam_files$ for i in $(cat ../samples.list); do ln -s ../bam_from_Julie/$i.*.bam $i.bam; done
# then run filtering steps on CA_Bee bams
bees/filtered_bams$ nohup parallel --noswap --joblog ../logs/filter_bams_CA_Bee.log --jobs 4 './sort_bams.sh {1} ../data/CA_Bee/bam_files; ./dedup_baq_bams.sh {1} filtered_bams/results' :::: ../data/CA_Bee/samples.list &> ../logs/filter_bams_CA_Bee.out &
[1] 6017 -- fixed some typos in directory, memory and PICARD variable
# make logs directory, then run:
bees/filtered_bams$ mkdir logs
bees/filtered_bams$ nohup parallel --noswap --joblog logs/filter_bams_CA_Bee.log --jobs 4 './sort_bams.sh {1} ../data/CA_Bee/bam_files; ./dedup_baq_bams.sh {1} results' :::: ../data/CA_Bee/samples.list &> logs/filter_bams_CA_Bee.out &
[1] 28013 - RUNNING 12.27.18

# using called SNPs and genotypes for high-coverage bees:
# ancestry reference pops: Harpur A, C, and M bees
# admixed bees: Riverside_2014 (n=8)
# original data: from Julie, in data/bees_new_positions/ALL.bam ALL.fam ALL.map
# note: the original positions in ALL.map are incorrect because gaps between scaffolds are skipped
# over for physical positions and recombination/genetic distance was calculated
# with a chromosomal mean recombination rate. I will need to recalculate.

# total number of SNPs passing Julie's filtering:
data/bees_new_positions$ wc -l ALL.map
5781640 ALL.map

# create a file where 3rd column is population label (to filter by in plink)
data/bees_new_positions$ awk '{print $1, '\t', $2, '\t', $1}' ALL.fam > populations.txt

# get allele frequencies for Harpur A, C and M
data/bees_new_positions$ for pop in A M C; do plink --bfile ALL --freq --keep-allele-order --filter populations.txt $pop --out $pop; done
# note that --keep-allele-order preserves original ref/alt allele from ALL.bed (not necessarily related to reference allele in bee reference genome (!))
# taking out freq. column to stick all pop freqs together
awk '$1!="CHR" {print $1, '\t', $2, '\t', $3, '\t', $4, '\t', $5}' A.frq > A.frq.temp
for pop in M C; do awk '$1!="CHR" {print $5}' $pop.frq > $pop.frq.temp; done
# make header
echo CHR$'\t'SNP$'\t'A1$'\t'A2$'\t'A$'\t'C$'\t'M > ACM.frq
# paste them together
paste A.frq.temp C.frq.temp M.frq.temp -d '\t' >> ACM.frq
# remove temporary files
rm *.frq.temp
#rm [ACM].frq

# positions with under 0.2 minor allele frequency in all 3 populations offer little ancestry information, so I filter those out
data/bees_new_positions$ awk '$7 >= 0.2 || $6 >= 0.2 || $5 >= 0.2 {print $0}' ACM.frq | wc -l
# 648636
# This leaves about 650k SNPs. I did not filter for differences between ancestries because I didn't want to bias my results for SNPs informative C-M but not, for example A-C which has lower Fst
data/bees_new_positions$ head -n1 ACM.frq > ACM_common.frq
data/bees_new_positions$ awk '$7 >= 0.2 || $6 >= 0.2 || $5 >= 0.2 {print $0}' ACM.frq >> ACM_common.frq


# Then I filter for SNPs with high LD in the A population using plink and a sliding window of 50 SNPs
# greedily removing SNPs until no pairs in the window have r^2 > .4 , then shifting the window by 10 SNPs
bees_new_positions$ plink --bfile ALL --indep-pairwise 50 10 0.4 --keep-allele-order --extract ACM_common.frq --filter populations.txt A --out lowLDA4

# this leaves 160k SNPs
bees_new_positions$ wc -l lowLDA4.prune.in161036 lowLDA4.prune.in

# now I get allele counts for Harpur A C M for those positions (and I put all the lowLD files in a folder) lowLDA4
data/bees_new_positions$ for pop in A C M; do plink --bfile ALL --freq counts --keep-allele-order --extract lowLDA4/lowLDA4.prune.in --filter populations.txt $pop --out lowLDA4/$pop; done

# I also try an alternative windowed approach to filter SNPs:
# The idea is that on average LD decays quickly in honeybees and in all major groups A, C, M and O, mean r^2 is below 0.1 at greater than 1.5 kb https://www.nature.com/articles/ng.3077/figures/8 .
# Based on this information, I only look for r^2 above 0.2 in the African population in widows length 1.5 kb to avoid chance spurious results at unreasonably great distances. This leaves 252k SNPs.
data/bees_new_positions$ plink -bfile ALL --indep-pairwise 1.5 kb 1 0.2 --keep-allele-order --extract ACM_common.frq --filter populations.txt A --out newlowLDA2/snps
# If I filter in serial then for alleles with LD within C and then within M, I get very few SNPs (47k)
data/bees_new_positions$ plink -bfile ALL --indep-pairwise 1.5 kb 1 0.2 --keep-allele-order --extract newlowLDA2/snps.prune.in --filter populations.txt C --out newlowLDA2/snpsAC
data/bees_new_positions$ plink -bfile ALL --indep-pairwise 1.5 kb 1 0.2 --keep-allele-order --extract newlowLDA2/snpsAC.prune.in --filter populations.txt M --out newlowLDA2/snpsACM
# I don't understand how this could be lower than a hard filter for SNPs closer than 1.5kb (see below)

# I need to ask Graham if it is an issue to only filter for LD within A; filtering in serial A -> C -> M leaves very few SNPs (<60k) likely due to chance high LD from small pop. sizes. Yet another alternative: Below I create a set of ~94k SNPs by doing a hard filter of min. 1.5kb between each SNP from the high ancestry freq (>0.4 in at least one ancestry) SNPs.
data/bees_new_positions$ plink --bfile ALL --write-snplist --keep noYorCeranaorDomestic.txt --keep-allele-order --extract ACM_common.frq --bp-space 1500 --out thin1andHalfKB_common

# now I get allele counts for each individual in Riverside_2014 for those same alleles.
# to do this, I first make a new file with 3rd column identifying samples by individual ID
data/bees_new_positions$ awk '{print $1, '\t', $2, '\t', $2}' populations.txt > individuals.txt
# then for each individual in riverside_2014, I make an allele counts file
data/bees_new_positions$ for ind in $(awk '$1 == "Riverside_2014" {print $2}' individuals.txt); do plink --bfile ALL --freq counts --keep-allele-order --extract lowLDA4/lowLDA4.prune.in --filter individuals.txt $ind --out lowLDA4/$ind; done
# these are now saved as, e.g. SRCD49A.frq.counts where columns C1 and C2 identify counts for allele A1 and A2 and column G0 counts missing genotypes (C1 + C2 + G0 = 2 for each individual)

# now I get physical positions relative to chromosome (not scaffold; assumes 50,000 bp gaps between scaffolds)
# and the recombination distance between positions based on Wallberg recombination map for each position 
# at 100,000 resolution (could go down to 10,000 or lower, but some smoothing is likely more accurate). 
# Note: As I understand it, this map skips over gaps between scaffolds as if the gaps take up 50kbp and it's contiguous sequence 
# (same with bp position for v4.5 genome). The lower resolution maps do the same, but omit a recombination rate for any window 
# bridging scaffolds as it's not estimated well. I impute these recombination rates using the average rate across all non-NA windows in the chromosome
Rscript bp_to_r_Wallberg2015.R data/bees_new_positions/lowLDA4/A.frq.counts

# now I merge all the files to the correct format for ancestry_hmm
# chromosome, position_bp, allele counts A1 in A, allele counts A2 in A, allele counts A1 in C, allele counts A2 in C, allele counts A1 in M, allele counts A2 in M,
# distance in Morgans between previous marker and this one
# read counts A1 in sample1, read counts A2 in sample1, read counts A1 in sample2 etc.
infX.counts.pos

# I also create the sample input file for ancestry_hmm specifying ploidy
Riv2014.sample.ploidy
sample1\t2
sample2\t2 etc.

# I run NGSadmix on A, C, M reference pops and riverside 2014 individuals using reduced SNPs (pruned for LD) to get approximate population admixture proportions for each contributing ancestry
# to run NGSadmix I need beagle genotype likelihoods for all individuals, which I create in ANGSD
# first I get a new set of SNPs chosen to be sparse (unlinked) and at > 0.05 freq. in entire sample, including admixed samples, but not Cerana or Y individuals or domestic bee samples
# inds to include
data/bees_new_positions$ awk '$1 != "Y" && $1 != "Cerana" && $1 != "Domestic_2014"  {print $0}' populations.txt > noYorCeranaorDomestic.txt
# thin positions to 5KB and only sites > 0.05 MAF (about 35K snps remain)
data/bees_new_positions$ plink --bfile ALL --make-bed --keep noYorCeranaorDomestic.txt --keep-allele-order --maf 0.05 --bp-space 5000 --out thin5KB

# make into ANGSD formatted position input file: chr \t pos \t major \t minor \t from thin5KB.frq
data/bees_new_positions$ cat thin5KB.bim | tr -s "." "\t" | awk '{print $3"."$4"\t"$5"\t"$9"\t"$10}' > thin5KB.positions
# make list of bams to include in NGSadmix: data/bees_new_positions/thin5KB_bams.list
data/bees_new_positions$ awk '$1 == "A" || $1 == "C" || $1 == "M" {print "data/Harpur_2014_NCBI/bam_files/Harpur_"$2".sort.mrkdup.bam"}' thin5KB.fam >> thin5KB_bams.list
data/bees_new_positions$ awk '$1 != "A" && $1 != "C" && $1 != "M" {print "data/CA_Bee/bam_files/"$2".sort.mrkdup.bam"}' thin5KB.fam >> thin5KB_bams.list
# indexed sites file for use by angsd:
data/bees_new_positions$ angsd sites index thin5KB.positions
# and I identify the scaffolds/chromosomes that have at least one SNP included:
data/bees_new_positions$ cut -f1 thin5KB.positions | uniq > thin5KB_chrs.txt

# run angsd to calculate genotype likelihoods (-doMajorMinor 3 and -sites ensures consistency of major and minor allele)
# bioinfo_pipe.txt describes the bio-informatics pipeline from raw reads to bams, coordinate sorted, indexed, with headers and with marked duplicates
# filters: use BAQ (needs reference to calc. BAQ), remove bad reads (marked duplicates), minimum mapping quality of 13, minimum base/BAQ quality of 13, use samtools method and create beagle-type genotype likelihood file (-GL 1 -doGlf), use 6 threads (-P 6)
# I do not filter stringently on minimum base quality (or minimum of base quality and adjusted base quality (BAQ)) because base quality is already considered in SAMTOOLS genotype likelihood calculation; 13 is the recommended default
bees$ nohup angsd -doMajorMinor 3 -sites data/bees_new_positions/thin5KB.positions \
-rf data/bees_new_positions/thin5KB_chrs.txt \
-GL 1 -doGlf 2 -bam data/bees_new_positions/thin5KB_bams.list -baq 1 \
-ref data/honeybee_genome/Amel_4.5_scaffolds.fa -remove_bads 1 \
-minMapQ 13 -minQ 13 -P 6 -out data/sims_downsample/NGSadmix/thin5KB_GL &> data/sims_downsample/NGSadmix/thin5KB_GL.log
mv think5KB_GL.gz thin5KB_GL.gz &> data/sims_downsample/NGSadmix/thin5KB_GL.log &
[1] 20137
# CANCELLED - going to take too long. I split the input file into more manageable chunks to run in parallel:
data/bees_new_positions$ split thin5KB.positions -d -l 1000 thin5KB_chunks/positions
# indexed the chunks
data/bees_new_positions/thin5KB_chunks$ for i in $(ls positions*); do angsd sites index $i; done
# and make chromosome files for each
data/bees_new_positions/thin5KB_chunks$ for i in $(ls positions[0-9][0-9]); do cut -f1 $i | uniq > $i.chr; done
# now run angsd to get genotype likelihoods (in parallel)
bees$ nohup parallel --joblog data/sims_downsample/NGSadmix/thin5KB_GL_chunks.log \
--noswap --jobs 6 'angsd -doMajorMinor 3 \
-sites data/bees_new_positions/thin5KB_chunks/positions{1} \
-rf data/bees_new_positions/thin5KB_chunks/positions{1}.chr \
-GL 1 -doGlf 2 -bam data/bees_new_positions/thin5KB_bams.list -baq 1 \
-ref data/honeybee_genome/Amel_4.5_scaffolds.fa -remove_bads 1 \
-minMapQ 13 -minQ 13 -out data/sims_downsample/NGSadmix/thin5KB_GL_chunk{1}' ::: {00..34} &> data/sims_downsample/NGSadmix/thin5KB_GL_chunks.out
[1] 29871

# I run NGSadmix on AMC reference pops and CA possible admixed pops, using genotype likelihood file from above
bees$ NGSadmix -likes inputdata/sims_downsample/NGSadmix/thin5KB_GL.beagle.gz -K 3 -P 4 -o data/sims_downsample/NGSadmix/CA_Bee_AMC -minMaf 0.05


# now I run ancestry_hmm, allowing it to estimate time since admixture between 2 and 60 generations (1-2 yrs/gen & admixture after 1957 - present/2014 sample)
# preparing ancestry_hmm input file with reference and admixed counts
# extract only counts for ACM and Riverside individuals
data/bees_new_positions/lowLDA4$ for i in $(ls *.frq.counts); do awk '$1!="CHR" {print $5"\t"$6}' $i > $i.strp; done
# separates SNP position on chromosome and recombination position
data/bees_new_positions/lowLDA4$ awk '{print $1"\t"$2}' A.frq.counts.rmap > all.pos
data/bees_new_positions/lowLDA4$ awk '{print $3}' A.frq.counts.rmap > all.rpos
# paste together with SNP position information to make input file
data/bees_new_positions/lowLDA4$ paste all.pos A.frq.counts.strp C.frq.counts.strp M.frq.counts.strp all.rpos $(ls SRCD*frq.counts.strp) -d '\t' >> ../../sims_downsample/ancestry_hmm/ACM_Riv2014.counts
# making ancestry_hmm sample file with admixed sample ind's ploidy
data/bees_new_positions/lowLDA4$ for i in $(ls SRC*.frq.counts | cut -d"." -f1); do echo $i"\\t"2 >> ../../sims_downsample/ancestry_hmm/Riv2014.ploidy; done




# -g indicates that called genotypes (allele counts), rather than read counts, are being used for admixed individuals 
# -a 3 0.4 0.4 0.2
# population C 100 gen (est.) receives M migrants then 60 gen (est.) receives second wave of A migrants
# -p 1 100000 0.4 -p 2 100 0.2 -p 0 -30 0.4 --tmax 60 --tmin 2
# --ne ?not_sure form Nelson 2017: "The Africanized population has a large (666,667) effective population size."

# I binomially sample 'reads' for coverage and re-run ancestry_hmm
1X.counts.pos, 2X.counts.pos, 4X.counts.pos, 6X.counts.pos etc.

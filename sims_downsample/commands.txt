# using called SNPs and genotypes for high-coverage bees:
# ancestry reference pops: Harpur A, C, and M bees
# admixed bees: Riverside_2014 (n=8)
# original data: from Julie, in data/bees_new_positions/ALL.bam ALL.fam ALL.map
# note: the original positions in ALL.map are incorrect because gaps between scaffolds are skipped
# over for physical positions and recombination/genetic distance was calculated
# with a chromosomal mean recombination rate. I will need to recalculate.

# total number of SNPs passing Julie's filtering:
data/bees_new_positions$ wc -l ALL.map
5781640 ALL.map

# create a file where 3rd column is population label (to filter by in plink)
data/bees_new_positions$ awk '{print $1, '\t', $2, '\t', $1}' ALL.fam > populations.txt

# get allele frequencies for Harpur A, C and M
data/bees_new_positions$ for pop in A M C; do plink --bfile ALL --freq --keep-allele-order --filter populations.txt $pop --out $pop; done
# note that --keep-allele-order preserves original ref/alt allele from ALL.bed (not necessarily related to reference allele in bee reference genome (!))
# taking out freq. column to stick all pop freqs together
awk '$1!="CHR" {print $1, '\t', $2, '\t', $3, '\t', $4, '\t', $5}' A.frq > A.frq.temp
for pop in M C; do awk '$1!="CHR" {print $5}' $pop.frq > $pop.frq.temp; done
# make header
echo CHR$'\t'SNP$'\t'A1$'\t'A2$'\t'A$'\t'C$'\t'M > ACM.frq
# paste them together
paste A.frq.temp C.frq.temp M.frq.temp -d '\t' >> ACM.frq
# remove temporary files
rm *.frq.temp
#rm [ACM].frq

# positions with under 0.2 minor allele frequency in all 3 populations offer little ancestry information, so I filter those out
data/bees_new_positions$ awk '$7 >= 0.2 || $6 >= 0.2 || $5 >= 0.2 {print $0}' ACM.frq | wc -l
# 648636
# This leaves about 650k SNPs. I did not filter for differences between ancestries because I didn't want to bias my results for SNPs informative C-M but not, for example A-C which has lower Fst
data/bees_new_positions$ head -n1 ACM.frq > ACM_common.frq
data/bees_new_positions$ awk '$7 >= 0.2 || $6 >= 0.2 || $5 >= 0.2 {print $0}' ACM.frq >> ACM_common.frq


# Then I filter for SNPs with high LD in the A population using plink and a sliding window of 50 SNPs
# greedily removing SNPs until no pairs in the window have r^2 > .4 , then shifting the window by 10 SNPs
bees_new_positions$ plink --bfile ALL --indep-pairwise 50 10 0.4 --keep-allele-order --extract ACM_common.frq --filter populations.txt A --out lowLDA4

# this leaves 160k SNPs
bees_new_positions$ wc -l lowLDA4.prune.in lowLDA4.prune.in

# now I get allele counts for Harpur A C M for those positions (and I put all the lowLD files in a folder) lowLDA4
data/bees_new_positions$ for pop in A C M; do plink --bfile ALL --freq counts --keep-allele-order --extract lowLDA4/lowLDA4.prune.in --filter populations.txt $pop --out lowLDA4/$pop; done

# I also try an alternative windowed approach to filter SNPs:
# The idea is that on average LD decays quickly in honeybees and in all major groups A, C, M and O, mean r^2 is below 0.1 at greater than 1.5 kb https://www.nature.com/articles/ng.3077/figures/8 .
# Based on this information, I only look for r^2 above 0.2 in the African population in widows length 1.5 kb to avoid chance spurious results at unreasonably great distances. This leaves 252k SNPs.
data/bees_new_positions$ plink -bfile ALL --indep-pairwise 1.5 kb 1 0.2 --keep-allele-order --extract ACM_common.frq --filter populations.txt A --out newlowLDA2/snps
# If I filter in serial then for alleles with LD within C and then within M, I get very few SNPs (47k)
data/bees_new_positions$ plink -bfile ALL --indep-pairwise 1.5 kb 1 0.2 --keep-allele-order --extract newlowLDA2/snps.prune.in --filter populations.txt C --out newlowLDA2/snpsAC
data/bees_new_positions$ plink -bfile ALL --indep-pairwise 1.5 kb 1 0.2 --keep-allele-order --extract newlowLDA2/snpsAC.prune.in --filter populations.txt M --out newlowLDA2/snpsACM
# I don't understand how this could be lower than a hard filter for SNPs closer than 1.5kb (see below)

# I need to ask Graham if it is an issue to only filter for LD within A; filtering in serial A -> C -> M leaves very few SNPs (<60k) likely due to chance high LD from small pop. sizes. Yet another alternative: Below I create a set of ~94k SNPs by doing a hard filter of min. 1.5kb between each SNP from the high ancestry freq (>0.4 in at least one ancestry) SNPs.
data/bees_new_positions$ plink --bfile ALL --write-snplist --keep noYorCeranaorDomestic.txt --keep-allele-order --extract ACM_common.frq --bp-space 1500 --out thin1andHalfKB_common

# now I get allele counts for each individual in Riverside_2014 for those same alleles.
# to do this, I first make a new file with 3rd column identifying samples by individual ID
data/bees_new_positions$ awk '{print $1, '\t', $2, '\t', $2}' populations.txt > individuals.txt
# then for each individual in riverside_2014, I make an allele counts file
data/bees_new_positions$ for ind in $(awk '$1 == "Riverside_2014" {print $2}' individuals.txt); do plink --bfile ALL --freq counts --keep-allele-order --extract lowLDA4/lowLDA4.prune.in --filter individuals.txt $ind --out lowLDA4/$ind; done
# these are now saved as, e.g. SRCD49A.frq.counts where columns C1 and C2 identify counts for allele A1 and A2 and column G0 counts missing genotypes (C1 + C2 + G0 = 2 for each individual)

# now I get physical positions relative to chromosome (not scaffold; assumes 50,000 bp gaps between scaffolds)
# and the recombination distance between positions based on Wallberg recombination map for each position
# at 100,000 resolution (could go down to 10,000 or lower, but some smoothing is likely more accurate).
# Note: As I understand it, this map skips over gaps between scaffolds as if the gaps take up 50kbp and it's contiguous sequence
# (same with bp position for v4.5 genome). The lower resolution maps do the same, but omit a recombination rate for any window
# bridging scaffolds as it's not estimated well. I impute these recombination rates using the average rate across all non-NA windows in the chromosome
bees$ Rscript bp_to_r_Wallberg2015.R data/bees_new_positions/lowLDA4/A.frq.counts
# this produces file A.frq.counts.rmap
# separates SNP position on chromosome and recombination position
data/bees_new_positions/lowLDA4$ awk '{print $1"\t"$2}' A.frq.counts.rmap > all.pos
data/bees_new_positions/lowLDA4$ awk '{print $3}' A.frq.counts.rmap > all.rpos

# preparing ancestry_hmm input file with reference and admixed counts (admixed = only Riverside_2014 inds)
# strip header and other information besides allele counts from .frq.counts files
data/bees_new_positions/lowLDA4$ for i in $(ls *.frq.counts); do awk '$1!="CHR" {print $5"\t"$6}' $i > $i.strp; done
# paste together stripped files into correct order for ancestry_hmm input file
# chromosome, position_bp, allele counts A1 in A, allele counts A2 in A, allele counts A1 in C, allele counts A2 in C, allele counts A1 in M, allele counts A2 in M,
# distance in Morgans between previous marker and this one
# read counts A1 in sample1, read counts A2 in sample1, read counts A1 in sample2 etc.
data/bees_new_positions/lowLDA4$ paste all.pos A.frq.counts.strp C.frq.counts.strp M.frq.counts.strp all.rpos \
$(ls SRCD*frq.counts.strp) -d '\t' > ../../sims_downsample/ancestry_hmm/ACM_Riv2014.counts

# making ancestry_hmm sample file with admixed sample ind's ploidy
data/bees_new_positions/lowLDA4$ ls SRC*.frq.counts.strp | sed 's/.frq.counts.strp/\t2/' > ../../sims_downsample/ancestry_hmm/Riv2014.ploidy


# I run NGSadmix on A, C, M reference pops and riverside 2014 individuals using reduced SNPs (pruned for LD) to get approximate population admixture proportions for each contributing ancestry
# to run NGSadmix I need beagle genotype likelihoods for all individuals, which I create in ANGSD
# first I get a new set of SNPs chosen to be sparse (unlinked) and at > 0.05 freq. in entire sample, including admixed samples, but not Cerana or Y individuals or domestic bee samples
# inds to include
data/bees_new_positions$ awk '$1 != "Y" && $1 != "Cerana" && $1 != "Domestic_2014"  {print $0}' populations.txt > noYorCeranaorDomestic.txt
# thin positions to 5KB and only sites > 0.05 MAF (about 35K snps remain)
data/bees_new_positions$ plink --bfile ALL --make-bed --keep noYorCeranaorDomestic.txt --keep-allele-order --maf 0.05 --bp-space 5000 --out thin5KB

# make into ANGSD formatted position input file: chr \t pos \t major \t minor \t from thin5KB.frq
data/bees_new_positions$ cat thin5KB.bim | tr -s "." "\t" | awk '{print $3"."$4"\t"$5"\t"$9"\t"$10}' > thin5KB.positions
# make list of bams to include in NGSadmix: data/bees_new_positions/thin5KB_bams.list
data/bees_new_positions$ awk '$1 == "A" || $1 == "C" || $1 == "M" {print "data/Harpur_2014_NCBI/bam_files/Harpur_"$2".sort.mrkdup.bam"}' thin5KB.fam >> thin5KB_bams.list
data/bees_new_positions$ awk '$1 != "A" && $1 != "C" && $1 != "M" {print "data/CA_Bee/bam_files/"$2".sort.mrkdup.bam"}' thin5KB.fam >> thin5KB_bams.list
# indexed sites file for use by angsd:
data/bees_new_positions$ angsd sites index thin5KB.positions
# and I identify the scaffolds/chromosomes that have at least one SNP included:
data/bees_new_positions$ cut -f1 thin5KB.positions | uniq > thin5KB_chrs.txt

# run angsd to calculate genotype likelihoods (-doMajorMinor 3 and -sites ensures consistency of major and minor allele)
# bioinfo_pipe.txt describes the bio-informatics pipeline from raw reads to bams, coordinate sorted, indexed, with headers and with marked duplicates
# filters: use BAQ (needs reference to calc. BAQ), remove bad reads (marked duplicates), minimum mapping quality of 13, minimum base/BAQ quality of 13, use samtools method and create beagle-type genotype likelihood file (-GL 1 -doGlf), use 6 threads (-P 6)
# I do not filter stringently on minimum base quality (or minimum of base quality and adjusted base quality (BAQ)) because base quality is already considered in SAMTOOLS genotype likelihood calculation; 13 is the recommended default
bees$ nohup angsd -doMajorMinor 3 -sites data/bees_new_positions/thin5KB.positions \
-rf data/bees_new_positions/thin5KB_chrs.txt \
-GL 1 -doGlf 2 -bam data/bees_new_positions/thin5KB_bams.list -baq 1 \
-ref data/honeybee_genome/Amel_4.5_scaffolds.fa -remove_bads 1 \
-minMapQ 13 -minQ 13 -P 6 -out data/sims_downsample/NGSadmix/thin5KB_GL &> data/sims_downsample/NGSadmix/thin5KB_GL.log
mv think5KB_GL.gz thin5KB_GL.gz &> data/sims_downsample/NGSadmix/thin5KB_GL.log &
[1] 20137
# CANCELLED - going to take too long. Deleted partial output. I split the input file into more manageable chunks to run in parallel:
data/bees_new_positions$ split thin5KB.positions -d -l 1000 thin5KB_chunks/positions
# indexed the chunks
data/bees_new_positions/thin5KB_chunks$ for i in $(ls positions*); do angsd sites index $i; done
# and make chromosome files for each
data/bees_new_positions/thin5KB_chunks$ for i in $(ls positions[0-9][0-9]); do cut -f1 $i | uniq > $i.chr; done
# now run angsd to get genotype likelihoods (in parallel)
bees$ nohup parallel --joblog data/sims_downsample/NGSadmix/thin5KB_GL_chunks.log \
--noswap --jobs 6 'angsd -doMajorMinor 3 \
-sites data/bees_new_positions/thin5KB_chunks/positions{1} \
-rf data/bees_new_positions/thin5KB_chunks/positions{1}.chr \
-GL 1 -doGlf 2 -bam data/bees_new_positions/thin5KB_bams.list -baq 1 \
-ref data/honeybee_genome/Amel_4.5_scaffolds.fa -remove_bads 1 \
-minMapQ 13 -minQ 13 -out data/sims_downsample/NGSadmix/thin5KB_GL_chunk{1}' ::: {00..34} &> data/sims_downsample/NGSadmix/thin5KB_GL_chunks.out
[1] 29871
# I concatenate GL by chunks together (without headers for all but first file):
data/sims_downsample/NGSadmix$ zcat thin5KB_GL_chunk00.beagle.gz | gzip >> thin5KB_GL_ALL.beagle.gz; \
for i in {01..34}; do zcat thin5KB_GL_chunk$i.beagle.gz | tail -n +2 | gzip >> thin5KB_GL_ALL.beagle.gz; done

# I run NGSadmix on AMC reference pops and CA possible admixed pops, using genotype likelihood file from above
bees$ NGSadmix -likes data/sims_downsample/NGSadmix/thin5KB_GL_ALL.beagle.gz -K 3 -P 4 -o data/sims_downsample/NGSadmix/CA_Bee_AMC -minMaf 0.05
# order of IDs that matches thin5KB_bams.list and output to NGSadmix:
data/bees_new_positions$ awk '$1 == "A" || $1 == "C" || $1 == "M" {print $1"\t"$2}' thin5KB.fam >> thin5KB_ids.list
data/bees_new_positions$ awk '$1 != "A" && $1 != "C" && $1 != "M" {print $1"\t"$2}' thin5KB.fam >> thin5KB_ids.list

# using results of NGSadmix, I infer approximate avg. contributions of A, C, and M ancestries to Riverside_2014 pop
bees/sims_downsample$ sim_sample_x_coverage.R # A, C, M in Riverside_2014: 0.426 0.376 0.198

# now I run ancestry_hmm, allowing it to estimate time since admixture between 2 and 60 generations (1-2 yrs/gen & admixture after 1957 - present/2014 sample)

# ancestry_hmm test run produced this error:
computing forward probabilities	Segmentation fault (core dumped)
# emailed Russ and problem was putting negative integers (-9) as the rmap distance
# to the first position of any chromosome (which is ignored by the hmm but negatives still produce an error)
# so I substituted any -9 for a 1
data/TEST$ sed 's/-9/1/' head_ACM_Riv2014.counts > head2_ACM_Riv2014.counts
data/TEST$ ancestry_hmm -g -a 3 0.426 0.376 0.198 -p 1 100000 0.376 -p 2 100 0.198 \
-p 0 -30 0.426 --tmax 60 --tmin 2 --ne 670000 -i head2_ACM_Riv2014.counts -s ../sims_downsample/ancestry_hmm/Riv2014.ploidy
# now short test file runs without issue


# ancestry_hmm (manual: https://github.com/russcd/Ancestry_HMM)
data/sims_downsample/ancestry_hmm/highx$ nohup ancestry_hmm -g -e 1e-3 -a 3 0.426 0.376 0.198 -p 1 100000 0.376 -p 2 100 0.198 -p 0 -30 0.426 -b 10 1000 --tmax 60 --tmin 2 --ne 670000 -i ../ACM_Riv2014.counts -s ../Riv2014.ploidy &> ancestry_hmm.out &
[1] 22032
# -i is the input file (read counts) and -s is the sample ploidy file
# -g indicates that called genotypes (allele counts), rather than read counts, are being used for admixed individuals
# for genotypes an error rate of .001 is reasonable; for read counts I will use 3e-3 (approx. a 1% raw error rate * 1/3 chance it's a switch to the major (or minor))
# -a 3 0.426 0.376 0.198
# population C 100 gen (est.) receives M migrants then
# at 30 gen (negative = estimate this) receives second wave of A migrants
# -p 1 100000 0.376 -p 2 100 0.198 -p 0 -30 0.426 --tmax 60 --tmin 2
# -b 10 1000 performs 10 bootstraps of 1000 snps to calculate get an error range for the time estimate
# --ne ?not_sure form Nelson 2017: "The Africanized population has a large (666,667) effective population size."

# I binomially sample 'reads' for coverage and re-run ancestry_hmm
1X.counts.pos, 2X.counts.pos, 4X.counts.pos, 6X.counts.pos etc.
# binomial samples are done two ways- using fixed (even) coverage across the genome, and using poisson total # reads/coverage per position
bees/sims_downsample$ nohup parallel --jobs 6 --joblog downsampling.log --noswap "Rscript sim_sample_x_coverage.R ../data/sims_downsample/ancestry_hmm/ACM_Riv2014.counts {1} {2} {3}" ::: {1..10} ::: {1001..1010} ::: poisson fixed &> downsampling.out &
[1] 23922
# removed above samples and re-did after fixing -9 -> 1 start of chr position issue
bees/sims_downsample$ nohup parallel --jobs 6 --joblog downsampling.log --noswap "mkdir -p ../data/sims_downsample/ancestry_hmm/{1}x/{3}/seed{2}; Rscript sim_sample_x_coverage.R ../data/sims_downsample/ancestry_hmm/ACM_Riv2014.counts {1} {2} {3} ../data/sims_downsample/ancestry_hmm/{1}x/{3}/seed{2}/ACM_Riv2014" ::: {1..10} ::: {1001..1010} ::: poisson fixed &> downsampling.out &
[1] 25847
# For each level of coverage, I use 10 different random seeds 1001-1010 for replicates.
# My plan is to compare ancestry at high confidence genomic locations in the high coverage data
# with corresponding ancestry calls across replicate seeds & across all individuals & genomic locations
# Note: there is some missing data (uncalled genotypes) in the high coverage genotype data which have 0 0 allele counts and can't be binomially sampled.
# run ancestry_hmm where both times (C-M admixture and secondary A admixture) are estimated from the low-coverage data
bees/data/sims_downsample/ancestry_hmm$ nohup parallel --jobs 6 --joblog ancestry_hmm_1-10x_est_t2.log --noswap \
"cd {1}x/{3}/seed{2}; mkdir -p est_t2; cd est_t2; \
ancestry_hmm -e 3e-3 -a 3 0.426 0.376 0.198 \
-p 1 100000 0.376 -p 2 -60 0.198 -p 0 -30 0.426 \
--tmax 100 --tmin 2 --ne 670000 \
-i ../ACM_Riv2014.{1}x.{2}.{3} -s ../../../../Riv2014.ploidy" \
::: {1..10} ::: {1001..1010} ::: poisson fixed &> ancestry_hmm_1-10x_est_t2.out &
[1] 31145

# the lowest coverage data tends to underestimate the times
# so to separate the effect of low-coverage generally and miss-specifiying the time
# I fix the times using the optimum from the full high coverage data w/ called genotypes
# run ancestry_hmm where admixture times are fixed at 28 and 61 (the optimum from running ancestry_hmm on the called genotypes).
# THIS WAS RUN AND SAVED IN data/sims_downsample/ancestry_hmm/est_t2/ directory, but I have no other record of command .. so I systematically re-run this for different Ne specifications below
# Note that ~29 is about 0.5 gen/yr 1956-2014, but neither date should be taken
# literally because additional ongoing gene flow from C, M, or A would reduce the estimated
# generations since admixture (b/c a mixture of exponentials looks like a more recent exp...
# the good news is it tends to fit well anyways)
bees/data/sims_downsample/ancestry_hmm$ nohup parallel --jobs 6 --joblog ancestry_hmm_1-10x_fix_t.log --noswap \
"cd {1}x/{3}/seed{2}; mkdir -p fix_t; cd fix_t; \
ancestry_hmm -e 3e-3 -a 3 0.426 0.376 0.198 \
-p 1 100000 0.376 -p 2 61 0.198 -p 0 28 0.426 \
--ne 670000 \
-i ../ACM_Riv2014.{1}x.{2}.{3} -s ../../../../Riv2014.ploidy" \
::: {1..10} ::: {1001..1010} ::: poisson fixed &> ancestry_hmm_1-10x_fix_t.out &
[1] 7553

# I will make a new downsampling simulation that does a negative binomial (more variance in total read coverage)
# sampling and accounts for a 1% error rate in illumina reads at each position in modified
sim_sample_x_coverage.R
# negative binomial distribution chosen has variance to mean ratio set to 3
# 3 comes from ReadDepth paper w/ Illumina sequenced human genomes by Christopher Miller 2011: 
# https://doi.org/10.1371/journal.pone.0016327
# re-doing all simulations including the illumina error rate of 1%:
bees/sims_downsample$ nohup parallel --jobs 6 --joblog downsampling.log --noswap "mkdir -p ../data/sims_downsample/ancestry_hmm/wSeqError/{1}x/{3}/seed{2}; Rscript sim_sample_x_coverage.R ../data/sims_downsample/ancestry_hmm/ACM_Riv2014.counts {1} {2} {3} ../data/sims_downsample/ancestry_hmm/wSeqError/{1}x/{3}/seed{2}/ACM_Riv2014" ::: {1..10} ::: {1001..1010} ::: negbinom poisson fixed &> downsampling_withSeqError.out &
[1] 15334

# now re-doing all ancestry hmm calls with fixed times :
data/sims_downsample/ancestry_hmm/wSeqError$ nohup parallel --jobs 6 \
--joblog ancestry_hmm_1-10x_fix_t.log --noswap \
"cd {1}x/{3}/seed{2}; mkdir -p fix_t; cd fix_t; \
ancestry_hmm -e 3e-3 -a 3 0.426 0.376 0.198 \
-p 1 100000 0.376 -p 2 61 0.198 -p 0 28 0.426 \
--ne 670000 \
-i ../ACM_Riv2014.{1}x.{2}.{3} -s ../../../../../Riv2014.ploidy" \
::: {1..10} ::: {1001..1010} ::: negbinom poisson fixed &> ancestry_hmm_1-10x_fix_t.out &
[1] 23086 - Killed b/c did not appear to run (no output or memory usage)
# fixed by adding a directory level ../ for Riv2014.ploidy above & re-ran:
[1] 10994

# and with it estimating times:
data/sims_downsample/ancestry_hmm/wSeqError$ nohup parallel --jobs 6 \
--joblog ancestry_hmm_1-10x_est_t2.log --noswap \
"cd {1}x/{3}/seed{2}; mkdir -p est_t2; cd est_t2; \
ancestry_hmm -e 3e-3 -a 3 0.426 0.376 0.198 \
-p 1 100000 0.376 -p 2 -100 0.198 -p 0 -30 0.426 \
--tmax 200 --tmin 2 --ne 670000 \
-i ../ACM_Riv2014.{1}x.{2}.{3} -s ../../../../../Riv2014.ploidy" \
::: {1..10} ::: {1001..1010} ::: negbinom poisson fixed &> ancestry_hmm_1-10x_est_t2.out &
[2] 15873

# there are multiple ways to verify the robustness of the highX ancestry_hmm calls:

# using the highX coverage I assess robustness to misspecifying Ne; 
# I reduce expected Ne by a factor of ten and 100 from 670k to 67k to 6.7k
data/sims_downsample/ancestry_hmm$ nohup parallel --noswap \
--joblog ancestry_hmm_diffNe_highx.log \
"mkdir -p Ne{1}/est_t2/; cd Ne{1}/est_t2; \ 
ancestry_hmm -g -e 1e-3 -a 3 0.426 0.376 0.198 \
-p 1 100000 0.376 -p 2 -100 0.198 -p 0 -30 0.426 \
-b 10 1000 --tmax 200 --tmin 2 --ne {1} \
-i ../../ACM_Riv2014.counts -s ../../Riv2014.ploidy" ::: 670000 67000 6700 \
&> ancestry_hmm_diffNe_highx.out &
[2] 23435 - Killed (didn't chagne Ne or get directory correct..oops..fixed and re-ran:)
[1] 15810

# I also use multimix -- a 3 way ancestry caller for admixed individuals that uses full haplotype information (i.e. no thinning) but does not require phasing (waiting for permission to use software -- only academic non-commercial use license)

# I will think more about how to pick ancestry-informative reads with high power to distinguish European from African bees

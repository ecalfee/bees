# using called SNPs and genotypes for high-coverage bees:
# ancestry reference pops: Harpur A, C, and M bees
# admixed bees: Riverside_2014 (n=8)
# original data: from Julie, in data/bees_new_positions/ALL.bam ALL.fam ALL.map
# note: the original positions in ALL.map are incorrect because gaps between scaffolds are skipped
# over for physical positions and recombination/genetic distance was calculated
# with a chromosomal mean recombination rate. I will need to recalculate.

# total number of SNPs passing Julie's filtering:
data/bees_new_positions$ wc -l ALL.map
5781640 ALL.map

# create a file where 3rd column is population label (to filter by in plink)
data/bees_new_positions$ awk '{print $1, '\t', $2, '\t', $1}' ALL.fam > populations.txt

# get allele frequencies for Harpur A, C and M
data/bees_new_positions$ for pop in A M C; do plink --bfile ALL --freq --keep-allele-order --filter populations.txt $pop --out $pop; done
# note that --keep-allele-order preserves original ref/alt allele from ALL.bed (not necessarily related to reference allele in bee reference genome (!))
# taking out freq. column to stick all pop freqs together
awk '$1!="CHR" {print $1, '\t', $2, '\t', $3, '\t', $4, '\t', $5}' A.frq > A.frq.temp
for pop in M C; do awk '$1!="CHR" {print $5}' $pop.frq > $pop.frq.temp; done
# make header
echo CHR$'\t'SNP$'\t'A1$'\t'A2$'\t'A$'\t'C$'\t'M > ACM.frq
# paste them together
paste A.frq.temp C.frq.temp M.frq.temp -d '\t' >> ACM.frq
# remove temporary files
rm *.frq.temp
#rm [ACM].frq

# positions with under 0.2 minor allele frequency in all 3 populations offer little ancestry information, so I filter those out
data/bees_new_positions$ awk '$7 >= 0.2 || $6 >= 0.2 || $5 >= 0.2 {print $0}' ACM.frq | wc -l
# 648636
# This leaves about 650k SNPs. I did not filter for differences between ancestries because I didn't want to bias my results for SNPs informative C-M but not, for example A-C which has lower Fst
data/bees_new_positions$ head -n1 ACM.frq > ACM_common.frq
data/bees_new_positions$ awk '$7 >= 0.2 || $6 >= 0.2 || $5 >= 0.2 {print $0}' ACM.frq >> ACM_common.frq


# Then I filter for SNPs with high LD in the A population using plink and a sliding window of 50 SNPs
# greedily removing SNPs until no pairs in the window have r^2 > .4 , then shifting the window by 10 SNPs
bees_new_positions$ plink --bfile ALL --indep-pairwise 50 10 0.4 --keep-allele-order --extract ACM_common.frq --filter populations.txt A --out lowLDA4

# this leaves 160k SNPs
bees_new_positions$ wc -l lowLDA4.prune.in lowLDA4.prune.in

# now I get allele counts for Harpur A C M for those positions (and I put all the lowLD files in a folder) lowLDA4
data/bees_new_positions$ for pop in A C M; do plink --bfile ALL --freq counts --keep-allele-order --extract lowLDA4/lowLDA4.prune.in --filter populations.txt $pop --out lowLDA4/$pop; done

# I also try an alternative windowed approach to filter SNPs:
# The idea is that on average LD decays quickly in honeybees and in all major groups A, C, M and O, mean r^2 is below 0.1 at greater than 1.5 kb https://www.nature.com/articles/ng.3077/figures/8 .
# Based on this information, I only look for r^2 above 0.2 in the African population in widows length 1.5 kb to avoid chance spurious results at unreasonably great distances. This leaves 252k SNPs.
data/bees_new_positions$ plink -bfile ALL --indep-pairwise 1.5 kb 1 0.2 --keep-allele-order --extract ACM_common.frq --filter populations.txt A --out newlowLDA2/snps
# If I filter in serial then for alleles with LD within C and then within M, I get very few SNPs (47k)
data/bees_new_positions$ plink -bfile ALL --indep-pairwise 1.5 kb 1 0.2 --keep-allele-order --extract newlowLDA2/snps.prune.in --filter populations.txt C --out newlowLDA2/snpsAC
data/bees_new_positions$ plink -bfile ALL --indep-pairwise 1.5 kb 1 0.2 --keep-allele-order --extract newlowLDA2/snpsAC.prune.in --filter populations.txt M --out newlowLDA2/snpsACM
# I don't understand how this could be lower than a hard filter for SNPs closer than 1.5kb (see below)

# I need to ask Graham if it is an issue to only filter for LD within A; filtering in serial A -> C -> M leaves very few SNPs (<60k) likely due to chance high LD from small pop. sizes. Yet another alternative: Below I create a set of ~94k SNPs by doing a hard filter of min. 1.5kb between each SNP from the high ancestry freq (>0.4 in at least one ancestry) SNPs.
data/bees_new_positions$ plink --bfile ALL --write-snplist --keep noYorCeranaorDomestic.txt --keep-allele-order --extract ACM_common.frq --bp-space 1500 --out thin1andHalfKB_common

# now I get allele counts for each individual in Riverside_2014 for those same alleles.
# to do this, I first make a new file with 3rd column identifying samples by individual ID
data/bees_new_positions$ awk '{print $1, '\t', $2, '\t', $2}' populations.txt > individuals.txt
# then for each individual in riverside_2014, I make an allele counts file
data/bees_new_positions$ for ind in $(awk '$1 == "Riverside_2014" {print $2}' individuals.txt); do plink --bfile ALL --freq counts --keep-allele-order --extract lowLDA4/lowLDA4.prune.in --filter individuals.txt $ind --out lowLDA4/$ind; done
# these are now saved as, e.g. SRCD49A.frq.counts where columns C1 and C2 identify counts for allele A1 and A2 and column G0 counts missing genotypes (C1 + C2 + G0 = 2 for each individual)

# now I get physical positions relative to chromosome (not scaffold; assumes 50,000 bp gaps between scaffolds)
# and the recombination distance between positions based on Wallberg recombination map for each position
# at 100,000 resolution (could go down to 10,000 or lower, but some smoothing is likely more accurate).
# Note: As I understand it, this map skips over gaps between scaffolds as if the gaps take up 50kbp and it's contiguous sequence
# (same with bp position for v4.5 genome). The lower resolution maps do the same, but omit a recombination rate for any window
# bridging scaffolds as it's not estimated well. I impute these recombination rates using the average rate across all non-NA windows in the chromosome
bees$ Rscript bp_to_r_Wallberg2015.R data/bees_new_positions/lowLDA4/A.frq.counts
# this produces file A.frq.counts.rmap
# separates SNP position on chromosome and recombination position
data/bees_new_positions/lowLDA4$ awk '{print $1"\t"$2}' A.frq.counts.rmap > all.pos
data/bees_new_positions/lowLDA4$ awk '{print $3}' A.frq.counts.rmap > all.rpos

# preparing ancestry_hmm input file with reference and admixed counts (admixed = only Riverside_2014 inds)
# strip header and other information besides allele counts from .frq.counts files
data/bees_new_positions/lowLDA4$ for i in $(ls *.frq.counts); do awk '$1!="CHR" {print $5"\t"$6}' $i > $i.strp; done
# paste together stripped files into correct order for ancestry_hmm input file
# chromosome, position_bp, allele counts A1 in A, allele counts A2 in A, allele counts A1 in C, allele counts A2 in C, allele counts A1 in M, allele counts A2 in M,
# distance in Morgans between previous marker and this one
# read counts A1 in sample1, read counts A2 in sample1, read counts A1 in sample2 etc.
data/bees_new_positions/lowLDA4$ paste all.pos A.frq.counts.strp C.frq.counts.strp M.frq.counts.strp all.rpos \
$(ls SRCD*frq.counts.strp) -d '\t' > ../../sims_downsample/ancestry_hmm/ACM_Riv2014.counts


# making ancestry_hmm sample file with admixed sample ind's ploidy
data/bees_new_positions/lowLDA4$ ls SRC*.frq.counts.strp | sed 's/.frq.counts.strp/\t2/' > ../../sims_downsample/ancestry_hmm/Riv2014.ploidy


# I run NGSadmix on A, C, M reference pops and riverside 2014 individuals using reduced SNPs (pruned for LD) to get approximate population admixture proportions for each contributing ancestry
# to run NGSadmix I need beagle genotype likelihoods for all individuals, which I create in ANGSD
# first I get a new set of SNPs chosen to be sparse (unlinked) and at > 0.05 freq. in entire sample, including admixed samples, but not Cerana or Y individuals or domestic bee samples
# inds to include
data/bees_new_positions$ awk '$1 != "Y" && $1 != "Cerana" && $1 != "Domestic_2014"  {print $0}' populations.txt > noYorCeranaorDomestic.txt
# thin positions to 5KB and only sites > 0.05 MAF (about 35K snps remain)
data/bees_new_positions$ plink --bfile ALL --make-bed --keep noYorCeranaorDomestic.txt --keep-allele-order --maf 0.05 --bp-space 5000 --out thin5KB

# make into ANGSD formatted position input file: chr \t pos \t major \t minor \t from thin5KB.frq
data/bees_new_positions$ cat thin5KB.bim | tr -s "." "\t" | awk '{print $3"."$4"\t"$5"\t"$9"\t"$10}' > thin5KB.positions
# make list of bams to include in NGSadmix: data/bees_new_positions/thin5KB_bams.list
data/bees_new_positions$ awk '$1 == "A" || $1 == "C" || $1 == "M" {print "data/Harpur_2014_NCBI/bam_files/Harpur_"$2".sort.mrkdup.bam"}' thin5KB.fam >> thin5KB_bams.list
data/bees_new_positions$ awk '$1 != "A" && $1 != "C" && $1 != "M" {print "data/CA_Bee/bam_files/"$2".sort.mrkdup.bam"}' thin5KB.fam >> thin5KB_bams.list
# indexed sites file for use by angsd:
data/bees_new_positions$ angsd sites index thin5KB.positions
# and I identify the scaffolds/chromosomes that have at least one SNP included:
data/bees_new_positions$ cut -f1 thin5KB.positions | uniq > thin5KB_chrs.txt

# run angsd to calculate genotype likelihoods (-doMajorMinor 3 and -sites ensures consistency of major and minor allele)
# bioinfo_pipe.txt describes the bio-informatics pipeline from raw reads to bams, coordinate sorted, indexed, with headers and with marked duplicates
# filters: use BAQ (needs reference to calc. BAQ), remove bad reads (marked duplicates), minimum mapping quality of 13, minimum base/BAQ quality of 13, use samtools method and create beagle-type genotype likelihood file (-GL 1 -doGlf), use 6 threads (-P 6)
# I do not filter stringently on minimum base quality (or minimum of base quality and adjusted base quality (BAQ)) because base quality is already considered in SAMTOOLS genotype likelihood calculation; 13 is the recommended default
bees$ nohup angsd -doMajorMinor 3 -sites data/bees_new_positions/thin5KB.positions \
-rf data/bees_new_positions/thin5KB_chrs.txt \
-GL 1 -doGlf 2 -bam data/bees_new_positions/thin5KB_bams.list -baq 1 \
-ref data/honeybee_genome/Amel_4.5_scaffolds.fa -remove_bads 1 \
-minMapQ 13 -minQ 13 -P 6 -out data/sims_downsample/NGSadmix/thin5KB_GL &> data/sims_downsample/NGSadmix/thin5KB_GL.log
mv think5KB_GL.gz thin5KB_GL.gz &> data/sims_downsample/NGSadmix/thin5KB_GL.log &
[1] 20137
# CANCELLED - going to take too long. Deleted partial output. I split the input file into more manageable chunks to run in parallel:
data/bees_new_positions$ split thin5KB.positions -d -l 1000 thin5KB_chunks/positions
# indexed the chunks
data/bees_new_positions/thin5KB_chunks$ for i in $(ls positions*); do angsd sites index $i; done
# and make chromosome files for each
data/bees_new_positions/thin5KB_chunks$ for i in $(ls positions[0-9][0-9]); do cut -f1 $i | uniq > $i.chr; done
# now run angsd to get genotype likelihoods (in parallel)
bees$ nohup parallel --joblog data/sims_downsample/NGSadmix/thin5KB_GL_chunks.log \
--noswap --jobs 6 'angsd -doMajorMinor 3 \
-sites data/bees_new_positions/thin5KB_chunks/positions{1} \
-rf data/bees_new_positions/thin5KB_chunks/positions{1}.chr \
-GL 1 -doGlf 2 -bam data/bees_new_positions/thin5KB_bams.list -baq 1 \
-ref data/honeybee_genome/Amel_4.5_scaffolds.fa -remove_bads 1 \
-minMapQ 13 -minQ 13 -out data/sims_downsample/NGSadmix/thin5KB_GL_chunk{1}' ::: {00..34} &> data/sims_downsample/NGSadmix/thin5KB_GL_chunks.out
[1] 29871
# I concatenate GL by chunks together (without headers for all but first file):
data/sims_downsample/NGSadmix$ zcat thin5KB_GL_chunk00.beagle.gz | gzip >> thin5KB_GL_ALL.beagle.gz; \
for i in {01..34}; do zcat thin5KB_GL_chunk$i.beagle.gz | tail -n +2 | gzip >> thin5KB_GL_ALL.beagle.gz; done

# I run NGSadmix on ACM reference pops and CA possible admixed pops, using genotype likelihood file from above
bees$ NGSadmix -likes data/sims_downsample/NGSadmix/thin5KB_GL_ALL.beagle.gz -K 3 -P 4 -o data/sims_downsample/NGSadmix/CA_Bee_AMC -minMaf 0.05
# order of IDs that matches thin5KB_bams.list and output to NGSadmix:
data/bees_new_positions$ awk '$1 == "A" || $1 == "C" || $1 == "M" {print $1"\t"$2}' thin5KB.fam >> thin5KB_ids.list
data/bees_new_positions$ awk '$1 != "A" && $1 != "C" && $1 != "M" {print $1"\t"$2}' thin5KB.fam >> thin5KB_ids.list

# using results of NGSadmix, I infer approximate avg. contributions of A, C, and M ancestries to Riverside_2014 pop
bees/sims_downsample$ sim_sample_x_coverage.R # A, C, M in Riverside_2014: 0.426 0.376 0.198

# now I run ancestry_hmm, allowing it to estimate time since admixture between 2 and 60 generations (1-2 yrs/gen & admixture after 1957 - present/2014 sample)

# ancestry_hmm test run produced this error:
computing forward probabilities	Segmentation fault (core dumped)
# emailed Russ and problem was putting negative integers (-9) as the rmap distance
# to the first position of any chromosome (which is ignored by the hmm but negatives still produce an error)
# so I substituted any -9 for a 1
data/TEST$ sed 's/-9/1/' head_ACM_Riv2014.counts > head2_ACM_Riv2014.counts
data/TEST$ ancestry_hmm -g -a 3 0.426 0.376 0.198 -p 1 100000 0.376 -p 2 100 0.198 \
-p 0 -30 0.426 --tmax 60 --tmin 2 --ne 670000 -i head2_ACM_Riv2014.counts -s ../sims_downsample/ancestry_hmm/Riv2014.ploidy
# now short test file runs without issue


# ancestry_hmm (manual: https://github.com/russcd/Ancestry_HMM)
data/sims_downsample/ancestry_hmm/highx$ nohup ancestry_hmm -g -e 1e-3 -a 3 0.426 0.376 0.198 -p 1 100000 0.376 -p 2 100 0.198 -p 0 -30 0.426 -b 10 1000 --tmax 60 --tmin 2 --ne 670000 -i ../ACM_Riv2014.counts -s ../Riv2014.ploidy &> ancestry_hmm.out &
[1] 22032
# -i is the input file (read counts) and -s is the sample ploidy file
# -g indicates that called genotypes (allele counts), rather than read counts, are being used for admixed individuals
# for genotypes an error rate of .001 is reasonable; for read counts I will use 3e-3 (approx. a 1% raw error rate * 1/3 chance it's a switch to the major (or minor))
# -a 3 0.426 0.376 0.198
# population C 100 gen (est.) receives M migrants then
# at 30 gen (negative = estimate this) receives second wave of A migrants
# -p 1 100000 0.376 -p 2 100 0.198 -p 0 -30 0.426 --tmax 60 --tmin 2
# -b 10 1000 performs 10 bootstraps of 1000 snps to calculate get an error range for the time estimate
# --ne ?not_sure form Nelson 2017: "The Africanized population has a large (666,667) effective population size."

# I binomially sample 'reads' for coverage and re-run ancestry_hmm
1X.counts.pos, 2X.counts.pos, 4X.counts.pos, 6X.counts.pos etc.
# binomial samples are done two ways- using fixed (even) coverage across the genome, and using poisson total # reads/coverage per position
bees/sims_downsample$ nohup parallel --jobs 6 --joblog downsampling.log --noswap "Rscript sim_sample_x_coverage.R ../data/sims_downsample/ancestry_hmm/ACM_Riv2014.counts {1} {2} {3}" ::: {1..10} ::: {1001..1010} ::: poisson fixed &> downsampling.out &
[1] 23922
# removed above samples and re-did after fixing -9 -> 1 start of chr position issue
bees/sims_downsample$ nohup parallel --jobs 6 --joblog downsampling.log --noswap "mkdir -p ../data/sims_downsample/ancestry_hmm/{1}x/{3}/seed{2}; Rscript sim_sample_x_coverage.R ../data/sims_downsample/ancestry_hmm/ACM_Riv2014.counts {1} {2} {3} ../data/sims_downsample/ancestry_hmm/{1}x/{3}/seed{2}/ACM_Riv2014" ::: {1..10} ::: {1001..1010} ::: poisson fixed &> downsampling.out &
[1] 25847
# For each level of coverage, I use 10 different random seeds 1001-1010 for replicates.
# My plan is to compare ancestry at high confidence genomic locations in the high coverage data
# with corresponding ancestry calls across replicate seeds & across all individuals & genomic locations
# Note: there is some missing data (uncalled genotypes) in the high coverage genotype data which have 0 0 allele counts and can't be binomially sampled.
# run ancestry_hmm where both times (C-M admixture and secondary A admixture) are estimated from the low-coverage data
bees/data/sims_downsample/ancestry_hmm$ nohup parallel --jobs 6 --joblog ancestry_hmm_1-10x_est_t2.log --noswap \
"cd {1}x/{3}/seed{2}; mkdir -p est_t2; cd est_t2; \
ancestry_hmm -e 3e-3 -a 3 0.426 0.376 0.198 \
-p 1 100000 0.376 -p 2 -60 0.198 -p 0 -30 0.426 \
--tmax 100 --tmin 2 --ne 670000 \
-i ../ACM_Riv2014.{1}x.{2}.{3} -s ../../../../Riv2014.ploidy" \
::: {1..10} ::: {1001..1010} ::: poisson fixed &> ancestry_hmm_1-10x_est_t2.out &
[1] 31145

# the lowest coverage data tends to underestimate the times
# so to separate the effect of low-coverage generally and miss-specifiying the time
# I fix the times using the optimum from the full high coverage data w/ called genotypes
# run ancestry_hmm where admixture times are fixed at 28 and 61 (the optimum from running ancestry_hmm on the called genotypes).
# THIS WAS RUN AND SAVED IN data/sims_downsample/ancestry_hmm/est_t2/ directory, but I have no other record of command .. so I systematically re-run this for different Ne specifications below
# Note that ~29 is about 0.5 gen/yr 1956-2014, but neither date should be taken
# literally because additional ongoing gene flow from C, M, or A would reduce the estimated
# generations since admixture (b/c a mixture of exponentials looks like a more recent exp...
# the good news is it tends to fit well anyways)
bees/data/sims_downsample/ancestry_hmm$ nohup parallel --jobs 6 --joblog ancestry_hmm_1-10x_fix_t.log --noswap \
"cd {1}x/{3}/seed{2}; mkdir -p fix_t; cd fix_t; \
ancestry_hmm -e 3e-3 -a 3 0.426 0.376 0.198 \
-p 1 100000 0.376 -p 2 61 0.198 -p 0 28 0.426 \
--ne 670000 \
-i ../ACM_Riv2014.{1}x.{2}.{3} -s ../../../../Riv2014.ploidy" \
::: {1..10} ::: {1001..1010} ::: poisson fixed &> ancestry_hmm_1-10x_fix_t.out &
[1] 7553

# I will make a new downsampling simulation that does a negative binomial (more variance in total read coverage)
# sampling and accounts for a 1% error rate in illumina reads at each position in modified
sim_sample_x_coverage.R
# negative binomial distribution chosen has variance to mean ratio set to 3
# 3 comes from ReadDepth paper w/ Illumina sequenced human genomes by Christopher Miller 2011:
# https://doi.org/10.1371/journal.pone.0016327
# re-doing all simulations including the illumina error rate of 1%:
bees/sims_downsample$ nohup parallel --jobs 6 --joblog downsampling.log --noswap "mkdir -p ../data/sims_downsample/ancestry_hmm/wSeqError/{1}x/{3}/seed{2}; Rscript sim_sample_x_coverage.R ../data/sims_downsample/ancestry_hmm/ACM_Riv2014.counts {1} {2} {3} ../data/sims_downsample/ancestry_hmm/wSeqError/{1}x/{3}/seed{2}/ACM_Riv2014" ::: {1..10} ::: {1001..1010} ::: negbinom poisson fixed &> downsampling_withSeqError.out &
[1] 15334

# now re-doing all ancestry hmm calls with fixed times :
data/sims_downsample/ancestry_hmm/wSeqError$ nohup parallel --jobs 6 \
--joblog ancestry_hmm_1-10x_fix_t.log --noswap \
"cd {1}x/{3}/seed{2}; mkdir -p fix_t; cd fix_t; \
ancestry_hmm -e 3e-3 -a 3 0.426 0.376 0.198 \
-p 1 100000 0.376 -p 2 61 0.198 -p 0 28 0.426 \
--ne 670000 \
-i ../ACM_Riv2014.{1}x.{2}.{3} -s ../../../../../Riv2014.ploidy" \
::: {1..10} ::: {1001..1010} ::: negbinom poisson fixed &> ancestry_hmm_1-10x_fix_t.out &
[1] 23086 - Killed b/c did not appear to run (no output or memory usage)
# fixed by adding a directory level ../ for Riv2014.ploidy above & re-ran:
[1] 10994

# and with it estimating times:
data/sims_downsample/ancestry_hmm/wSeqError$ nohup parallel --jobs 6 \
--joblog ancestry_hmm_1-10x_est_t2.log --noswap \
"cd {1}x/{3}/seed{2}; mkdir -p est_t2; cd est_t2; \
ancestry_hmm -e 3e-3 -a 3 0.426 0.376 0.198 \
-p 1 100000 0.376 -p 2 -100 0.198 -p 0 -30 0.426 \
--tmax 200 --tmin 2 --ne 670000 \
-i ../ACM_Riv2014.{1}x.{2}.{3} -s ../../../../../Riv2014.ploidy" \
::: {1..10} ::: {1001..1010} ::: negbinom poisson fixed &> ancestry_hmm_1-10x_est_t2.out &
[2] 15873

# there are multiple ways to verify the robustness of the highX ancestry_hmm calls:

# using the highX coverage I assess robustness to misspecifying Ne;
# I reduce expected Ne by a factor of ten and 100 from 670k to 67k to 6.7k
data/sims_downsample/ancestry_hmm$ nohup parallel --noswap \
--joblog ancestry_hmm_diffNe_highx.log \
"mkdir -p Ne{1}/est_t2/; cd Ne{1}/est_t2; \
ancestry_hmm -g -e 1e-3 -a 3 0.426 0.376 0.198 \
-p 1 100000 0.376 -p 2 -100 0.198 -p 0 -30 0.426 \
-b 10 1000 --tmax 200 --tmin 2 --ne {1} \
-i ../../ACM_Riv2014.counts -s ../../Riv2014.ploidy" ::: 670000 67000 6700 \
&> ancestry_hmm_diffNe_highx.out &
[2] 23435 - Killed (didn't chagne Ne or get directory correct..oops..fixed and re-ran:)
[1] 15810

# I also use multimix -- a 3 way ancestry caller for admixed individuals that uses full haplotype information (i.e. no thinning) but does not require phasing (got permission to use software -- only academic non-commercial use license)
# publication:
C. Churchhouse and J. Marchini (2013) Multi-way admixture deconvolution using phased or unphased ancestral panels. Genetic Epidemiology
# file:///home/erin/Software/multimix/index.html:
# creating multimix input files:
# first split bim file into chromosomes:
bees/data/bees_new_positions$ mkdir ALL_splitbychr
bees/data/bees_new_positions$ parallel 'plink --bfile ALL --chr {1} --keep-allele-order --make-bed --out ALL_splitbychr/ALL_chr{1}' ::: {1..16}
# then create position file ('chr*.legend'):
bees$ parallel 'Rscript bp_scaffold_to_bp_LG_4multimix.R data/bees_new_positions/ALL_splitbychr/ALL_chr{1} {1} data/sims_downsample/multimix' ::: {1..16}
# create genotype files admix:
bees$ parallel --joblog data/sims_downsample/multimix/make_admix_input_geno.log 'type={3} bim=data/bees_new_positions/ALL_splitbychr/ALL_chr{2} chr={2} pop={1} out=data/sims_downsample/multimix sims_downsample/make_multimix_input_geno.sh' ::: Riverside_2014 ::: {1..16} ::: admix &> data/sims_downsample/multimix/make_admix_input_geno.out &
[1] 15890
# create genotype files ref:
bees$ parallel --joblog data/sims_downsample/multimix/make_ref_input_geno.log 'type={3} bim=data/bees_new_positions/ALL_splitbychr/ALL_chr{2} chr={2} pop={1} out=data/sims_downsample/multimix sims_downsample/make_multimix_input_geno.sh' ::: A C M ::: {1..16} ::: ref &> data/sims_downsample/multimix/make_ref_input_geno.out &
[2] 13992
# finally create an appropriate genetic map file: (doesn't have to include all SNPs, but I do it that way)
bees$ parallel --joblog data/sims_downsample/multimix/make_recomb_maps.log "Rscript bp_LG_to_r_Wallberg2015_4multimix.R data/sims_downsample/multimix {1} data/recomb_map/Wallberg_2015/recombination_rates/A.rates.1000.201.low_penalty.csv.cM_Mb.windows.100000.csv" ::: {1..16} &> data/sims_downsample/multimix/make_recomb_maps.out &
[1] 18437 -- oops, corrected typo:
[1] 19467

# "To run MCMC-MULTIMIX when the admixed samples are unphased genotypes we use MULTIMIX_MCMCgeno instead of MULTIMIX_MCMC:
cd data/sims_downsample/multimix
# NOTE: need to make output directory before running MULTIMIX -- it won't produce an error
bees/data/sims_downsample/multimix$ parallel --joblog run_50_or_100_SNP_windows.log \
"mkdir -p output_wind{1}_iters{2}; MULTIMIX_MCMCgeno_v1.1.0 -dir ./input/ -o ./output_wind{1}_iters{2}/ \
-sourcepops A/ C/ M/ -sampledir Riverside_2014/ \
-misfit 0.95 0.025 0.025 0.025 0.95 0.025 0.025 0.025 0.95 -M -sourcegenos \
-chr.list 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \
-iters {2} -burnin 100 -chunk {1}" ::: 50 100 ::: 200 500 &> run_50_or_100_SNP_windows.out &
[1] 28128
# got following error: Multivariate Normal Density undefined. Use a larger value of the lambda parameter. (lambda = 0.005)
# so I re-running with a larger lambda, which sets a small positive prior on the within-pop SNP covariance matrices for each ref. pop.
# (see Churchhouse & Marchini 2013 for details: https://doi.org/10.1002/gepi.21692 )
# "The modification of the sample covariance matrix is such that a small positive value λ is added to the variances to ensure the matrix is positive semidefinite and therefore invertible. This modification is the same as is used in ridge regression and can be justified from a Bayesian perspective through the use of a N(0, lambda*I) prior on the parameters being inferred. The parameters alpha_k (pop mean allele freq) and epsilon_k (covariance of SNPs within jth window from kth pop) can also be estimated if the source population data are unphased. Allele frequencies are easily estimated from unphased data. To estimate the haplotypic covariance matrix, we use half the genotypic covariance matrix."
# Basically, multimix works by estimating ancestry in each window of say 50 or 100 SNPs and accounts for within-pop haplotype LD within, but not between, these windows (a practical approach to minimizing bias/overconfidence in ancestry calls due to background LD).
# Rather than modeling true haplotypes, it calculates the covariance matrix for SNPs within a window for each reference pop and approximates this discrete haplotype structure with a MVN; switches of ancestry between windows is a regular markov chain.
parallel --joblog run_50_or_100_SNP_windows_lambda.log \
"mkdir -p output_wind{2}_iters{3}_lambda{1}; MULTIMIX_MCMCgeno_v1.1.0 -dir ./input/ -o ./output_wind{2}_iters{3}_lambda{1}/ \
-sourcepops A/ C/ M/ -sampledir Riverside_2014/ \
-misfit 0.95 0.025 0.025 0.025 0.95 0.025 0.025 0.025 0.95 -M -sourcegenos \
-chr.list 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \
-iters {3} -burnin 100 -chunk {2} -lambda {1}" ::: 0.01 0.05 0.1 ::: 50 100 ::: 200 500 &> run_50_or_100_SNP_windows_lambda.out &
[1] 29995
# I am trying again with even larger lambda values (and down to 25 SNPs per window) due to the same error:
multimix$ parallel --joblog run_50_or_100_SNP_windows_lambdaLarge.log "mkdir -p output_wind{2}_iters{3}_lambda{1}; MULTIMIX_MCMCgeno_v1.1.0 -dir ./input/ -o ./output_wind{2}_iters{3}_lambda{1}/ -sourcepops A/ C/ M/ -sampledir Riverside_2014/ -misfit 0.95 0.025 0.025 0.025 0.95 0.025 0.025 0.025 0.95 -M -sourcegenos -chr.list 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 -iters {3} -burnin 100 -chunk {2} -lambda {1}" ::: 0.2 0.3 0.5 1 ::: 25 50 100 ::: 200 &> run_50_or_100_SNP_windows_lambdaLarge.out &
[1] 1853

# I am seeing if I can reproduce this error in the sample files by using small reference panels of only 10 ind's:
~/Software/multimix/multimix_v1.1.0_Linux_x86_64/data/haplotypes$ cut -f1-10 --delimiter=" " YRI/chr1.genos > YRI_small/chr1.genos
~/Software/multimix/multimix_v1.1.0_Linux_x86_64/data/haplotypes$ cut -f1-10 --delimiter=" " CEU/chr1.genos > CEU_small/chr1.genos
~/Software/multimix/multimix_v1.1.0_Linux_x86_64$ mkdir -p sample_out_small; MULTIMIX_MCMCgeno_v1.1.0 -dir ./data/ -o ./sample_out_small/ -sourcepops CEU_small/ YRI_small/ -misfit 0.95 0.05 0.05 0.95 -M -sourcegenos -chr.list 1 -iters 200 -burnin 100 -chunk 50 &> test_CEU_YRI_small.out &
[2] 2318
# comparison with MULTIMIX_MCMCgeno_v1.1.0 with full sample sizes
~/Software/multimix/multimix_v1.1.0_Linux_x86_64$ mkdir -p sample_out_reg; MULTIMIX_MCMCgeno_v1.1.0 -dir ./data/ -o ./sample_out_reg/ -sourcepops CEU/ YRI/ -misfit 0.95 0.05 0.05 0.95 -M -sourcegenos -chr.list 1 -iters 200 -burnin 100 -chunk 50 &> test_CEU_YRI_reg.out &
[2] 2323
# ran okay -- b/c bees have some missing data I also ran with even smaller reference panels to see effect (n=5) for CEU/YRI
~/Software/multimix/multimix_v1.1.0_Linux_x86_64$ mkdir -p sample_out_small; MULTIMIX_MCMCgeno_v1.1.0 -dir ./data/ -o ./sample_out_Xsmall/ -sourcepops CEU_Xsmall/ YRI_Xsmall/ -misfit 0.95 0.05 0.05 0.95 -M -sourcegenos -chr.list 1 -iters 200 -burnin 100 -chunk 50 &> test_CEU_YRI_Xsmall.out &
[2] 2439 # ran without error. That's not the issue.

# parameters: specify input, output, source pop & admixed sample directories
# -M estimates the misfit probabilities specified in flattened matrix -misfit
# -chr.list specifies to run on all 16 bee chromosomes
# -sourcegenos indicates unphased source pops and MCMCgeno indicates unphased admixed samples
# -iters sets total number of MCMC iterations, of which -burnin are used for 'burn in'; -chunk sets # SNPs per window
# I should possibly filter sites near the boundaries of windows because "All of the methods are window-based meaning that the sites of switches in ancestry are restricted to occur only at the boundaries between these windows."
# The output files Local_Samples_indiv*.txt give the chromosome number, window number, then the number of post-burn-in MCMC samples for each ancestry state: AA AC AM CC CM MM . * indicates the Riverside_2014 individual # by order listed in
# multimix/input/Samples/genos/Riverside_2014/admix.ind




# I will think more about how to pick ancestry-informative reads with high power to distinguish European from African bees


# choosing ~2 individuals per pop for sequencing: aiming for 5x coverage at 20% estimated duplication rates = 63 bees/lane
# (see illumina calculations sims_downsample/illumina_seq_est_63beesperlane_5x_20percDup.png)
# maps of sampled individuals now in new R script: bees/maps/map_samples.R
# bees for sequencing chosen at random from those spaced by at least 2-3 miles w/in a pop

# due to issues with MULTIMIX, I will try a new ancestry HMM method by Townshend + Simon Myers preprint 2018 bioXiv
# doi: https://doi.org/10.1101/376137 MOSAIC is an R package: https://maths.ucd.ie/~mst/MOSAIC/
# open R in terminal to install MOSAIC
# sapply(c("ff", "combinat", "Rcpp", "doParallel", "argparser"), install.packages) #w/ first installing dependencies
# install.packages("~/Downloads/MOSAIC_1.0.tar.gz")
# MOSAIC help: https://maths.ucd.ie/~mst/MOSAIC/README.txt
# this method requires (imperfect) phasing, for which I will use fastPHASE which is more accurate
# than alternatives like Beagle for
# small sample size (<100) (Browning & Browning 2011 Review: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3217888/)
# MOSAIC input requirements:
Rscript ~/Software/MOSAIC/mosaic.R --help
There should be a folder with 4 types of input file:
1. phased haplotypes: "pop.genofile.chr" in the format #snps rows and #haps columns.
2. pop names: "sample.names" format unimportant apart from first column should have all the population names.
3. snp files: "snpfile.chr" #snps rowns and 6 columns of rsID, chr, position, distance, allele ?, allele ?.
4. recombination map: "rates.chr" 3 rows of #sites, position, recombination rate.
data/sims_downsample/MOSAIC$ Rscript /home/erin/Software/MOSAIC/mosaic.R --chromosomes 1:16 --maxcores 4 --ancestries 3 -n 1000 (# target haplotypes = double # diploid individuals; or large number it will take all of them) Riv2014 input
Riv2014 = target = name of target population (all other populations can be haplotype 'donors')
input folder containing input data
# make new sample names file from plink output (just the family file of all included ind's in order)
# not clear if recombination position in snp file is in M or cM (?) -- last SNP on chr22 is at 0.5 so it's likely Morgans
# geno files are phased SNPs encoded 0/1. I need to check what is used for missing data.
# run example data:
#######  EXAMPLES  ###############################################################################################
The "example_data" folder contains example data for chromosomes 18 to 22 and a real-data example run of mosaic can be done using:
> Rscript mosaic.R Moroccan example_data/ -a 2 -n 4 -c 18:22 # note to run just one chromosome I did 21:21
# and I had to make folders MOSAIC_RESULTS and MOSAIC_PLOTS ahead of time
# the output is in the form of save .Rdata which I can 'load' and then access individual parts, e.g. localanc
load("localanc_Moroccan_2way_1-2_21-21_158_60_0.99_100.RData") # from example file
# I added ?'s for some 0/1 genotypes in all the populations and it ran just fine as soon as I made all the files
it was looking for (e.g. snpfile too)
~/Software/MOSAIC$ Rscript mosaic.R Moroccan example_data/ -a 2 -n 4 -c 55:55
e.g. warning: In lapply(X = X, FUN = FUN, ...) : NAs introduced by coercion
# I need to ask the interpretation of output files, e.g. local.anc is 2X4X3696 for an original datased with 7087 SNPs and 22 moroccan ind's. I'm pretty sure the 2 is for both ancestries and the 3.6k is for new window boundaries (or center?) but
I don't see how this encodes 22 individuals
or equivalently in an interactive R session:
> mosaic.result=run_mosaic("Moroccan","example_data/",18:22,2,2)
# can plink give me recomb. rates for every SNP position based on an rmap?
# PHASING WITH fastPHASE

-oACM_Riv2014_chr1 # results prefix, no space is required
-g (don't impute genotypes)
using default for # posterior samples; -H200 would minimize individual phasing errors (default is 50)
# but I don't need super high precision because mosaic re-phases data
-i (estimate individual haplotypes)
otherwise I use default parameters (e.g. K = 10 or 20 clusters, # EM runs etc.) -- see all with ~$ fastPHASE -H

# use plink to filter genotypes for just populations of interest
bees/data/sims_downsample/fastPHASE$ for pop in A C M Riverside_2014; do echo $pop >> ACM_Riv2014_families.list; done
# and to make input files
bees/data/sims_downsample/fastPHASE$ plink --bfile ../../bees_new_positions/ALL --keep-allele-order --keep-fam ACM_Riv2014_families.list --recode fastphase --out ACM_Riv2014
# because in default settigns fastPHASE don't use the position information and it was causing errors on input,
# I manually remove it from input files first
bees/data/sims_downsample/fastPHASE$ for i in {1..16}; \
do grep -v "P " ACM_Riv2014.chr-$i.recode.phase.inp >> ACM_Riv2014.chr$i.recode.phase.inp; \
rm ACM_Riv2014.chr-$i.recode.phase.inp; done
# now running fastPHASE 1.4.8 for all 16 chromosomes in parallel
# was running with 8 jobs and H200 but was taking a very long time and using swap; delay start is to not overwhelm memory when new jobs start up together
bees/data/sims_downsample/fastPHASE$ nohup parallel --delay 10 --noswap --joblog fastPHASE.log --jobs 4 "echo Starting chr{1}; echo date; fastPHASE -g -i -oACM_Riv2014_chr{1} ACM_Riv2014.chr{1}.recode.phase.inp" ::: {1..16} &> fastPHASE.out &
[1] 28595

# now I want to convert the phased output from fastPHASE into input for MOSAIC ancestry inference program
# I want to use vcf-conversion-tools 1.0 to do this, but first I need an 'original vcf' to do this (split by chromosome)
bees/data/sims_downsample/fastPHASE$ for i in {1..16}; do plink --bfile ../../bees_new_positions/ALL --keep-allele-order --keep-fam ACM_Riv2014_families.list --chr $i --recode vcf --out ACM_Riv2014_chr$i; done
# these vcf's now match the input files I used for fastPHASE
# NOTE: I'm not sure that I filtered for only variant sites, which would make fastphase inefficient, but I should filter out
# invariants before continuing (about ~1/3 are invariant and can be filtered out with --maf .001 in plink)

# I downloaded vcf-conversion-tools 9.11.2018 from https://zenodo.org/record/10288#.W5hZgxRlDCI
~/Software/lstevison-vcf-conversion-tools-0139f9e$ cp fastPHASE2VCF.pl ../../bin/. # copy to bin
~/bin$ chmod u+x fastPHASE2VCF.pl # add permissions to run
# try again with the more up-to-date version cloned from git:
~/Software$ git clone https://github.com/lstevison/vcf-conversion-tools.git
~/Software/vcf-conversion-tools$ cp fastPHASE2VCF.pl ../../bin/. # copy to bin
~/bin$ chmod u+x fastPHASE2VCF.pl # add permissions to run
# Cite as
# Laurie Stevison, . (2014, June 4). vcf-conversion-tools 1.0 (Version 1.0). Zenodo. http://doi.org/10.5281/zenodo.10288
# convert fastPHASE output to VCF:
bees/data/sims_downsample/fastPHASE$ fastPHASE2VCF.pl ACM_Riv2014.chr16.recode.phase.inp ACM_Riv2014_chr16_hapguess_indiv.out ACM_Riv2014_chr16.vcf ACM_Riv2014_chr16.indiv.phased.out 16
# problem -- I get the following error:
Reading in fastPHASE input file...positions: -...done.
Reading in fastPHASE output file...Error: Original number of sites does not match output number of sites in fastPHASE files!
Died at /home/erin/bin/fastPHASE2VCF.pl line 102, <FPOUTPUT> line 170.
# I don't see that the vcf and true input to fastPHASE have different #s of sites.
# It also didn't fix the problem to replace null characters with ?'s in the fastPHASE output:
sed 's/\x0/?/g' ACM_Riv2014_chr16_hapguess_indiv.out > TEST_ACM_Riv2014_chr16_hapguess_indiv.out
bees/data/sims_downsample/fastPHASE$ fastPHASE2VCF.pl ACM_Riv2014.chr16.recode.phase.inp TEST_ACM_Riv2014_chr16_hapguess_indiv.out ACM_Riv2014_chr16.vcf TEST_ACM_Riv2014_chr16.indiv.phased.out 16 # same error
## I don't understand source of the error: input and output fastPHASE files as well as input VCF appear to have = # sites
ACM_Riv2014_chr10.vcf has 334171 lines and 334164 variants
bees/data/sims_downsample/fastPHASE$ sed '25!d' ACM_Riv2014_chr10_hapguess_indiv.out | tr -d [:blank:] | wc -m
### returns 334165
data/sims_downsample/fastPHASE$ sed '4!d' ACM_Riv2014.chr10.recode.phase.inp | tr -d [:blank:] | wc -m
### also returns 334165 (maybe +1 due to end of line character? not sure)

# others have also had this error: https://www.biostars.org/p/265377/
# I'm not sure the problem of if I should just try to use -Z fastphase output (simple, no dividing ind. Id's),
and pre-assign one allele to 0 vs. 1 in plink and filtering for invariant sites before passing input files to fastPHASE
so that I can just to a transformation of rows and columns to get it into the correct format.



# 2.6.19 trying again to run Salter-Townshend method:


# (1) make input files:

sims_downsample$ mkdir -p results/fastPHASE
sims_downsample$ mkdir -p results/geno

# find SNPs segregating in A/C/M/Riv2014 sample
sims_downsample$ plink --bfile ../data/bees_new_positions/ALL --keep-allele-order \
--keep-fam ACM_Riv2014_families.list --maf 0.05 --geno 0.5 \
--make-bed --out results/geno/ACM_Riv2014_var_sites

# recode for fastphase input files
sims_downsample$ plink --bfile results/geno/ACM_Riv2014_var_sites --keep-allele-order \
--recode fastphase 01 --out results/fastPHASE/ACM_Riv2014_01

# remove position information (not used by fastPHASE and creates problems):
sims_downsample$ for i in {1..16}; \
do grep -v "P " results/fastPHASE/ACM_Riv2014_01.chr-$i.recode.phase.inp \
> results/fastPHASE/ACM_Riv2014_01.chr$i.recode.phase.inp; \
rm results/fastPHASE/ACM_Riv2014_01.chr-$i.recode.phase.inp; done

# run fastPHASE with simplified -Z output
sims_downsample$ nohup parallel --delay 10s --noswap --joblog logs/fastPHASE01.log \
--jobs 4 "echo Starting chr{1}; echo date; \
fastPHASE -Z -g -i -oresults/fastPHASE/ACM_Riv2014_01.chr{1} results/fastPHASE/ACM_Riv2014_01.chr{1}.recode.phase.inp" \
::: {1..16} &> logs/fastPHASE01.out &
[1] 11012 - COMPLETED 2.6.19. Results may have imputed genotypes (even though I attempted to turn off imputation with -g). I do not find any ?'s or alternative missing value symbols in simplified output (-Z option).

# I take the fastPHASE output that minimizes switch error, transpose the results, then create per-population haplotype files for MOSAIC input (2xN ind's per pop = columns, SNPs per chrom = rows):
sims_downsample$ nohup parallel --joblog logs/transposing_genotypes_for_mosaic_ACM_Riv2014.log --jobs 4 './transpose_fastPHASE_to_MOSAIC_input.sh ACM_Riv2014 chr{1}' ::: {1..16} &> logs/transposing_genotypes_for_mosaic_ACM_Riv2014.out &
[1] 13563 - Had to fix special character for missing genotypes. Rerunning:
[1] 980 - COMPLETED 2.12.19

# rates files are space separated, begin with # of sites on that chromosome, and then list bp pos and cM pos
# to do this I'll start with Julie's positions from bees_new_positions/ALL.bed
# which just sticks adjacent scaffolds together. But I can extract the scaffold position from the SNP name and use the position relative to the scaffold to calculate the bp and cM position relative to the chromosome,
# assuming a 50000 bp gap between any two adjacent scaffolds.
:sites:101564
1523 1543 1816 2092 2183
0 0.000101034 0.002869933 0.005689183 0.006640906

# TO DO: get genetic position of all SNPs in ACM_Riv2014_var_sites for MOSAIC input. Run MOSAIC.

# For use of riverside_2014 genotype calls at same SNPs as I’m calling local ancestry, see local_ancestry/commands.txt

#################################################################################################################################
#################################################################################################################################
# CORRECT ORDER OF ADMIXING POPULATIONS ACM -> CMA:
# (makes output order more clear & 100% sure correct ancestry interpretation)

# remake input file for called genotypes:
data/bees_new_positions/lowLDA4$ paste all.pos C.frq.counts.strp M.frq.counts.strp A.frq.counts.strp all.rpos \
$(ls SRCD*frq.counts.strp) -d '\t' > ../../sims_downsample/ancestry_hmm/CMA_Riv2014.counts
data/sims_downsample/ancestry_hmm$ mkdir CMA

# Run ancestry_hmm on genotypes (estimate times):
data/sims_downsample/ancestry_hmm/CMA/highx$ nohup ancestry_hmm -g -e 1e-3 -a 3 0.4 0.2 0.4 -p 0 100000 0.4 -p 1 -100 0.2 -p 2 -60 0.4 --tmax 150 --tmin 2 --ne 670000 -i ../../CMA_Riv2014.counts -s ../../Riv2014.ploidy &> ancestry_hmm.out &
[1] 17631

# Simulate downsampling reads (includes .01 sequencing error):
bees/sims_downsample$ nohup parallel --jobs 5 --joblog downsampling_CMA.log --noswap "mkdir -p ../data/sims_downsample/ancestry_hmm/CMA/{1}x/{3}/seed{2}; Rscript sim_sample_x_coverage.R ../data/sims_downsample/ancestry_hmm/CMA_Riv2014.counts {1} {2} {3} ../data/sims_downsample/ancestry_hmm/CMA/{1}x/{3}/seed{2}/CMA_Riv2014" ::: {1..10} ::: 100 ::: negbinom &> downsampling_CMA.out &

# Run ancestry_hmm on simulated allele counts:
data/sims_downsample/ancestry_hmm/CMA$ nohup parallel --jobs 5 --joblog ancestry_hmm_1-10x_est_t2.log --noswap \
"cd {1}x/{3}/seed{2}; mkdir -p est_t2; cd est_t2; \
ancestry_hmm -e 3e-3 -a 3 0.4 0.2 0.4 -p 0 100000 0.4 -p 1 -100 0.2 -p 2 -60 0.4 \
--tmax 150 --tmin 2 --ne 670000 -i ../CMA_Riv2014.{1}x.{2}.{3} -s ../../../../../Riv2014.ploidy" \
::: {1..10} ::: 100 ::: negbinom &> ancestry_hmm_1-10x_est_t2.out &
[1] 21984

# Produce plot of results using compare_local_ancestry.R . add to manuscript supplement.
plots/sims_downsample.png




